<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-FEDBM7F51Q"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-FEDBM7F51Q');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>➕ 👵🏼 😵 人工ニューラルネットワークとは 🖕🏼 🤙🏻 👹</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="人工ニューラルネットワークは、音声認識システムから二次タンパク質構造の認識、さまざまな種類の癌の分類、遺伝子工学まで、さまざまな科学分野で使用されています。 しかし、彼らはどのように機能し、どのように優れていますか？ 
  
 
  
  大量の情報を処理すること以外のタスクに関しては、人間の脳はコ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <link rel="sitemap" type="application/xml" href="/sitemap.xml"/>

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>

  <script>document.write('<script src="https://pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://tech-in-japan.github.io/index.html"></a>
    <div class="page-header-text">Clever Geek Handbook</div>
  </header>
  <section class="page js-page"><h1>人工ニューラルネットワークとは</h1><div class="post__text post__text-html js-mediator-article" id="post-content-body"> 人工ニューラルネットワークは、音声認識システムから二次タンパク質構造の認識、さまざまな種類の癌の分類、遺伝子工学まで、さまざまな科学分野で使用されています。 しかし、彼らはどのように機能し、どのように優れていますか？ 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <a name="habracut"></a> 大量の情報を処理すること以外のタスクに関しては、人間の脳はコンピューターよりも優れています。 部屋に多くの異物があり、照明が弱い場合でも、人は顔を認識することができます。 騒がしい部屋にいるときでも、見知らぬ人を簡単に理解できます。 しかし、長年の研究にもかかわらず、コンピューターはそのようなタスクを高レベルで実行するにはほど遠いです。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     人間の脳は驚くほど信頼性が高く、コンピューターと比較して、いくつかの細胞が死んだからといって動作を停止することはありませんが、コンピューターは通常、CPUの損傷に耐えられません。 しかし、人間の脳の最も驚くべき特徴は、学習できることです。 自転車の乗り方を学びたい場合、ソフトウェアやアップデートは必要ありません。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     脳の計算は、軸索、シナプス、および樹状突起からなる神経ワイヤを介して電気インパルスを送信することにより情報を送信する密接に相互接続されたニューラルネットワークを通じて実行されます。  1943年、McCullochとPittsは人工ニューロンをスイッチとしてモデル化しました。スイッチは他のニューロンから情報を受け取り、入力の合計に応じてアクティブ化されるか、非アクティブのままです。  ANNノードでは、着信信号に対応するシナプスの重みが乗算され、合計されます。 これらの係数は、正（興奮）と負（抑制）の両方になります。  1960年代には、このような神経モデルは脳に似た特性を持っていることが証明されました。複雑なパターン認識操作を実行でき、ニューロン間の接続の一部が切断されても機能することができます。  Rosenblattパーセプトンのデモンストレーションでは、特定の分野で知られている例を使用して、そのようなニューロンの単純なネットワークをトレーニングできることを示しました。 後に、ミンスキーとペーパーレットは、単純な教訓は非常に狭いクラスの線形分離可能な問題（下記参照）しか解決できないことを証明しました。その後、ANNの学習活動は減少しました。 それにもかかわらず、例を使用して複雑なニューラルネットワークをトレーニングするタスクを促進できる学習エラーの後方伝播の方法は、これらの問題は分離できない可能性があることを示しました。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      NETtalkは人工ニューラルネットワークを使用してテキストを機械加工し、最初の広く知られたアプリケーションでした。 生物学では、タンパク質の二次構造を予測するために、まったく同じタイプのネットワークが使用されました。 実際、最高の研究者の一部はまだ同じ方法を使用しています。 別の波はこれから始まり、ANNの研究への関心を喚起し、思考機械の魔法の訓練について大騒ぎしました。 最も重要な初期発見のいくつかは、ソース5に記載されています。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      ANNは、コンピューターでニューロンネットワークのモデルをシミュレートすることで作成できます。 実際のニューロンのプロセスを模倣するアルゴリズムを使用して、ネットワークを「学習」させることができます。これは、さまざまな問題の解決に役立ちます。 ニューロンモデルはしきい値として提示されます（図1aに示されています）。 モデルは他の多くの外部ソースからデータを受け取り、各入力の値を決定し、これらの値を追加します。 合計入力がしきい値よりも大きい場合、ブロックの出力は1に等しく、そうでない場合はゼロになります。 したがって、入力の合計「加重」合計がしきい値に等しい場合、出力は0から1に変わります。 この条件を満たす元の空間の点は、いわゆる超平面を決定します。  2次元では、超平面は線ですが、3次元では、超平面は法線（垂直）平面です。 超平面の片側のポイントは0に分類され、反対側のポイントは1に分類されます。これは、2つのクラスが超平面によって分離されている場合、しきい値を使用して分類問題を解決できることを意味します。 これらの問題は線形分離可能と呼ばれ、図1bに示されています。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/getpro/habr/post_images/386/bb0/6cb/386bb06cbda4ec2478f3dae7e0b6288e.jpg" alt="画像">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     図1 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      <i>人工ニューラルネットワーク。</i>  <i>（a）ニューラルネットワークモデルとMcCulloch and Pittsしきい値要素のグラフィカルな表現。</i>  <i>しきい値ブロックは、1からNまでの番号が付けられた他のN個のブロックまたは外部ソースから入力信号を受け取ります。入力iはxiと呼ばれ、重みwiに関連付けられています。</i>  <i>すべての入力の重みの合計を測定するためのデバイスへの一般的な入力、wixi = w1x1 + w2x2 + ... +WNxΣi= 1 NN。値がしきい値tを下回る場合、ブロックの出力は1、それ以外の場合は-0。 wixiΣi= 1-tg（N）で表されます。gはステップ関数で、引数が負の場合は0、引数が正の場合は1です（実際の値は関係ありません。ここでは1を選択します）。</i>  <i>いわゆる伝達関数gは、赤い線で示されているように連続的で「S字型」でもあります。</i>  <i>（b）線形分離可能性（分離可能性）。</i>  <i>3次元では、しきい値によって、平面で分離できるモーメントを分類できます。</i>  <i>各ポイントは、ブロックのしきい値での入力値x1、x2、x3を表します。</i>  <i>緑の点はクラス0のデータポイントに対応し、赤の点は1に対応します。緑と赤の十字は、排他的論理和の論理機能を示しています。</i>  <i>緑と赤のドット（またはx1、x2プレーンのライン）を分離するプレーンを見つけることは不可能です（C）単方向ANN。</i>  <i>示されているネットワークは、7つの入力を占有し、隠れ層に5つのユニットがあり、1つの出力があります。</i>  <i>これは2層ネットワークです。なぜなら、</i>  <i>入力レイヤーは変更を行わず、考慮されません。</i>  <i>（d）再トレーニング。</i>  <i>8つのポイントは放物線のプラスで示されます（「実験的」ノイズを除く）。</i>  <i>これらは3つの異なるANNのトレーニングに使用されます。</i>  <i>ネットワークは、x値を入力（単一入力）として認識し、y値を望ましい結果として学習します。</i>  <i>予想どおり、1つの隠れブロック（緑）を持つネットワークは、高レベルの作業に対処しません。</i>  <i>10個の隠れた要素（青）を持つネットワークは、驚くほどよくコア機能をもたらします。</i>  <i>20の隠された要素（バイオレット）を持つ最後のネットワークは情報を適切に処理し、ネットワークは十分に訓練されていますが、一部の中間エリアでは過度に創造的です。</i> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4> トレーニング </h4>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     分類問題が分離可能な場合、しきい値デバイスが分類問題を正しく解決できるように、重みとしきい値を設定する方法を見つける必要があります。 これは、既知の分類からの例を常に追加することで実現できます。 このプロセスは、人が何かを学習するプロセスに似ているため、学習またはトレーニングと呼ばれます。 コンピューター支援学習モデリングでは、各ステップの後に分類がより高いレベルで行われるように、重みとしきい値を絶えず変更します。 トレーニングはさまざまなアルゴリズムによって実装できます。これらのアルゴリズムの1つについては後で説明します。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     訓練中、超平面は空間内で正しい位置を見つけるまで一方向に移動し、次に他の方向に移動しますが、その後は大幅に変化しません。 このようなプロセスは、Neural Java（ <a href="http://lcn.epfl.ch/tutorial/english/index.html">http://lcn.epfl.ch/tutorial/english/index.html</a> ）によって十分に実証されています。  「Adline、Percepton、Backpropagation」（赤と青の点が2つのクラスを表します）のリンクをたどり、「play」をクリックします。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     人工ニューラルネットワークを簡単に適用できるタスクの例を考えてみましょう。  2種類のがんのうち、特定の治療法に反応するのは1種類のみです。 これら2種類の癌を互いに区別できる単純なバイオマーカーはないため、腫瘍サンプルの遺伝子発現を測定して、各腫瘍の種類を決定することにします。  50個のクラス0（非反応性）腫瘍と50個のクラス1（反応性）腫瘍で20種類の遺伝子の値を測定したとします。 このデータに基づいて、入力として20個の遺伝子値を取り、結果として0または1を出力するしきい値デバイスをトレーニングして、それぞれ2つのクラスの1つを決定します。 データが線形に分離可能な場合、しきい値ブロックはトレーニングデータを正しく分類します。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     ただし、多くの分類問題は線形分離可能ではありません。 より多くの超平面を導入する、つまり複数のしきい値ブロックを導入することにより、このような非線形問題のクラスを分離できます。 通常、これは、しきい値要素の追加の（非表示の）レベルを追加することによって行われます。各レベルは、入力データを部分的に分類し、出力データを最後のレベルに送信します。 最終レベルでは、すべての部分的な分類が収集されて最終レベルが作成されます（図1b）。 このようなネットワークは、マルチレベルパーセプトンまたは単方向ネットワークと呼ばれます。 単方向ニューラルネットワークは、バイナリ出力（0および1）ではなく、一定の出力を必要とする回帰タスクにも使用できます。 ステップ関数を連続関数に置き換えると、出力として実数が得られます。 多くの場合、「シグモイド」活性化関数が使用される場合、それは一時的なしきい値関数です（図1a）。  「シグモイド」アクティベーション関数は分類問題にも使用でき、0.5未満の出力をクラス0として、0.5を超える出力をクラス1として解釈します。また、結果をクラス1の確率として解釈するのも理にかなっています。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     上記の例では、次のオプションも使用できます。クラス1は発音された遺伝子1として特徴付けられ、無症候性のクラスは0、またはその逆です。 両方の遺伝子が発音または無症候性の場合、クラス0（腫瘍）が割り当てられます。 これは排他的論理「or」に対応し、非線形に分離可能な関数の標準的な例です（図1b）。 この場合、腫瘍の分類には、マルチレベルネットワークを使用する必要がありました。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4> ラーニングエラーポストバック </h4>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     上記の学習エラーポストバックアルゴリズムは、アナログ出力の単方向ニューラルネットワークで機能します。 トレーニングは、小さな乱数のネットワークにすべての重りを設置することから始まります。 ここで、各入力例について、ネットワークはランダムに開始する出力を提供します。  2つの出力の差の2乗と、対応するクラスまたは値の望ましい結果を測定します。 すべてのケーススタディのこれらすべての数値の合計は、一般的なネットワークエラーと呼ばれます。 数値がゼロの場合、ネットワークは理想的です。したがって、エラーが小さいほど、ネットワークは良好です。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     総誤差を最小限に抑える重みを選択すると、最適な方法で問題を解決するニューラルネットワークが得られます。 これは、2つのパラメーターが選択された行を特徴付ける線形回帰と同じです。そのため、行と情報ポイント間の平方差の合計は最小になります。 このような問題は線形回帰で解析的に解くことができますが、非表示要素を持つ単方向ニューラルネットワークには解決策がありません。 ポストバックアルゴリズムでは、エラー、重み、およびしきい値は新しいサンプルが提供されるたびに変化するため、エラーの可能性は徐々に小さくなります。 エラーが変わらないままになるまで、このプロセスは何百回も繰り返されます。 このプロセスの視覚的表現は、上記のNeural Javaサイトでリンク「Multi-layer Perceptron」（ニューロン{0、1}の出力）をクリックして見つけることができます。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     エラーポストバックアルゴリズムでは、数値最適化手法は勾配降下アルゴリズムと呼ばれ、特に数学的計算を簡素化します。 このアルゴリズムは、解くのに役立つ方程式の形式のためにその名前を得ました。 エラーフィードバック伝送を使用する際に調整する必要があるいくつかのトレーニングパラメーター（いわゆる学習率と運動量比）があります。 考慮に値する他の問題もあります。 たとえば、勾配降下アルゴリズムでは、誤差のグローバル最小値の検出が保証されないため、学習結果は重みの初期値に依存します。 ただし、1つの問題が他のすべての問題を覆い隠します。それは再トレーニングの問題です。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     再トレーニングは、ニューラルネットワークに使用可能なパラメーターの数から抽出できるパラメーターが多すぎる場合、つまり、複数のポイントが自由パラメーターが多すぎる関数に対応する場合に発生します（図1d）。 これらのすべての方法が分類と回帰の両方に適しているという事実にもかかわらず、ニューラルネットワークは通常、再パラメーター化の傾向があります。 たとえば、この問題を解決するための10個の非表示要素を持つネットワークには、221個のパラメーターがあります。20個の非表示の重みとしきい値、および出力での10個の重みとしきい値です。 これは、100の例から抽出できるパラメーターが多すぎます。 トレーニングデータに適しているネットワークでは、トレーニング以外の出力を一般化することはできません。 ネットワークの再トレーニングを制限する方法は多数あります（小規模なネットワークの作成を除く）が、最も一般的な方法には、複数のネットワークでの平均化、ベイジアン統計法の正規化および使用が含まれます。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     ニューラルネットワークのパフォーマンスを評価するには、ネットワークのトレーニング中に使用されなかった独立したデータでニューラルネットワークをテストする必要があります。 通常、クロスチェックが実行され、データセットは、たとえば同じサイズの複数のセットに分割されます。 次に、ネットワークは9セットでトレーニングされ、10日でテストされます。この操作は10回繰り返され、すべてのセットがテストに使用されます。 これにより、ネットワークの一般化能力、つまりネットワークがトレーニングされていない入力を分類する能力の評価が得られます。 非常に重要な客観的な評価を得るために、個別のセットに同様の例を含めるべきではありません。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4> 拡張機能とアプリケーション </h4>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      1つのブロックを備えた単純なパーセプトロンと複数のデバイスを備えた多層ネットワークの両方を簡単に一般化して、出力値を追加するだけで3つ以上のパラメーターを予測できます。 分類問題は、バイナリ出力のセットでエンコードできます。 上記の例では、たとえば、3つの異なる治療法があると想像できます。この腫瘍に対して、どの治療法が効果的かを知りたいです。 この問題は、同じタイプの隠れユニットに接続されている3つの出力要素を使用することで解決できます。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     ニューラルネットワークは、科学、医学、技術のさまざまな分野で多くの興味深い問題に使用され、場合によってはハイテクソリューションを提供します。 ニューラルネットワークは、単純な方法でより良い結果が得られるタスクに誤って使用されることがあり、それによって一部の科学者の間でANNの評判が悪くなりました。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     ここで説明されていない他のタイプのニューラルネットワークがあります。 たとえば、ボルツマンマシン、非制御ネットワーク、Kohonenネットワーク。  ANNに密接に関連するベクターマシンのサポート。 より詳細な知り合いについては、Chris Bishopの本、私の共著者の古い本、Dudの本などをお勧めしますANNを作成するために使用できる多くのプログラムは、独自のデータでトレーニングされています。 これらには、Microsoft Excell、Matlab、およびR（ <a href="http://www.r-project.org/">http://www.r-project.org/</a> ）の拡張機能とプラグイン、およびコードライブラリと大規模な商用パッケージが含まれます。  FANNライブラリ（ <a href="http://leenissen.dk/fann/">http://leenissen.dk/fann/</a> ）。これは、深刻なアプリケーションに使用されます。  Cのオープンソースコードで満たされていますが、たとえばPerlやPythonプログラムから呼び出すことができます。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4> さらに読む </h4>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      1.ミンスキー、ML＆ペーパー、SAパーセプトロン（MIT Press、ケンブリッジ、1969）。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      2.ルメルハート、DE、ヒントン、GE＆ウィリアムズ、RJ Nature 323、533-536（1986）。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      3. Sejnowski、TJ＆Rosenberg、CR Complex Systems 1、145-168（1987）。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      4. Qian、N.＆Sejnowski、TJJ Mol。 バイオ  202、865–884（1988）。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      5.アンダーソン、JA＆ローゼンフェルド、E。（編）。 ニューロコンピューティング：研究の基礎（MIT Press、ケンブリッジ、1988年）。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      6. Bishop、CM Neural Networks for Pattern Recognition（Oxford University Press、オックスフォード、1995）。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      7.ノーブル、WS Nat。 バイオテクノロジー。  24、1565-1567（2006）。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      8.ビショップ、CMパターン認識および機械学習（Springer、ニューヨーク、2006年）。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      9. Hertz、JA、Krogh、A。、およびPalmer、R。神経計算理論入門（Addison-Wesley、Redwood City、1991）。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      10. Duda、RO、Hart、PE＆Stork、DGパターン分類（Wiley Interscience、ニューヨーク、2000年）。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     記事の翻訳（Anders Krogh NATURE BIOTECHNOLOGY VOLUME 26 NUMBER 2 FEBRUARY 2008） </div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../J134992/index.html">DonateMe Donation Collection（パートI）</a></li>
<li><a href="../J134993/index.html">Android Ice Cream Sandwichを離れる理由</a></li>
<li><a href="../J134994/index.html">GithubがJenkins Continuous Integration Serverをリリース</a></li>
<li><a href="../J134996/index.html">明けましておめでとうございます！</a></li>
<li><a href="../J134997/index.html">CMS、競争、開発について</a></li>
<li><a href="../J134999/index.html">Windows 7 x64の重大な脆弱性：BSODおよびシステムの侵害</a></li>
<li><a href="../J13500/index.html">ソニーは世界で最も強力な砂糖電池を作成しました</a></li>
<li><a href="../J135000/index.html">Scalaxyの問題</a></li>
<li><a href="../J135001/index.html">関数呼び出しイベントのエミュレーション</a></li>
<li><a href="../J135004/index.html">Lexand LT-115およびLexand LT-117電子マルチメディアリーダー</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter70218013 = new Ya.Metrika({
                  id:70218013,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/70218013" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'G-FEDBM7F51Q', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Clever Geek | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <div class="company-info js-company-info" itemscope="" itemtype="http://schema.org/Organization">
      <span itemprop="name">Western Town Media (WTM)</span>
      <div itemprop="address" itemscope="" itemtype="http://schema.org/PostalAddress">
        <span itemprop="streetAddress">1968 Stoney Lonesome Road</span>
        <br>
        <span itemprop="postalCode">PA 18640</span>
        <span itemprop="addressLocality">Pittston, USA</span>
      </div>
      <span itemprop="telephone">570-362-1316</span>
    </div>
    <script type="application/ld+json">
      {
        "@context": "http://schema.org",
        "@type": "Organization",
        "address": {
          "@type": "PostalAddress",
          "addressLocality": "Pittston, USA",
          "postalCode": "PA 18640",
          "streetAddress": "1968 Stoney Lonesome Road"
        },
        "name": "Western Town Media (WTM)",
        "telephone": "570-362-1316"
      }
    </script>
  </div>
</footer>
  
</body>

</html>