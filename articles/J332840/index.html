<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-FEDBM7F51Q"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-FEDBM7F51Q');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👨🏿‍🍳 👩🏻‍🚀 🖲️ ビデオの自動テキスト認識 👩🏻‍🤝‍👨🏾 🚞 🔬</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="この記事は、ドイツのマンハイム大学Rainer LinhartとFrank Stueberによる記事「デジタルビデオでの自動テキスト認識」の翻訳です。 
  
 
  
  短いレビュー  
  
 序文、キャプション、結論からテキストを抽出する映画のキャラクターの自動セグメンテーションのアルゴリズ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <link rel="sitemap" type="application/xml" href="/sitemap.xml"/>

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>

  <script>document.write('<script src="https://pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://tech-in-japan.github.io/index.html"></a>
    <div class="page-header-text">Clever Geek Handbook</div>
  </header>
  <section class="page js-page"><h1>ビデオの自動テキスト認識</h1><div class="post__text post__text-html js-mediator-article" id="post-content-body" data-io-article-url="https://habr.com/ru/post/332840/">  <i>この記事は、ドイツのマンハイム大学Rainer LinhartとFrank Stueberによる記事「デジタルビデオでの自動テキスト認識」の翻訳です。</i> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h2> 短いレビュー </h2>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     序文、キャプション、結論からテキストを抽出する映画のキャラクターの自動セグメンテーションのアルゴリズムを開発しています。 当社のアルゴリズムは、ビデオの標準テキスト文字を使用して、セグメンテーションの品質を改善し、その結果、認識効率を向上させます。 その結果、フレームから個々のキャラクターができました。  OCRソフトウェアを使用して分析できます。 後続のすべてのフレームの同じシンボルのいくつかのインスタンスの認識結果は、認識の品質を改善し、最終結果を計算するために結合されます。 テレビから録画したビデオクリップを使用した一連の実験でアルゴリズムをテストし、良好なセグメンテーション結果を達成しました。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <a name="habracut"></a>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h2> エントリー </h2>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     マルチメディアの時代において、ビデオは情報を送信するためのますます重要かつ一般的な方法になりつつあります。 ただし、現在のビデオデータのほとんどは構造化されていません。つまり、ピクセルとしてのみ保存および表示されます。 ビデオのコンテンツに関する追加情報はありません：リリース年、キャスト、監督、衣装、撮影場所、シーン内の休憩の位置や種類など、未処理のビデオを使用する利便性は制限されており、効率的で生産的な検索を除外しています。 現在、インターネットには何千ものMPEGビデオがあります。 名前や簡単な説明以外に、これらの映画の内容や構造に関する情報を見つけることはめったに不可能であるため、たとえば特定の目に見えるシーンの検索は重大な作業です。 私たちは皆、現在よりも動画コンテンツに関するより詳細な情報を受け取りたいと思っています。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     通常、この情報は手動で記述する必要がありますが、ビデオの手動注釈は非常に高価で時間がかかります。 したがって、コンテンツに基づく情報の検索と表示では、インデックス作成のための自動ビデオ分析ツールが必要になります[2] [15] [16] [17] ビデオに関する重要な情報源の1つは、ビデオに含まれるテキストです。 キャラクタの自動セグメンテーションとビデオでの認識のためのアルゴリズムを開発しました。 これらのアルゴリズムは、序文、キャプション、および結論からテキストを自動的かつ確実に抽出します。 アルゴリズムは、ビデオタイトルジェネレーターまたは同様のデバイスおよび/または方法によって作成されたビデオのテキストの典型的な特性を明示的に使用して、セグメンテーションの品質を改善し、結果として認識効率を改善します。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     記事の残りの部分は次のように構成されています。 セクション2では、ビデオのテキストセグメンテーションとテキスト認識に関する同様の作業について説明します。 次に、フィルムに表示される文字とテキストの機能について説明します。セクション4では、セクション3で指定された文字の特性に基づいて、候補領域をセグメント化する特性ベースのアプローチを示します。セクション5では、認識アルゴリズムについて説明します。 以下は、セクション6のアルゴリズムの実装に関する情報です。セクション7では、経験的な結果を、アルゴリズムが良好なセグメンテーション結果につながる証拠として提示します。 最後に、作業の概要と将来の作業の見通しを示して作業を終了します。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h2> 関連作品 </h2>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     現在、テキスト認識に関する既存の作業は、主に印刷および原稿の光学文字認識に焦点を当てています。オフィスオートメーションシステムや市場向けの文書読み取りデバイスに対する大きな需要があるためです。 これらのシステムは高度な成熟度に達しています[6]。 また、テキスト認識作品は、産業用アプリケーションで見つけることができます。 これらの作品のほとんどは、非常に狭い範囲に焦点を当てています。 例は、自動車のナンバープレートの自動認識です[13]。 提案されたシステムは、背景がほとんどモノクロであり、その位置が制限されているシンボル/数字に対してのみ機能します。 さらに、ビデオに表示されるテキスト内の文字の認識に関する小さな作品が公開されました。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Michael A. SmithとTakeo Canadaは[12]で、テキスト情報を含むビデオフレームから領域を抽出することに焦点を当てた方法を簡単に説明しています。 ただし、標準の光学式文字認識ソフトウェア用に検出されたテキストを準備しません。 特に、キャラクターのアウトラインを定義したり、個々のキャラクターをセグメント化しようとはしません。 テキストを含むビットマップをそのまま保存します。 人々は自分でそれらを分解しなければなりません。 彼らはテキストを「グループ化された鋭いエッジの水平長方形構造」[12]として特徴づけ、この機能を使用してテキストセグメントを識別します。 充填段階のアプローチでもこの関数を使用します。 彼らのアプローチとは異なり、この関数は、候補領域のセグメント化のプロセスで小さな役割しか果たしません。 また、異なる条件下で複数のインスタンスを使用して、セグメンテーションと認識の効率を高めます。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     シーン画像でのテキスト認識に対する別の興味深いアプローチは、大谷ya、塩昭夫、赤松茂によって使用されています。 シーン画像のシンボルは、さまざまなノイズ成分の影響を受ける場合があります。 シーン画像のテキストは3次元空間に存在するため、回転、傾斜、部分的に非表示および/または暗くなり、制御されない照明下に置かれる可能性があります[7]。 テキストキャラクターの多くの可能な自由度を考慮して、Ohya et al。は、検出を容易にするために、それらをほぼ垂直、単色、非連結に制限しました。 これにより、Okhya et al。のアプローチは、ビデオストリームではなく静止画像に焦点を当てているため、ビデオに表示されるテキストの典型的な特性を使用しないという事実にもかかわらず、私たちの目的に適しています。 さらに、シーンテキストではなく、ビデオタイトルジェネレーターによって作成されたテキストに注目します。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h2> キャプションおよび開始テキストと終了テキストの文字の機能 </h2>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     ビデオのテキストはさまざまな目的に使用されます。放送の開始時および/または終了時に、彼はその名前、監督、俳優、プロデューサーなどについて視聴者に知らせます。 ブロードキャストテキストは、現在取り上げられている主題に関する重要な情報も提供します。 たとえば、スポーツブロードキャストのテキストはしばしば結果を報告しますが、ニュースリリースやドキュメンタリーでは、スピーカーの名前と場所、および/またはトピックに関する重要な情報が取り上げられました。 広告のテキストは、スローガン、製品または会社の名前を伝えます。 これらのテキスト表現には、明確に指示されているという共通点があります。 それらはちょうどそのように表示されません-それらはフレームに重ねられ、読まれるように作成されます。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     さらに、テキストはその一部としてシーンに表示することもできます。たとえば、ショッピングセンターのビデオでは、多くの店名がビデオに表示されます。 ビデオ内のこのようなテキストは、検出または認識が困難であり、任意の角度で、歪みがあり、任意の光の下で、まっすぐまたは波状の表面にあります（たとえば、Tシャツのテキスト）。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     この記事ではシーンテキストを使用していませんが、特にビデオタイトルジェネレーターを使用して、ビデオに人為的に追加されたテキストのみに焦点を当てています。 その理由は、シーンの上にオーバーレイされるテキストは、シーンに含まれるテキストと根本的に異なるため、同時に2つの異なる問題に対処したくなかったからです。 したがって、将来、「テキスト」および「シンボル」という言葉は、機械または同様のデバイス/方法によって作成されたビデオタイトルのみを指します。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     単語やテキストを認識できるようになる前に、それらの外観の特徴を分析する必要があります。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     リストには以下が含まれます。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <ul><li> プレーンキャラクター。 非常に小さな割合だけが色を持っているため、このパラメーターはあまり重要ではありません。 </li><li> キャラクターは大変です。 フレームごとに形状、サイズ、方向を変更することはありません。 繰り返しますが、サイズ変更の文字の割合はそれほど高くないので、私たちにとっても興味がありません。 </li><li> 文字にはサイズ制限があります。 文字はフレーム全体ほど大きくなく、特定のピクセル数よりも小さくなります。そうしないと、文字が読みにくくなります。 </li><li> シンボルは動かないか、直線的に動きます。 静止キャラクターは移動せず、それらの位置はいくつかの後続フレームで固定されたままです。 動くキャラクターは絶えず動いており[3]、一定の動きの方向を持っています。原則として、キャラクターは水平または垂直に動きます。 さらに、移動するテキストのほとんどは、右から左または下から上に移動します。 </li><li> シンボルは背景と対照的です。 人工テキストは読むことを目的としているため、背景と区別できる必要があります。 しかし、後で見るように、テレビ信号の帯域幅が狭いため、この項目はすべてのキャラクター回路に保存されるわけではありません。 </li><li> 同じ文字が複数の連続したフレームに表示されます（時間比率）。 </li><li> シンボルは、限られた距離でクラスター（行）に表示され、水平方向に整列（空間関係）します。これは、これが単語や文章を書く自然な方法だからです。 しかし、これは前提条件ではなく、単なる明確な指標です。  1行に1文字しか表示されない場合があります。 </li><li> 文字/境界回路の品質は、最新のテレビ技術とデジタルコンバーターボードにより低下しています。 多くの場合、シンボルは、特に左側で背景と混合されます。 普通の文字はこれらのように見えなくなりました。 色は非常に濁っていて、たとえば周囲の背景の色と混ざることで、時折空間と時間でわずかに変化します。 静止テキストでも数ピクセル移動することがあります。 これらは典型的な古いアナログテレビとビデオ録画です。 </li></ul>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     セグメンテーションとテキスト認識の（人工的な）方法は、これらの観察された機能に基づいている必要があります。 次に、それらの使用について説明します。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h2> 候補文字領域の分離 </h2>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     理論的には、セグメンテーションパスは、ビデオに表示されるテキストに属するすべてのピクセルを抽出します。 ただし、これはどこの文字を知っていない限り実行できません。 したがって、セグメンテーションステップの最終目標は、ビデオの各フレームのピクセルを2つのクラスに分割することです。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <ul><li> テキストを含む領域 </li><li> テキストを含まない領域。 </li></ul>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     テキストを含まない領域は認識プロセスに貢献できないため破棄され、テキストを含む可能性のある領域は保持されます。 それらは（完全ではない）シンボル領域のスーパーセットであるため、それらを候補領域と呼びます。 それらは評価のために認識段階に転送されます。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     ここでは、セグメンテーションプロセスについて説明します。  3つの部分に分割できます。各部分は、テキストを含まない他の領域によって前の部分の文字のない領域のセットを増やし、候補領域を減らして、記号のある領域にますます近づけます。 まず、各フレームを他のフレームとは独立して処理します。 次に、連続するフレームで同じテキストの複数のインスタンスを活用しようとします。 最後に、各フレームの残りの領域のコントラストを分析して、候補領域の数をさらに減らし、最終的な候補領域を構築します。 各パートでは、セクション3で説明されているように、シンボル関数を使用します。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h3> 単一フレームの候補領域の文字セグメンテーション </h3>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4> 一色 </h4>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     元のフレームから始めましょう（図1）。 単色の文字が想定されているため、処理の最初の段階でフレームをグレースケールの均一なセグメントに分割します。  Horowitz and Pavlidis [4]によって提案された「Separation and Merge」アルゴリズムを使用してセグメンテーションを実行します。 フレームの階層的な分解に基づいています。  Horowitz and Pavlidisによると、分離プロセスは、画像全体を最初のセグメントとして開始し、その後、それを4分の1に分割します。 各四半期は、セグメントが「十分に均質」かどうかを判断するために、特定の均一性基準についてテストされます。 均一性が十分でない場合、セグメントは再び四半期に分割されます。 このプロセスは、同種のセグメントのみが残るまで再帰的に適用されます。 標準的な均一性基準を使用します。最高と最低のグレートーン強度の差は、特定のしきい値を下回る必要があります。 しきい値をmax_split_distanceと呼びます。 同種セグメントには、その平均グレーレベルが割り当てられます。 次に、マージのプロセスで、グレートーンの平均レベルの強度がパラメーターmax_merge_distanceより小さい場合、隣接するセグメントが一緒に結合されます。 その結果、画像に表示されるすべてのモノクロシンボルは、一部のモノクロセグメントに含まれている必要があります。 サンプルフレームの場合、「Split and Merge」アルゴリズムは図2に示す画像を表示します。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4> サイズ制限。 </h4>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     セグメント化された画像は、均一なグレートーン強度の領域で構成されています。 一部のエリアは大きすぎますが、他のエリアは小さすぎてキャラクターのインスタンスにはなりません。 結果として、単色セグメントの幅と高さはmax_sizeを超えます。これは、接続されたモノクロセグメントの合計サイズがmin_sizeより小さいためです。 画像の例を図3に示します（削除されたセグメントは黒になります）。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://pp.userapi.com/c638231/v638231513/6e403/NNwewAJlPyg.jpg" alt="画像">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      <i>図1.元のフレーム</i> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://pp.userapi.com/c638231/v638231513/6e40a/CN_0Uqd0MZs.jpg" alt="画像">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      <i>図2. Split and Mergeメソッドを使用した図1</i> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h3> シーケンシャルフレームに基づく高度なシーケンス </h3>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     ビデオタイトルジェネレーターで作成されたビデオのテキストを分析するため、通常、連続するフレームの数に同じテキストが表示されます。 明らかに、テキストの各文字は、ノイズ、背景の変化、および/または位置の変化のためにフレームごとにわずかに変化するため、同じテキストのこれらの複数のインスタンスを使用してセグメンテーションの結果を改善できます。 したがって、連続するフレームで候補領域の対応するシンボルを検出する必要があります。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4> 運動解析 </h4>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     セクション3で既に述べたように、ここで考慮されるテキストは静止または直線移動のいずれかであり、静止テキストでさえ、フレームからフレームへ元の位置を中心に数ピクセル移動できます。 したがって、モーション分析を実行して、連続するフレームで対応する候補領域を検出する必要があります。 ブロックマッチングはハードオブジェクトに適しているため、動きはブロックマッチングを使用して評価されます。キャラクターの形状、向き、色が変わらない場合、キャラクターはハードと見なされます。 さらに、ブロックマッチングは非常に人気があり、H.261やMPEG3などの国際的なビデオ圧縮規格で動きを補正するために使用されます。 コンプライアンス基準は、絶対差の最小平均基準です[14]。 平均絶対差（MAD）は次のように定義されます 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://pp.userapi.com/c638231/v638231513/6e412/k6Yk-t-j9SQ.jpg" alt="画像">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Rは、平行移動ベクトルが計算されるブロックを示します。 バイアス推定 <img src="https://pp.userapi.com/c638231/v638231513/6e419/5atYXu4OLys.jpg" alt="画像">  forブロックRはオフセットとして指定され、MAD値は最小です。 検索範囲は制限されています。 <img src="https://pp.userapi.com/c638231/v638231513/6e420/9DrgVbz-Gek.jpg" alt="画像"> スクロール可能なタイトルの速度に続きます。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     次の質問は、動き推定に使用されるブロックの位置とサイズを決定する方法です。 明らかに、オフセット推定の品質は、シーケンシャルフレームのインスタンスと一致させようとしているブロックの位置とサイズに依存します。 たとえば、選択したブロックが大きすぎる場合、ブロックの一部がフレームを離れる可能性があるため（スクロールリストで発生する可能性がある）、または次のフレームのブロックの一部が背景として正しく認識されるため、アルゴリズムが同等のブロックを見つけることができない場合がありますそれらは除外されず、候補エリアの一部のままでした。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     これらの問題を回避するために、文字が単語として表示されるため、行に配置されるという事実を利用します。 次のアルゴリズムを使用してRブロックを選択します。入力画像は2色に変換されます（背景=黒、残り=白）。 そして、各白いピクセルは、指定された半径の円に拡大します。 図4からわかるように、記号と単語がコンパクトな領域を構成しています。 接続された各クラスターを長方形で構成し、ブロックRとして定義します。曲線因子が特定のしきい値を超える場合、そのブロックを使用して動きを分析します。 フィルファクタが特定のしきい値を下回る場合、結果のブロックのフィルファクタがしきい値を超えるまで、ブロックは再帰的に小さなブロックに分割されます。 必要なデューティサイクルに対応する結果ブロックごとに、動きのブロック分析が実行されます。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://pp.userapi.com/c638231/v638231513/6e427/YkIckCIp4ag.jpg" alt="画像">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      <i>図3.図2のサイズ制限の適用</i> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://pp.userapi.com/c638231/v638231513/6e43b/2ZJAvZqRhnQ.jpg" alt="画像">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      <i>図4：2色のフレームに変換してストレッチした後の図3。</i>  <i>ブロックは長方形でマークされています。</i> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     同等のブロックは、次のフレームで破棄されます。 さらに、後続のフレームで同等のブロックを持っているが、それらの平均グレートーン強度に大きな違いを示すブロックは破棄されます。 結果の画像は、セグメンテーションの次の段階に送信されます（図5）。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://pp.userapi.com/c638231/v638231513/6e451/m1Hr_NKkliU.jpg" alt="画像">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      <i>図5：図3の2つの連続したフレームにモーション分析を適用した後の画像結果</i> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h3> コントラスト分析を使用した候補領域のセグメンテーションの改善 </h3>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4> コントラスト分析 </h4>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     ビデオタイトルジェネレーターによって作成されたシンボルは、通常、背景と対照的です。 したがって、これは候補地域の前提条件でもあります。 そのため、前のセグメンテーション手順で残った各領域をチェックして、その輪郭が背景やその他の残りの領域と部分的に強く対比しているかどうかを確認します。 特に文字の下にあることが多い暗い影は、読みやすさを向上させるために、文字の領域とその環境の一部の間に非常に強いコントラストをもたらすはずです。 そのようなコントラストが領域で見つからない場合、シンボルに属することができないと結論付け、領域を破棄します。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     コントラスト分析は、次の処理キューによって実行されます。Cannyの境界のマップを計算し（1）、非常に高いしきい値（canny_thresholdと呼ばれる）を適用して、鋭いエッジへの応答を制限します。 結果のエッジ画像は、dilation_radiusを使用して展開されます。 次に、モーション分析のセグメンテーションセグメントの領域は、拡張されたエッジと交差しない場合は破棄されます。 この例では、図6に示す結果になります。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4> デューティ比と幅と高さの比 </h4>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     上記のモーション分析セクションで説明したように、ブロックとそれぞれのフィルファクターは、残りの各候補領域に対して再度計算されます。 フィルファクタが低すぎる場合、対応する領域は破棄されます。 次に、ブロックの幅と高さの比率が計算されます。 特定の制限を超える場合、つまり  min_ratioとmax_ratioの間にない場合、対応する領域も破棄されます。 このプロセスにより、セグメンテーションの最終イメージが得られます。 図7は、例示的なビデオフレームのこれを示しています。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4> セグメンテーション結果 </h4>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     これまで、各フレームの候補シンボル領域が抽出されました。 リージョンは新しいフレームに保存されるため、新しいビデオが作成されます。 これらのフレームでは、候補領域に属するピクセルは元のグレーレベルを保持します。 他のすべてのピクセルは背景としてマークされます。 セグメンテーションが完了し、標準のOCRソフトウェアを使用して新しいビデオをフレームごとに分析できます。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://pp.userapi.com/c638231/v638231513/6e458/TBNBmee_Yho.jpg" alt="画像">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      <i>図6：図5のコントラスト分析後の結果</i> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://pp.userapi.com/c638231/v638231513/6e45f/ylECrmpRQjc.jpg" alt="画像">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      <i>図7：最終的なセグメンテーション</i> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h2> 文字認識 </h2>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     セグメンテーションは、候補者のエリアを示すビデオを提供します。 文字認識では、各フレームをOCRソフトウェアで分析する必要があります。  [11]で説明されているように、ベクトル特性を持つオブジェクトの分類アプローチを使用して、独自のOCRソフトウェアを実装しました。 ただし、このソフトウェアは完全にはほど遠いため、商用ソフトウェアパッケージを使用すると、認識率が高くなります。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     ビデオを分析すると、各キャラクターがいくつかの連続したフレームに表示されます。 したがって、同じ文字のすべての認識インスタンスを1つの認識結果に結合する必要があります。 セクション4.2で説明されているように、対応するシンボルとシンボルのグループはモーション分析によって識別されます。 したがって、複数の独立した認識結果を同じ文字と単語に関連付けることができます。 最も一般的な結果は、認識の最終結果です。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h2> 実装 </h2>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     セグメンテーションアルゴリズムは、Solaris 2.4ではSUN SPARCstation 5、Cコードは2300行のDigital Unix 3.2ではDEC ALPHA 3000に実装されていましたが、MoCA Workbench5の一部であり、Vista 1.3ライブラリが必要です。 Cの1200行のCコードで、14種類のポストスクリプトフォントでトレーニングされています。 ただし、文字認識プロセスの2番目の部分、つまり、すべてのテキスト認識結果を1つの最終テキスト出力に結合する作業はまだ進行中であり、まもなく完了する予定です。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h2> 実験結果 </h2>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     デジタルビデオの8つのサンプルでセグメンテーションアプローチをテストしました。 ビデオデータは、品質係数508、サイズ384 x 288ピクセル、14フレーム/秒の24ビットJPEG画像の形式で、ドイツおよび国際的なテレビ放送からデジタル化されました。 すべてのJPEG画像はグレースケール画像としてのみデコードされました。 次のクラスごとに2つのサンプルがあります。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <ul><li> 静止したテキスト、静止したシーン。 </li><li> 静止テキスト、動くシーン。 </li><li> 動くテキスト、動きのないシーン。 </li><li> テキストの移動、シーンの移動。 </li></ul>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     テキストの移動とは、たとえば、テキストがシーン内を移動することです。 ボトムアップまたは右から左。 同様に、動いているシーンとは、動きが非常に大きいシーン、またはより一般的に知られている非常に強い変化があるシーンを指します。 静止シーンは、静止画像または非常に静的なシーン（ニュースリリースのコラムシーンなど）です。 固定テキストは固定位置のままです。 さらに、ビデオサンプルの文字は、サイズ、色、形が異なります。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     実験では、次のパラメーターに次の値を使用しました 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <ul><li>  <i>max_split_distance</i> = 30; </li><li>  <i>max_merge_distance</i> = 30; </li><li>  <i>max_size</i> = 70ピクセル; </li><li>  <i>min_size</i> = 5ピクセル; </li><li>  <i>search_area</i> = 20ピクセル。 </li><li>  <i>拡張半径</i> = 3ピクセル。 </li><li>  <i>fill_faktor_threshold</i> = 0.7（セクション4.2）および0.3（セクション4.3）。 </li><li>  <i>canny_threshold</i> = 80; </li><li>  <i>min_ratio</i> = 0および<i>max_ratio</i> = 6 </li></ul>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     実験結果は表1にあります。最初の列はビデオのタイプを決定し、その後にフレームで測定されたビデオの長さが続きます。  3番目の列には、対応するビデオサンプルの実際の文字数が含まれています。 ビデオサンプルに表示されるビデオタイトルのテキスト全体と文字カウントを記録することで測定されます。 したがって、文字番号は、すべてのフレームに表示される文字の数の合計によってビデオのテキストを参照しません。  4番目の列は、セグメンテーションアルゴリズムに従って候補領域としてセグメント化された文字の数と割合を示します。<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">実験のセグメンテーション効率は常に86％から100％と非常に高く、したがって、アルゴリズムの品質に関する実験データを提供します。動いているテキストや動いているシーンを含むビデオサンプルの場合、セグメンテーションパフォーマンスは97％から100％の範囲です。これらのパフォーマンス測定は、当社のアプローチと一致しています。同じキャラクターのすべてのインスタンスが同じ背景を持っているため、静止テキストの静止シーンの複数のインスタンスの恩恵を受けることはできません。したがって、セグメンテーションパフォーマンスは低下します。</font></font>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <font style="vertical-align: inherit;"><font style="vertical-align: inherit;">8本のビデオクリップを見ることに興味のある読者</font><a href="http://www.informatik.uni-mannheim.de/~lienhart/MoCA_TextRecognition/"><font style="vertical-align: inherit;">は、ここから</font></a><font style="vertical-align: inherit;">抜け出すことができ</font></font><a href="http://www.informatik.uni-mannheim.de/~lienhart/MoCA_TextRecognition/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ます。</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。ここでは文字のセグメンテーションのみを扱っているため、認識プロセスの候補領域の文字の品質はここでは評価できません。このような評価はOCRソフトウェアと組み合わせてのみ実行でき、今後の実験で調査する必要があります。</font></font>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <font style="vertical-align: inherit;"><font style="vertical-align: inherit;">セグメンテーションプロセスでのもう1つの重要な品質要因は、各ピクセルの平均縮小率です。これにより、セグメンテーションプロセスでの関連ピクセル数の削減が決定され、認識プロセスの作業負荷が軽減されます。さらに、縮小率が高いほど、文字候補領域の一部である非文字領域が少なくなり、OCRソフトウェアの誤認識が減少します。平均削減率が決定されます</font></font>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://pp.userapi.com/c638231/v638231513/6e46c/RkBUr9afZ14.jpg" alt="画像">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <font style="vertical-align: inherit;"><font style="vertical-align: inherit;">表1の最後の列は、ビデオサンプルのフレームあたりの文字数を示しています。</font><font style="vertical-align: inherit;">これは、平均削減率と相関しています。</font></font>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <table border="1"><caption><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 表1.セグメンテーションの結果 </font></font></caption><tbody><tr><th><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ビデオの種類 </font></font></th><th><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> フレーム </font></font></th><th><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> キャラクター </font></font></th><th colspan="2"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> これらのうち、候補エリアに含まれる </font></font></th><th><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 減らす </font></font></th><th><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> フレーム内のキャラクター </font></font></th></tr><tr><td> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">静止テキスト、静止シーン</font></font></b> </td><td>  400 </td><td>  137 </td><td>  131 </td><td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 96％ </font></font></td><td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 0.058 </font></font></td><td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 0.34 </font></font></td></tr><tr><td> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">静止テキスト、静止シーン</font></font></b> </td><td>  400 </td><td>  92 </td><td>  79 </td><td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 86％ </font></font></td><td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 0,028 </font></font></td><td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 0.23 </font></font></td></tr><tr><td> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">静止したテキスト、動くシーン。</font></font></b> </td><td>  116 </td><td>  21 </td><td>  21 </td><td>  100％ </td><td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 0,035 </font></font></td><td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 0.18 </font></font></td></tr><tr><td> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">静止したテキスト、動くシーン。</font></font></b> </td><td>  400 </td><td>  148 </td><td>  144 </td><td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 97％ </font></font></td><td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 0,037 </font></font></td><td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 0.36 </font></font></td></tr><tr><td> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">テキストの移動、静止シーン</font></font></b> </td><td>  139 </td><td>  264 </td><td>  264 </td><td>  100％ </td><td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 0,065 </font></font></td><td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 1.90 </font></font></td></tr><tr><td> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">テキストの移動、静止シーン</font></font></b> </td><td>  190 </td><td>  273 </td><td>  273 </td><td>  100％ </td><td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 0,112 </font></font></td><td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 1.44 </font></font></td></tr><tr><td> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">テキストの移動、シーンの移動</font></font></b> </td><td>  202 </td><td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 373 </font></font></td><td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 372 </font></font></td><td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 99.7％ </font></font></td><td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 0.130 </font></font></td><td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 1.85 </font></font></td></tr><tr><td> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">テキストの移動、シーンの移動</font></font></b> </td><td>  400 </td><td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 512 </font></font></td><td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 512 </font></font></td><td>  100％ </td><td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 0,090 </font></font></td><td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 1.28 </font></font></td></tr></tbody></table>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <font style="vertical-align: inherit;"><font style="vertical-align: inherit;">アルゴリズムの安定性の経験的証拠を示すために、テキストなしの9番目のビデオサンプルでテストしました。ビデオサンプルは500フレームで構成され、平均削減率は0.038でした。この値は、テキストを含むビデオサンプルで見られる値と比較して非常に低い値です。したがって、このアルゴリズムは、テキストをほとんどまたはまったく含まないシーンを検出することもできます。しかし、最終決定はOCRツールにかかっています。一部の読者は、シーンの一部としてのテキストについてはどうでしょうか？これは、アルゴリズムの実験結果を歪めますか？一般に、シーンテキストは抽出されません。ただし、人工テキストと同じ機能がある場合は抽出されます。これは通常、同様のタスクのビデオで使用されるシーンテキストで発生します。人工テキストなど。たとえば、近距離の都市名のスナップショット。</font></font>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 結論と展望 </font></font></h2>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <font style="vertical-align: inherit;"><font style="vertical-align: inherit;">序文、キャプション、およびクロージングワードのテキストを自動的かつ確実に抽出する動画の文字の自動セグメント化アルゴリズムを導入しました。</font><font style="vertical-align: inherit;">合計2247フレームで構成されるデジタルビデオの8つのサンプルの実験結果は、非常に有望です。</font><font style="vertical-align: inherit;">当社のアルゴリズムは、デジタルビデオサンプルに追加されたすべてのテキスト画像の86％から100％を抽出しました。</font><font style="vertical-align: inherit;">動いているテキストや動いているシーンを含むビデオサンプルの場合、セグメンテーションパフォーマンスは97％から100％の範囲です。</font><font style="vertical-align: inherit;">結果の候補領域は、標準のOCRソフトウェアで簡単に分析できます。</font><font style="vertical-align: inherit;">当社の認識アルゴリズムは、同じ文字のすべての認識インスタンスを単一の認識結果に結合します。</font></font>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <font style="vertical-align: inherit;"><font style="vertical-align: inherit;">現在、当社のアルゴリズムはグレースケール画像を処理しています。これにより、たとえば、灰色がかった青色の背景に黄色のテキストを検出することが難しくなります。これらの色はグレースケールの画像と対照的ではないためです。したがって、この方法では、このようなテキストを確実にセグメント化できませんでした。今後の計画では、対応する色空間のカラー画像を処理するアルゴリズムを拡張し、これらのカラー画像のコントラストを計算します。</font></font>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <font style="vertical-align: inherit;"><font style="vertical-align: inherit;">将来的には、自動ビデオアブストラクションシステムにテキストセグメンテーションとテキスト認識モジュールを含めて、フィルムの名前とフィルムの最も重要な俳優が抽出に不可欠な部分であるため、それらを抽出できるようにする予定です。</font><font style="vertical-align: inherit;">特定のジャンルは特定のテキストによって特徴付けられるため、パフォーマンスの向上を考慮して、ビデオジャンルの自動認識のためのアルゴリズムもシステムに組み込まれます[2]。</font></font>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <div class="spoiler">  <b class="spoiler_title">参照資料</b> <div class="spoiler_text"> [1] <a href="https://pdfs.semanticscholar.org/55e6/6333402df1a75664260501522800cf3d26b9.pdf">John Canny, “A Computational Approach to Edge Detection”, IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. 8, No. 6, pp. 679-697, Nov. 1986.</a> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     [2] <a href="https://ub-madoc.bib.uni-mannheim.de/805/1/TR-95-006.pdf">Stefan Fischer, Rainer Lienhart, and Wolfgang Effelsberg, “Automatic Recognition of Film Genres”, Proc. ACM Multimedia 95, San Francisco, CA, Nov. 1995, pp. 295-304.</a> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     [3] <a href="http://www.cs.ucsb.edu/~almeroth/classes/W10.290F/papers/legall-acm-91.pdf">DL Gall, “MPEG: A Video Compression Standard for Multimedia Applications”, Communications of the ACM, 34, 4, April 1991.</a> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     [4] SL Horowitz and T. Pavlidis, “Picture Segmentation by a Traversal Algorithm”, Comput. Graphics Image Process.  1、pp。 360-372, 1972. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     [5] <a href="http://www.multimedia-computing.de/mediawiki/images/3/39/1995-tr-95-34.pdf">Rainer Lienhart, Silvia Pfeiffer, and Wolfgang Effelsberg, “The MoCA Workbench”, University of Mannheim, Computer Science Department, Technical Report TR-34-95, November 1996.</a> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     [6] Shunji Mori, Ching Y. Suen, Kazuhiko Yamamoto, “Historical Review of OCR Research and Development”, Proceedings of the IEEE, Vol. 80, No. 7, pp. 1029-1058, July 1992. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     [7] Jun Ohya, Akio Shio, and Shigeru Akamatsu, “Recognizing Characters in Scene Images”, IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. 16, No. 2, pp. 214-220, 1994. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     [8] William B. Pennebaker and Joan L. Mitchel, “JPEG Still Image Data Compression Standard”, Van Nostrand Rheinhold, New York, 1993. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     [9] Arthur R. Pope, Daniel Ko, David G. Lowe, “Introduction to Vista Programming Tools”, Department of Computer Science, University of British Columbia, Vancouver. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     [10] <a href="https://www.semanticscholar.org/paper/Vista-a-software-environment-for-computer-vision-r-Pope-Lowe/0331a58d34bdc668799229329e4f66a8782eecca">Arthur R. Pope and David G. Lowe, “Vista: A Software Environment for Computer Vision Research”, Department of Computer Science, University of British Columbia, Vancouver.</a> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     [11] <a href="https://archive.org/stream/automaticcharact112stev/automaticcharact112stev_djvu.txt">Alois Regl, “Methods of Automatic Character Recognition”, Ph. D. thesis, Johannes Kepler University Linz, Wien 1986 (in German).</a> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     [12] <a href="http://www.informedia.cs.cmu.edu/documents/cmu-cs-95-186.pdf">Michael A. Smith and Takeo Kanade, “Video Skimming for Quick Browsing Based on Audio and Image Characterization”, Carnegie Mellon University, Technical Report CMU-CS-95-186, July 1995.</a> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     [13] <a href="http%253A%252F%252Fpatentimages.storage.googleapis.com%252Fpdfs%252FUS6101274.pdf%26usg%3DAFQjCNFz1JncMz9K9S3Rxdua5-JJcRMIIw">M. Takatoo et al., “Gray Scale Image Processing Technology Applied to Vehicle License Number Recognition System”, in Proc. Int. Workshop Industrial Applications of Machine Vision and Machine Intelligence, pp. 76-79, 1987.</a> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     [14] <a href="http://ptgmedia.pearsoncmg.com/images/9780133991000/samplepages/9780133991000.pdf">A. Murat Tekalp, “Digital Video Processing”, Prentice Hall Signal Processing Series, ISBN 0-13-190075-7, 1995.</a> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     [15] <a href="http://www.cs.cornell.edu/~rdz/Papers/ZMM-MM95.pdf">Ramin Zabih, Justin Miller, and Kevin Mai, “A Feature-Based Algorithm for Detecting and Classifying Scene Breaks”, Proc. ACM Multimedia 95, San Francisco, CA, pp. 189-200, Nov. 1995.</a> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     [16] HJ Zhang, CY Low, SW Smoliar, and JH Wu, “Video Parsing, Retrieval and Browsing: An Integrated and Content-Based Solution”, Proc. ACM Multimedia 95, San Francisco, CA, pp. 15-24, Nov. 1995. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     [17] <a href="http://proceedings.spiedigitallibrary.org/proceeding.aspx%3Farticleid%3D957711">Hong Jiang Zhang and Stephen W. Smoliar, “Developing Power Tools for Video Indexing and Retrieval”, Proc. SPIE Conf. on Storage and Retrieval for Image and Video Databases, San Jose, pp. 140-149, CA, 1994.</a> </div></div></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../J332828/index.html">100万個のニューロンからの記録：新しいDARPAプラン</a></li>
<li><a href="../J332830/index.html">危機の間にモスクワの売上を60％増やす方法は？ ある会社の成功事例</a></li>
<li><a href="../J332832/index.html">BSPツリーを使用してゲームカードを作成する</a></li>
<li><a href="../J332834/index.html">スーパージョブPHP-meetup</a></li>
<li><a href="../J332836/index.html">継続的インテグレーション：CircleCI vs Travis CI vs Jenkins</a></li>
<li><a href="../J332842/index.html">本番環境での継続的な統合と配信のためのGitLab CI。 パート2：困難を克服する</a></li>
<li><a href="../J332844/index.html">国内ネットワークセグメントの持続可能性調査</a></li>
<li><a href="../J332846/index.html">Webアプリケーションの継続的な保護の問題。 研究者およびオペレーターからの眺め。 パート2</a></li>
<li><a href="../J332850/index.html">GraphQLクエリ。 単純なものから複雑なものへ</a></li>
<li><a href="../J332852/index.html">IoTの不十分なセキュリティの5つの主要な側面</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter70218013 = new Ya.Metrika({
                  id:70218013,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/70218013" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'G-FEDBM7F51Q', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Clever Geek | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <div class="company-info js-company-info" itemscope="" itemtype="http://schema.org/Organization">
      <span itemprop="name">Western Town Media (WTM)</span>
      <div itemprop="address" itemscope="" itemtype="http://schema.org/PostalAddress">
        <span itemprop="streetAddress">1968 Stoney Lonesome Road</span>
        <br>
        <span itemprop="postalCode">PA 18640</span>
        <span itemprop="addressLocality">Pittston, USA</span>
      </div>
      <span itemprop="telephone">570-362-1316</span>
    </div>
    <script type="application/ld+json">
      {
        "@context": "http://schema.org",
        "@type": "Organization",
        "address": {
          "@type": "PostalAddress",
          "addressLocality": "Pittston, USA",
          "postalCode": "PA 18640",
          "streetAddress": "1968 Stoney Lonesome Road"
        },
        "name": "Western Town Media (WTM)",
        "telephone": "570-362-1316"
      }
    </script>
  </div>
</footer>
  
</body>

</html>