<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-FEDBM7F51Q"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-FEDBM7F51Q');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü•° üë®üèΩ‚Äçüíº üõ§Ô∏è Quasi-Newton methods, or when there are too many second derivatives for Athos üòì üêΩ ‚ö´Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="When you first get acquainted with quasi-Newtonian methods, you may be surprised twice. First, after a quick glance at the formulas, doubts arise that...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <link rel="sitemap" type="application/xml" href="/sitemap.xml"/>

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>

  <script>document.write('<script src="https://pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://tech-in-japan.github.io/index.html"></a>
    <div class="page-header-text">Clever Geek Handbook</div>
  </header>
  <section class="page js-page"><h1>Quasi-Newton methods, or when there are too many second derivatives for Athos</h1><div class="post__text post__text-html js-mediator-article">  When you first get acquainted with quasi-Newtonian methods, you may be surprised twice.  First, after a quick glance at the formulas, doubts arise that this can work at all.  However, they work.  Further it seems doubtful that they will work well.  And it‚Äôs all the more surprising to see how much faster they are than the various variations of gradient descent, not on specially constructed tasks, but on real ones taken from practice.  And if after this there are still doubts mixed with interest, then you need to understand why this something works at all. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <a name="habracut"></a>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      The origin and basic ideas that drive gradient methods, including the Newton method, have <a href="https://habr.com/ru/post/469877/">already been considered</a> .  Namely, we relied on the information about the behavior of the function in the vicinity of the current position, which gives us a simple mathematical analysis.  At a minimum, it was assumed that information on the first derivatives was available to us.  What if this is all that is available to us?  Is gradient descent our sentence?  Of course, yes, unless you suddenly remember that we are dealing with a <i>process</i> in which the objective function is properly processed.  And if so, why don't we use the accumulated information about the behavior of the function in order to make our walk on its surface a little less blind? 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      The idea of ‚Äã‚Äãusing information about the path covered lies at the heart of most ways to speed up the descent methods.  This article discusses one of the most effective, although not the cheapest, way of accounting for this kind of information, leading to the idea of ‚Äã‚Äãquasi-Newtonian methods. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      In order to understand where the legs of quasi-Newtonian methods grow and where the name comes from, we will again have to return to the minimization method based on the direct solution of the stationary point equation <img src="https://habrastorage.org/getpro/habr/post_images/c43/946/5f9/c439465f905d9f366a2f4b3296306290.gif" title="&quot;\ bigtriangledown f = 0&quot;">  .  Just as the consideration of the Newton method applied to the solution of this equation led us to the optimization method of the same name (which, unlike its progenitor, has a global region of convergence), we can expect that consideration of other methods for solving systems of nonlinear equations will be fruitful in plan ideas for building other optimization methods. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h2>  Secant methods </h2>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Let me remind you that Newton‚Äôs method for solving the system of equations <img src="https://habrastorage.org/getpro/habr/post_images/0a0/ec7/804/0a0ec780406efe57ca6444290ccfde09.gif" title="&quot;F (x) = 0&quot;">  , is based on the replacement in the neighborhood of some point close to the solution <img src="https://habrastorage.org/getpro/habr/post_images/779/0dd/0ef/7790dd0efb4a03a4c876741804d9b559.gif" title="x">  the functions <img src="https://habrastorage.org/getpro/habr/post_images/01a/a15/8fc/01aa158fc8bc3d7f7f3b2807df8b4a5e.gif" title="&quot;F&quot;">  its linear approximation <img src="https://habrastorage.org/getpro/habr/post_images/d15/479/f23/d15479f235f0d60ce8837c9043a0d2cc.gif" title="&quot;L (p) = F (x) + J (x) p&quot;">  where <img src="https://habrastorage.org/getpro/habr/post_images/206/f34/999/206f349991c0724c2fdce788124abe1c.gif" title="&quot;J&quot;">  Is a linear operator, which, when <img src="https://habrastorage.org/getpro/habr/post_images/779/0dd/0ef/7790dd0efb4a03a4c876741804d9b559.gif" title="x">  is a vector and <img src="https://habrastorage.org/getpro/habr/post_images/01a/a15/8fc/01aa158fc8bc3d7f7f3b2807df8b4a5e.gif" title="&quot;F&quot;">  has partial derivatives with respect to each variable, coincides with the Jacobi matrix <img src="https://habrastorage.org/getpro/habr/post_images/4d2/826/ff6/4d2826ff6ba22f9f67cab70bfbe17a16.gif" title="&quot;J_ {ij} = \ dfrac {\ partial F_ {i}} {\ partial x_ {j}}&quot;">  .  Next, the equation is solved <img src="https://habrastorage.org/getpro/habr/post_images/c9d/8be/3f2/c9d8be3f2d70054db890ea34e3409544.gif" title="&quot;L (p) = 0&quot;">  and point <img src="https://habrastorage.org/getpro/habr/post_images/2c4/a7b/e55/2c4a7be5582848bfbcdd9ee141e7d764.gif" title="&amp; quot;  x '= x + p &amp; quot;">  taken as a new approximation to the desired solution.  It is simple and it works. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      But what if we for some reason cannot calculate the Jacobi matrix?  The first thing that comes to mind in this case is that if we cannot calculate the partial derivatives analytically, then we can well get a numerical approximation for them.  The simplest (although by no means the only) variant of such an approximation can be the formula of right finite differences: <img src="https://habrastorage.org/getpro/habr/post_images/149/708/f5b/149708f5b8bab4374023295557622e82.gif" title="&quot;\ dfrac {\ partial F_ {i}} {\ partial x_ {j}} \ approx \ dfrac {F_ {i} (x + h_ {j} e_ {j}) - F_ {i} (x)} { h_ {j}} &quot;">  where <img src="https://habrastorage.org/getpro/habr/post_images/459/e61/aa0/459e61aa08f7fe807167a596e7ebd8a9.gif" title="&quot;e_ {j}&quot;">  Is the jth base vector.  The matrix composed of such approximations will be denoted <img src="https://habrastorage.org/getpro/habr/post_images/a51/533/990/a5153399048e881eb8661304792b8c81.gif" title="&quot;\ bar {J}&quot;">  .  An analysis of how much replacement <img src="https://habrastorage.org/getpro/habr/post_images/206/f34/999/206f349991c0724c2fdce788124abe1c.gif" title="&quot;J&quot;">  on <img src="https://habrastorage.org/getpro/habr/post_images/a51/533/990/a5153399048e881eb8661304792b8c81.gif" title="&quot;\ bar {J}&quot;">  in Newton's method, its convergence affects, a fairly large number of works are devoted, but in this case we are interested in another aspect.  Namely, such an approximation requires the calculation of the function at N additional points, and, in addition, the function <img src="https://habrastorage.org/getpro/habr/post_images/6c4/afd/100/6c4afd1002ddcfa43d07afbc9f103a9d.gif" title="&quot;\ bar {L} (p) = F (x) + \ bar {J} p&quot;">  at these points the function <i>interpolates</i> <img src="https://habrastorage.org/getpro/habr/post_images/01a/a15/8fc/01aa158fc8bc3d7f7f3b2807df8b4a5e.gif" title="&quot;F&quot;">  , i.e. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/getpro/habr/post_images/c56/5c9/4b4/c565c94b4a37b9cd5f42fc1be92b2e15.gif" title="&quot;\ bar {L (} h_ {j} e_ {j}) = F (x) + h_ {j} \ dfrac {F (x + h_ {j} e_ {j}) - F (x)} {h_ {j}} = F (x) + F (x + h_ {j} e_ {j}) - F (x) = F (x + h_ {j} e_ {j}). &quot;">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Not every approximation of the Jacobi matrix has this property, but every matrix of an affine function with this property is an approximation of the Jacobi matrix.  Indeed, if <img src="https://habrastorage.org/getpro/habr/post_images/88f/5c8/dd7/88f5c8dd7e9876a2d0e0980882f261da.gif" title="&quot;F (x + p_ {j}) = F (x) + J (x) p_ {j} + o \ left (\ left \ Vert p_ {j} \ right \ Vert ^ {2} \ right)&quot;">  and <img src="https://habrastorage.org/getpro/habr/post_images/5ad/e1e/ad2/5ade1ead2804a3bfaa8ffdf9122a179a.gif" title="&quot;\ bar {J} p_ {j} = F (x + p_ {j}) - F (x)&quot;">  then at <img src="https://habrastorage.org/getpro/habr/post_images/803/ca4/351/803ca4351b87edf1a13a2a2947772fa7.gif" title="&quot;\ left \ Vert p_ {j} \ right \ Vert \ rightarrow0 \ quad \ bar {J} (x) p_ {j} \ rightarrow J (x) p_ {j}&quot;">  .  This property, namely, the interpolation property, gives us a constructive way to generalize the Newton method. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Let be <img src="https://habrastorage.org/getpro/habr/post_images/194/ad1/d42/194ad1d42aa4320679b9498748ceb78d.gif" title="&quot;\ bar {L} (p) = a + Ap&quot;">  - function satisfying the requirement <img src="https://habrastorage.org/getpro/habr/post_images/06e/34e/3a7/06e34e3a7a0d0058ef351da74258a637.gif" title="&quot;\ bar {L} (p_ {i}) = F (x + p_ {i})&quot;">  for some system of linearly independent vectors <img src="https://habrastorage.org/getpro/habr/post_images/cf2/deb/64e/cf2deb64e8b0e4d34902a32a5fd93b7b.gif" title="&quot;p_ {i}&quot;">  .  Then such a function is called a <i>secant</i> function <img src="https://habrastorage.org/getpro/habr/post_images/01a/a15/8fc/01aa158fc8bc3d7f7f3b2807df8b4a5e.gif" title="&quot;F&quot;">  , and the equation that defines it is <i>the secant equation</i> .  If the system of vectors <img src="https://habrastorage.org/getpro/habr/post_images/cf2/deb/64e/cf2deb64e8b0e4d34902a32a5fd93b7b.gif" title="&quot;p_ {i}&quot;">  is complete (that is, there are exactly N of them and they are still linearly independent), and, in addition, the system of vectors <img src="https://habrastorage.org/getpro/habr/post_images/94f/cf5/579/94fcf55798902795ffb670e35359d2af.gif" title="&quot;\ left \ {F (x + p_ {i}), i = 1 \ dots N \ right \}&quot;">  linearly independent then <img src="https://habrastorage.org/getpro/habr/post_images/77f/eec/dd2/77feecdd2ae9a4795d2f81f3eec18b1b.gif" title="&quot;\ bar {L}&quot;">  defined uniquely. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Any method based on local change of equation <img src="https://habrastorage.org/getpro/habr/post_images/0a0/ec7/804/0a0ec780406efe57ca6444290ccfde09.gif" title="&quot;F (x) = 0&quot;">  equation of the form <img src="https://habrastorage.org/getpro/habr/post_images/ccb/557/80f/ccb55780f0c8e65187b0f4c9126be81c.gif" title="&quot;\ bar {L} (p) = 0&quot;">  where <img src="https://habrastorage.org/getpro/habr/post_images/77f/eec/dd2/77feecdd2ae9a4795d2f81f3eec18b1b.gif" title="&quot;\ bar {L}&quot;">  satisfies <i>the secant equation</i> , called <i>the secant method</i> . 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      A fair question arises about how to construct the secant for a function in the most rational way. <img src="https://habrastorage.org/getpro/habr/post_images/01a/a15/8fc/01aa158fc8bc3d7f7f3b2807df8b4a5e.gif" title="&quot;F&quot;">  .  The following line of reasoning seems obvious: let an affine model be constructed at the point x that interpolates the given function at the points <img src="https://habrastorage.org/getpro/habr/post_images/462/bcf/f32/462bcff32469c0ec5f8ccfc80534c05c.gif" title="&quot;x-x_ {1}, x-x_ {2}, \ dots, x-x_ {N}&quot;">  .  Equation solution <img src="https://habrastorage.org/getpro/habr/post_images/ccb/557/80f/ccb55780f0c8e65187b0f4c9126be81c.gif" title="&quot;\ bar {L} (p) = 0&quot;">  gives us a new point <img src="https://habrastorage.org/getpro/habr/post_images/2c4/a7b/e55/2c4a7be5582848bfbcdd9ee141e7d764.gif" title="&amp; quot; x '= x + p &amp; quot;">  .  Then to build an affine model at a point <img src="https://habrastorage.org/getpro/habr/post_images/787/cf7/c3a/787cf7c3a3d374114b3a07305b7fa446.gif" title="&amp; quot; x '&amp; quot;">  it is most reasonable to choose interpolation points so that the value <img src="https://habrastorage.org/getpro/habr/post_images/01a/a15/8fc/01aa158fc8bc3d7f7f3b2807df8b4a5e.gif" title="&quot;F&quot;">  already known - that is, take them from the set <img src="https://habrastorage.org/getpro/habr/post_images/333/297/225/33329722533f0b608b0994d2a5ba83fa.gif" title="&amp; quot; \ left \ {x'-x, x'-x_ {1}, x'-x_ {2}, \ dots, x'-x_ {N} \ right \} &amp; quot;">  .  There are different options for which points to choose from the many previously used.  For example, you can take as interpolation points those in which <img src="https://habrastorage.org/getpro/habr/post_images/bb3/e3a/cd5/bb3e3acd5043b859fe89006d4cabe5a0.gif" title="&quot;\ left \ Vert F \ right \ Vert&quot;">  matters least or just the first <img src="https://habrastorage.org/getpro/habr/post_images/055/8e9/3d9/0558e93d918ff32e873b6a71703e9969.gif" title="&quot;N&quot;">  points.  In any case, it seems obvious that <img src="https://habrastorage.org/getpro/habr/post_images/95f/756/92b/95f75692ba0aeefcef24ae42714dbc1b.gif" title="&amp; quot; p = x'-x &amp; quot;">  should be included in many interpolation points for the new affine model.  So beyond <img src="https://habrastorage.org/getpro/habr/post_images/f24/8e8/91e/f248e891effc6650d9d31fbefc54cbe4.gif" title="&quot;n&quot;">  steps of the iterative process in our set can be up to <img src="https://habrastorage.org/getpro/habr/post_images/f24/8e8/91e/f248e891effc6650d9d31fbefc54cbe4.gif" title="&quot;n&quot;">  displacements built on previously passed points.  If the process is constructed in such a way that the new affine model uses no more <img src="https://habrastorage.org/getpro/habr/post_images/4b2/8c1/3d5/4b28c13d5f5d658adb7478fbc9efc923.gif" title="&quot;p&quot;">  of the previous values, then such a process is called the p-point secant method. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      At first glance, it might seem that the N-point secant method is the best candidate for the role of replacing the Newton method, since it makes maximum use of the information that we obtain in the process of solving, and at the same time minimizes the number of additional calculations - we use the value of the function in the latter N points passed.  Unfortunately, it is not.  The thing is that the vector system <img src="https://habrastorage.org/getpro/habr/post_images/ed0/117/8ca/ed01178ca46506fa4588780d16d705a1.gif" title="&quot;F (x_ {0}), F (x_ {1}), \ dots F (x_ {N})&quot;">  stubbornly refuses to be linearly independent with a sufficiently large N. In addition, even if this condition turns out to be fulfilled and the corresponding affine model still exists, then there‚Äôs a chance that the directions <img src="https://habrastorage.org/getpro/habr/post_images/602/ff2/50c/602ff250c473d5b28e08a1453d4175b3.gif" title="&quot;p_ {j} = x_ {j} -x_ {0}&quot;">  also prove to be linearly independent, it turns out even less.  And this entails the fact that the affine model, although it exists, is degenerate and practically unsuitable. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      In general, the most stable is the 2-point secant method.  That is, a method in which at each iteration we have to calculate additional N-1 values ‚Äã‚Äãof the function.  This is clearly not suitable for our practical purposes. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Then the question is - what was all this? 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h2>  Quasi-Newtonian methods for solving equations </h2>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      The way out is simple, although not obvious.  If we do not have the technical ability, based on the already calculated values, to uniquely determine an affine model that satisfies the secant equation, then it is not necessary.  We take the equation of secants as a basis, but we will require that it be satisfied only for some incomplete system of vectors <img src="https://habrastorage.org/getpro/habr/post_images/e5e/f2b/432/e5ef2b43292735aa2a68afffb80bf520.gif" title="&quot;\ left \ {p_ {1}, p_ {2}, \ dots, p_ {m} \ right \}, m &amp; lt; N&quot;">  .  In other words, we will require that the interpolation condition is satisfied only for a sufficiently small number of known values.  Of course, in this case we can no longer guarantee that the matrix used in such a model will tend to the Jacobi matrix, but we will not need this.  Adding to this, the affine model must interpolate the function at the current point, i.e. <img src="https://habrastorage.org/getpro/habr/post_images/3b9/9d1/7fa/3b99d17fa378aeaf36097faef3830bd5.gif" title="&quot;\ bar {L} (0) = F (x)&quot;">  , we get the following formulation of the secant method: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/getpro/habr/post_images/78c/f30/421/78cf304219a4bc90d4f900062bf2d027.gif" title="&quot;\\ \ bar {L} (p_ {i}) = F (x) + Ap_ {i} = F (x + p_ {i}), \ quad i = 1 \ dots m \\ \ bar {L} (p) = 0 \ quad \ Rightarrow p = A ^ {- 1} F (x) &quot;">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Bruiden was the first to consider methods of this kind for m = 1, calling them quasi-Newtonian.  It is clear that the secant condition in this case allows us to uniquely identify the matrix <img src="https://habrastorage.org/getpro/habr/post_images/c9d/999/d9a/c9d999d9a4e8bd3d6f8e50519d1dfaa8.gif" title="&quot;A&quot;">  only if additional conditions are imposed on it, and each such additional condition gives rise to a separate method.  Bruyden himself reasoned as follows: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      <i>as the movement in the direction</i> <i><img src="https://habrastorage.org/getpro/habr/post_images/4b2/8c1/3d5/4b28c13d5f5d658adb7478fbc9efc923.gif" title="&quot;p&quot;"></i>  <i>from point</i> <i><img src="https://habrastorage.org/getpro/habr/post_images/460/82f/7d6/46082f7d6471c3fabb832d8f94075758.gif" title="&quot;x_ {0}&quot;"></i>  <i>to the point</i> <i><img src="https://habrastorage.org/getpro/habr/post_images/1d0/56f/301/1d056f3016bc715aacc23418d8629173.gif" title="&quot;x_ {1}&quot;"></i>  <i>does not give us any additional information on how the function changes in other than</i> <i><img src="https://habrastorage.org/getpro/habr/post_images/4b2/8c1/3d5/4b28c13d5f5d658adb7478fbc9efc923.gif" title="&quot;p&quot;"></i>  <i>directions, then the effect of the new affine function on the vector</i> <i><img src="https://habrastorage.org/getpro/habr/post_images/9fc/c76/a21/9fcc76a21130891ea5d5b10efa979bff.gif" title="q"></i>  <i>should differ from the effect of the old function on the same vector the less the more different</i> <i><img src="https://habrastorage.org/getpro/habr/post_images/9fc/c76/a21/9fcc76a21130891ea5d5b10efa979bff.gif" title="q"></i>  <i>from</i> <i><img src="https://habrastorage.org/getpro/habr/post_images/4b2/8c1/3d5/4b28c13d5f5d658adb7478fbc9efc923.gif" title="&quot;p&quot;"></i>  <i>.</i>  <i>As a last resort, when</i> <i><img src="https://habrastorage.org/getpro/habr/post_images/9fc/c76/a21/9fcc76a21130891ea5d5b10efa979bff.gif" title="q"></i>  <i>orthogonal</i> <i><img src="https://habrastorage.org/getpro/habr/post_images/4b2/8c1/3d5/4b28c13d5f5d658adb7478fbc9efc923.gif" title="&quot;p&quot;"></i>  <i>, the behavior of the new function should not be different from the behavior of the old one.</i> <i>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    </i> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Breiden's idea is brilliant in its simplicity.  Indeed, if we do not have new information about the behavior of the function, then the best we can do is try not to foul the old one.  Then the additional condition 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/getpro/habr/post_images/0b3/d43/d20/0b3d43d207b144b926274d0c81abccbf.gif" title="&quot;\ bar {L} _ {1} q = \ bar {L} _ {0} q&quot;">  for all <img src="https://habrastorage.org/getpro/habr/post_images/9fc/c76/a21/9fcc76a21130891ea5d5b10efa979bff.gif" title="q">  such that <img src="https://habrastorage.org/getpro/habr/post_images/c16/9f6/315/c169f6315171249a34b50b26a2975c6e.gif" title="&quot;q ^ {T} p = 0&quot;">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      allows you to uniquely determine the matrix of the new transformation - it is obtained by adding a rank 1 correction to the old matrix. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/getpro/habr/post_images/522/f36/1f9/522f361f94a7b5a2e9da68094983b21d.gif" title="&quot;\\ A_ {1} = A_ {0} + \ dfrac {(y-A_ {0} p) p ^ {T}} {p ^ {T} p} \\ y = F (x_ {0}) -F (x_ {1}) &quot;">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      However, despite the simplicity and consistency of the conclusions made by Bruiden, they do not provide the point of support that could serve as the basis for constructing other similar methods.  Fortunately, there is a more formal expression of his idea.  Namely, the matrix constructed in this way <img src="https://habrastorage.org/getpro/habr/post_images/147/7e7/ca0/1477e7ca06155c3e43fd4a640e0f7f98.gif" title="&quot;A_ {1}&quot;">  It turns out to be the solution to the following problem: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/getpro/habr/post_images/028/96f/3fa/02896f3facb898d70f26abad02fe90a9.gif" title="&quot;\\ \ left \ Vert A_ {1} -A_ {0} \ right \ Vert _ {F} \ rightarrow \ min \\ F (x_ {1}) - Ap = F (x_ {0})&quot;">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      The task constraint is nothing but the secant equation, and the minimization condition reflects our desire to save as much information as possible in the matrix <img src="https://habrastorage.org/getpro/habr/post_images/107/a45/803/107a45803b226180325815eaa7be8706.gif" title="&quot;A_ {0}&quot;">  .  The measure of the discrepancy between the matrices in this case is the Frobenius norm, in which the problem posed has a unique solution.  This formulation may well serve as a starting point for constructing other methods.  Namely, we can change both the <i>measure</i> by which we evaluate the introduced changes and tighten the <i>conditions</i> imposed on the matrix.  In general, one can already work with such a formulation of the method. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h2>  Quasi-Newton Optimization Methods </h2>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Having understood the main idea, we can finally return to optimization problems and notice that the application of the Bruiden formula for recalculation of the affine model does not fall too well on our task.  In fact, the first derivative of the gradient function <img src="https://habrastorage.org/getpro/habr/post_images/6b8/82e/be7/6b882ebe727121dcb5fc21b091044b5a.gif" title="&quot;\ bigtriangledown f&quot;">  there is nothing else but the Hessian matrix, which by construction is symmetric.  At the same time, updating according to the Bruyden rule leads to an asymmetric matrix <img src="https://habrastorage.org/getpro/habr/post_images/147/7e7/ca0/1477e7ca06155c3e43fd4a640e0f7f98.gif" title="&quot;A_ {1}&quot;">  even <img src="https://habrastorage.org/getpro/habr/post_images/107/a45/803/107a45803b226180325815eaa7be8706.gif" title="&quot;A_ {0}&quot;">  was symmetrical.  This does not mean that the Broyden method cannot be applied to solve the stationary point equation, but based on such an update rule, we are unlikely to be able to construct good optimization methods.  In general, it is quite obvious that the quasi-Newton method should work the better, the more accurately the system of conditions of the problem describes the specifics of a specific Jacobi matrix. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      To correct this drawback, we add an additional restriction to the Bruden minimization problem, explicitly requiring that the new matrix be symmetric along with the old one: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/getpro/habr/post_images/03e/167/aa2/03e167aa25e0f4aa6b8df8546552e79a.gif" title="&quot;\\ \ left \ Vert A_ {1} -A_ {0} \ right \ Vert _ {F} \ rightarrow \ min \\ \ bigtriangledown f (x_ {1}) - Ap = \ bigtriangledown f (x_ {0} ) \\ A_ {1} ^ {T} = A_ {1} &quot;">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      The solution to this problem is 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/getpro/habr/post_images/df8/356/74b/df835674b94bab190bca3c18efed98ce.gif" title="&quot;A_ {1} = A_ {0} + \ dfrac {(y-A_ {0} p) p ^ {T} + p (y-A_ {0} p) ^ {T}} {p ^ {T} p} - \ dfrac {(y-A_ {0} p) ^ {T} p} {\ left (p ^ {T} p \ right) ^ {2}} pp ^ {T} &quot;">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Here <a href="https://www.codecogs.com/eqnedit.php%3Flatex%3Dy%3D%255Cbigtriangledown%26space%3Bf(x_%257B1%257D)-%255Cbigtriangledown%26space%3Bf(x_%257B0%257D)"><img src="https://habrastorage.org/getpro/habr/post_images/89c/f84/f29/89cf84f292ed72d1b20755677688a054.gif" title="y = \ bigtriangledown f (x_ {1}) - \ bigtriangledown f (x_ {0})"></a>  , and the matrix recalculation formula is named after its creators - Powell, Shanno and Bruyden (PSB).  The resulting matrix is ‚Äã‚Äãsymmetric, but clearly not positive definite, if only suddenly <img src="https://habrastorage.org/getpro/habr/post_images/6c7/040/47d/6c704047d3148fd7a8b563aaf79dd7f4.gif" title="&quot;y&quot;">  will not be collinear <img src="https://habrastorage.org/getpro/habr/post_images/4b2/8c1/3d5/4b28c13d5f5d658adb7478fbc9efc923.gif" title="&quot;p&quot;">  .  And we <a href="https://habr.com/ru/post/469877/">saw</a> that positive certainty is highly desirable in optimization methods. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Again, we will correct the condition of the problem, using this time the scaled Frobenius norm as a measure of matrix divergence. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/getpro/habr/post_images/f37/eb1/0f4/f37eb10f4eb10d0c54acc9adab962f10.gif" title="&quot;\\ \ left \ Vert T ^ {- T} \ left (A_ {1} -A_ {0} \ right) T ^ {- 1} \ right \ Vert _ {F} \ rightarrow \ min \\ \ bigtriangledown f (x_ {1}) - Ap = \ bigtriangledown f (x_ {0}) \\ A_ {1} ^ {T} = A_ {1} &quot;">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      The origin of this formulation of the question is a separate big topic, but it is interesting that if the matrix T is such that <a href="https://www.codecogs.com/eqnedit.php%3Flatex%3DT%255E%257BT%257DT%3DG,Gp%3Dy"><img src="https://habrastorage.org/getpro/habr/post_images/673/872/131/673872131fa6cb0f44e6839be0e448e7.gif" title="T ^ {T} T = G, Gp = y"></a>  (that is, G is also an affine transformation matrix satisfying the secant equation for the direction p), then the solution to this problem turns out to be independent of the choice of T and leads to the update formula 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/getpro/habr/post_images/135/ea6/c14/135ea6c14ea8f63f961e83576f1be5d5.gif" title="&quot;A_ {1} = A_ {0} + \ dfrac {(y-A_ {0} p) y ^ {T} + y (y-A_ {0} p) ^ {T}} {y ^ {T} p} - \ dfrac {\ left (y-A_ {0} p \ right) ^ {T} p} {\ left (y ^ {T} p \ right) ^ {2}} yy ^ {T} &quot;">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      known as the Davidon-Fletcher-Powell formula.  This update method has proven itself in practice, as it has the following property: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      <i>if</i> <i><img src="https://habrastorage.org/getpro/habr/post_images/e3e/c44/1c1/e3ec441c17e1b43df108a7d8e15d3dd6.gif" title="&quot;y ^ {T} p &amp; gt; 0&quot;"></i>  <i>and</i> <i><img src="https://habrastorage.org/getpro/habr/post_images/107/a45/803/107a45803b226180325815eaa7be8706.gif" title="&quot;A_ {0}&quot;"></i>  <i>positive definite then</i> <i><img src="https://habrastorage.org/getpro/habr/post_images/147/7e7/ca0/1477e7ca06155c3e43fd4a640e0f7f98.gif" title="&quot;A_ {1}&quot;"></i>  <i>also positively identified.</i> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      I note after that if the first condition is not satisfied, then there does not exist an affine function with a positive definite matrix that satisfies the secant equation. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      If in the problem leading to the DFP method, we take, as a measure of the discrepancy of affine models, the distance not between the matrices themselves, but between the matrices inverse to them, we obtain a problem of the form 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/getpro/habr/post_images/337/0b0/af2/3370b0af216ab9695789eeb586cf3604.gif" title="&quot;\\ \ left \ Vert T ^ {- T} \ left (A_ {1} ^ {- 1} -A_ {0} ^ {- 1} \ right) T ^ {- 1} \ right \ Vert _ { F} \ rightarrow \ min \\ \ bigtriangledown f (x_ {1}) - Ap = \ bigtriangledown f (x_ {0}) \\ A_ {1} ^ {T} = A_ {1} &quot;">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Its solution is a well-known formula, discovered almost simultaneously by Breuden, Fletcher, Goldfarb and Shanno (BFGS). 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/getpro/habr/post_images/3fa/840/c7b/3fa840c7b6ec3de81eb02bb0e9240722.gif" title="&quot;A_ {1} = A_ {0} + \ dfrac {yy ^ {T}} {y ^ {T} p} - \ dfrac {A_ {0} pp ^ {T} A_ {0}} {p ^ { T} A_ {0} p} &quot;">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      To date, it is believed that recalculation according to this formula is the most efficient from a computational point of view and at the same time is less prone to degeneration of the matrix with a large number of iterations.  Under the same conditions as DFP, this formula preserves the property of positive definiteness. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      All the described methods for updating the matrix require a correction of rank 2. This makes it easy and easy to invert the matrix <img src="https://habrastorage.org/getpro/habr/post_images/147/7e7/ca0/1477e7ca06155c3e43fd4a640e0f7f98.gif" title="&quot;A_ {1}&quot;">  using the Sherman-Morrison formula and the value <img src="https://habrastorage.org/getpro/habr/post_images/5f6/3ac/2d9/5f63ac2d91f47a730fee01b5db38f3bd.gif" title="&quot;A_ {0} ^ {- 1}&quot;">  . 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/getpro/habr/post_images/ed0/9f8/002/ed09f80027e56f58a3502cc943758509.gif" title="&quot;B_ {1} = B_ {0} + uv ^ {T} \ Rightarrow B_ {1} ^ {- 1} = B_ {0} ^ {- 1} + \ dfrac {B_ {0} ^ {- 1} uv ^ {T} B_ {0} ^ {- 1}} {1 + v ^ {T} B_ {0} ^ {- 1} u} &quot;">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      provided that the denominator of the formula is nonzero.  I will not give specific formulas for updating the inverse matrices of the listed methods, since they are easy to find or derive independently.  The only thing that should be noted in this case is that the variants of the methods with updating the inverse matrix are usually much less stable (that is, they suffer more from rounding errors) than those that suggest updating the original matrix.  It is most effective to update not the matrix itself, but its Cholesky decomposition (unless, of course, such a decomposition takes place), since such an implementation option is more numerically stable and, in addition, minimizes the cost of solving an equation that determines the direction of motion. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      It remains to consider the question of how the very first matrix should look in the quasi-Newtonian process.  Everything is obvious here - the closer it is to the Hessian matrix or to its corrected version, if the Hessian does not suddenly turn out to be positive definite, the better it will be in terms of convergence.  However, in principle, any positive definite matrix can be suitable for us.  The simplest version of such a matrix is ‚Äã‚Äãa single one, and then the first iteration coincides with the iteration of the gradient descent.  Fletcher and Powell showed (naturally, for the DFP method) that if the quadratic function is minimized, regardless of which (positive definite) matrix is ‚Äã‚Äãused as the initial DFP iteration, they will lead to a solution in exactly N iterations, where N is dimension of the problem, and the quasi-Newtonian matrix coincides with the Hessian matrix at the minimum point.  In the general non-linear case of such happiness, we, of course, will not wait, but this at least gives reason to not worry too much about the poor choice of the initial matrix. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h2>  Conclusion </h2>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      The described approach to the construction of quasi-Newtonian methods is not the only possible one.  At a minimum, the discoverers of the described quasi-Newtonian methods and many subsequent researchers came to the same formulas on the basis of completely different considerations.  However, it is interesting that as soon as a certain quasi-Newtonian method appeared, then regardless of the method of obtaining it, after a rather short time it became clear that it was a solution to some very easily interpreted optimization problem.  In my opinion, it is remarkable that it is possible to bring some common denominator for such diverse methods, since this provides the basis for constructing other methods that better take into account the specifics of a particular task.  In particular, there are quasi-Newtonian methods designed to update sparse matrices, methods in which as few elements as possible are subjected to change, and many others would be fantasy. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      It should also be noted that methods of variable metrics, in spite of their name, do not always lead to the construction of matrices, which are actually metrics, although they do it every time it is possible at all.  This is usually not a big problem, but those who want to protect themselves from a possible embarrassment may well resort to the same tricks that were made to overcome a similar problem with the Newton method - for example, by changing the direction or applying <a href="https://habr.com/ru/post/470181/">the Levenberg-Marquardt scheme</a> .  True, in this case, questions of choosing the form of a trusting region will again become relevant, but here it is necessary to choose the lesser of evils.  Another solution to the problem is to use linear search methods to ensure that the necessary conditions for maintaining positive certainty are met.  Wolfe‚Äôs rule guarantees the fulfillment of this condition, while the Armijo and Goldstein rules do not. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Theoretically, it is almost impossible to determine which of the huge number of possible quasi-Newtonian methods will be the most effective in relation to a certain class of problems.  Usually, when formulating a method, they are limited to showing its effectiveness in minimizing a quadratic function (by the way, a method is considered effective if it leads to an exact solution in N iterations, that is, no more slowly than direct methods for solving SLAEs).  In more rare cases, one can find studies of the convergence order of the method (which is usually superlinear, that is, significantly better than what gradient descent gives us), stability, and other characteristics of interest.  But in general, the only reasonable criterion that allows us to judge the effectiveness of a particular method for a particular class of tasks is practice.  So shovels in hand - and success in application. </div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../470618/index.html">Thematic modeling of news using factor analysis</a></li>
<li><a href="../470620/index.html">Infrastructure as Code: How to Overcome Problems with XP</a></li>
<li><a href="../470622/index.html">Overview of Feature Selection Techniques</a></li>
<li><a href="../470632/index.html">Arend - HoTT-based dependent type language (part 2)</a></li>
<li><a href="../470634/index.html">Identify cross-community on Instagram to identify user interests</a></li>
<li><a href="../470640/index.html">Sizing Elasticsearch</a></li>
<li><a href="../470642/index.html">Meet Yandex.Station Mini. Big story of a small device</a></li>
<li><a href="../470644/index.html">Why corblogs sometimes turn sour: a few observations and tips</a></li>
<li><a href="../470646/index.html">Math for Data Science. New course from OTUS</a></li>
<li><a href="../470648/index.html">IBM LTO-8 - Easy Way to Store Cold Data</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter70218013 = new Ya.Metrika({
                  id:70218013,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/70218013" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'G-FEDBM7F51Q', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Clever Geek | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <div class="company-info js-company-info" itemscope="" itemtype="http://schema.org/Organization">
      <span itemprop="name">Western Town Media (WTM)</span>
      <div itemprop="address" itemscope="" itemtype="http://schema.org/PostalAddress">
        <span itemprop="streetAddress">1968 Stoney Lonesome Road</span>
        <br>
        <span itemprop="postalCode">PA 18640</span>
        <span itemprop="addressLocality">Pittston, USA</span>
      </div>
      <span itemprop="telephone">570-362-1316</span>
    </div>
    <script type="application/ld+json">
      {
        "@context": "http://schema.org",
        "@type": "Organization",
        "address": {
          "@type": "PostalAddress",
          "addressLocality": "Pittston, USA",
          "postalCode": "PA 18640",
          "streetAddress": "1968 Stoney Lonesome Road"
        },
        "name": "Western Town Media (WTM)",
        "telephone": "570-362-1316"
      }
    </script>
  </div>
</footer>
  
</body>

</html>