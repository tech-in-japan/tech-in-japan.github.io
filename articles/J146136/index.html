<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-FEDBM7F51Q"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-FEDBM7F51Q');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🙍🏿 ✔️ 👼🏻 コンピュータグラフィックスの被写界深度 ⛲️ 📢 🤹🏻</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="人間の目とは異なり、コンピューターはシーン全体に焦点を合わせてレンダリングします。 瞳孔またはレンズの開口部の直径が有限であるため、カメラと目の両方の被写界深度は限られています。 より優れたフォトリアリズムを実現するには、コンピューターで取得した画像に被写界深度の効果を使用することをお勧めします。 ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <link rel="sitemap" type="application/xml" href="/sitemap.xml"/>

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>

  <script>document.write('<script src="https://pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://tech-in-japan.github.io/index.html"></a>
    <div class="page-header-text">Clever Geek Handbook</div>
  </header>
  <section class="page js-page"><h1>コンピュータグラフィックスの被写界深度</h1><div class="post__text post__text-html js-mediator-article" id="post-content-body"><img src="https://habrastorage.org/storage2/774/908/98e/77490898ef29ccb47cc23b3ca7845fb4.jpg" width="256" height="189" alt="ドフ" align="left"> 人間の目とは異なり、コンピューターはシーン全体に焦点を合わせてレンダリングします。 瞳孔またはレンズの開口部の直径が有限であるため、カメラと目の両方の被写界深度は限られています。 より優れたフォトリアリズムを実現するには、コンピューターで取得した画像に被写界深度の効果を使用することをお勧めします。 さらに、被写界深度を制御することで、著者の芸術的意図を明らかにし、意味において重要なオブジェクトを強調することができます。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     これまで、コンピューターグラフィックスで現実的な被写界深度を表示するタスクは完全には解決されていませんでした。 長所と短所を備えた多くのソリューションがあり、さまざまなケースに適用できます。 現時点で最も人気のあるものを検討します。 <a name="habracut"></a>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h2> 光学系で </h2> レンズで屈折した光は、フィルム、マトリックス、網膜などの感光要素に画像を形成します。 十分な量の光がチャンバーに入るために、入力開口部（光学システムへの入り口での光ビームの直径）は十分な大きさでなければなりません。 空間の1点からの光線は常にレンズの1点後ろに正確に収束しますが、この点は必ずしも選択された画面（センサーの平坦度）と一致しません。 したがって、画像の被写界深度は限られています。つまり、オブジェクトとレンズとの距離と焦点距離の差が大きいほど、オブジェクトはよりぼやけます。 その結果、特定の距離にある点がぼやけたスポットとして表示されます：混乱の輪（CoC）。 ぼかし半径は、特定の法則に従って計算されます。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/storage2/f67/461/d3e/f67461d3e4de7222e12e357405f7c903.png" alt="ぼかしディスク直径式">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      <font color="#aaa">ぼかし直径の決定（詳細については、 <a href="http://en.wikipedia.org/wiki/Depth_of_field">Wikipediaを</a>参照）。</font> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     レンダラーで使用されるメソッドは、 <a href="http://en.wikipedia.org/wiki/Pinhole_camera">ピンホールカメラ</a>モデルを使用します（入力アパーチャが0であるため、すべてのオブジェクトに焦点が合います）。 有限サイズの開口部、したがって被写界深度のシミュレーションには、追加の労力が必要です。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/storage2/ca3/655/195/ca3655195b85bc4355268c0a39b8cac3.png" alt="CoC">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      <font color="#aaa">シーン内のポイントは、散乱スポットとして画面に投影されます。</font> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h2> 一般的なレビュー </h2> 被写界深度を実装する方法は、オブジェクト空間メソッドと画像空間メソッドの2つの大きなグループに分けることができます。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     オブジェクト空間メソッドは、シーンオブジェクトの3D表現で機能するため、レンダリング中に適用されます。 ポストプロセスメソッドとも呼ばれる画像空間メソッドは、標準のピンホールカメラモデルを使用して取得されたラスターイメージで動作します（完全にフォーカスされています）。 被写界深度の効果を実現するために、これらのメソッドは、深度マップを指定して、画像の領域をぼかします。 一般に、オブジェクト空間メソッドは、画像空間メソッドよりも物理的に正確な結果を生成でき、アーティファクトが少ない一方で、画像空間メソッドははるかに高速です。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     オブジェクト空間法は、幾何光学または波動光学に基づいています。 ほとんどのアプリケーションは、幾何光学を使用します。これは、ほとんどの目標を達成するのに十分です。 ただし、焦点が合っていない画像では、回折と干渉が重要な役割を果たします。 彼らの検討のため、波動光学の法則を適用する必要があります。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     画像空間法は、生成された画像に適用される方法とデジタル写真に適用される方法に分けることができます。 従来のポストプロセッシング技術では、カメラからの画像ポイントの遠隔性に関する情報を含む深度マップが必要ですが、そのようなマップを写真で取得することは困難です。 デプスマップなしでオブジェクトの焦点をぼかすことができる、ライトフィールドの興味深いテクニックがあります。 この技術の欠点は、特別な機器が必要なことですが、結果の画像にはシーンの複雑さに対する制限がありません。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h2> オブジェクト空間アプローチ </h2>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h3> 分散レイトレーシング </h3> この方法は、幾何光学を直接シミュレートします。 サンプルごとに1つのレイをトレースする代わりに（オリジナルでは、ピクセルですが、カウントされるレイの数はAA設定に応じて変化し、まれに1ピクセルに等しいため）、不適切だと思いました。有限口径のカメラで取得したアナログ画像を取得します。 各サンプルの光線は、画面上の1点から来ますが、レンズの異なる部分に向けられます。 レンズによる屈折の後、ビームはシーンに放射されます。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     説明は、光学の物理法則（波を除く）を考慮して、画像が形成されることを示しています。 したがって、この方法で取得した画像は非常に現実的であり、後処理方法を確認できる「ゴールドスタンダード」と見なされます。 この方法の欠点は明らかです。各サンプルについて、高品質のブラーを得るのに十分な光線の数をそれぞれ計算する必要があるため、レンダリング時間が長くなります。 被写界深度を浅くしたい場合は、レンダリング時間を数百または数千倍増やす必要があります。 ぼやけた領域で使用する余分な光線の数が不十分な場合、ノイズが発生します。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     このメソッドは、mia_lens_bokehシェーダーに実装されています。 <pre><code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">//   struct depth_of_field { miScalar focus_plane_distance; miScalar blur_radius; miInteger number_of_samples; }; miBoolean depth_of_field ( miColor *result, miState *state, struct depth_of_field *params ) { //   miScalar focus_plane_distance = *mi_eval_scalar(&amp;params-&gt;focus_plane_distance); miScalar blur_radius = *mi_eval_scalar(&amp;params-&gt;blur_radius); miUint number_of_samples = *mi_eval_integer(&amp;params-&gt;number_of_samples); miVector camera_origin, camera_direction, origin, direction, focus_point; double samples[2], focus_plane_z; int sample_number = 0; miColor sum = {0,0,0,0}, single_trace; //      miaux_to_camera_space(state, &amp;camera_origin, &amp;camera_direction); //    focus_plane_z = state-&gt;org.z - focus_plane_distance; miaux_z_plane_intersect(&amp;focus_point, &amp;camera_origin, &amp;camera_direction, focus_plane_z); //     while (mi_sample(samples, &amp;sample_number, state, 2, &amp;number_of_samples)) { miaux_sample_point_within_radius(&amp;origin, &amp;camera_origin, samples[0], samples[1], blur_radius); mi_vector_sub(&amp;direction, &amp;focus_point, &amp;origin); mi_vector_normalize(&amp;direction); miaux_from_camera_space(state, &amp;origin, &amp;direction); mi_trace_eye(&amp;single_trace, state, &amp;origin, &amp;direction); miaux_add_color(&amp;sum, &amp;single_trace); } //   miaux_divide_color(result, &amp;sum, number_of_samples); return miTRUE; }</span></span></code>
      
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
     </pre> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/storage2/14d/20e/fd6/14d20efd64c2667b97f223af9f33ae3b.jpg" alt="DOFシェーダー">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      <font color="#aaa">シェーダーを適用した結果（コードは<a href="http://www.writingshaders.com/lecture_slides/WMRS_part6_image_april_2008.pdf">手動のmental ray</a>から取得され、画像はそこから取得され<a href="http://www.writingshaders.com/lecture_slides/WMRS_part6_image_april_2008.pdf">ます</a> ）。</font> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h3> 現実的なカメラモデル </h3> 以前の方法では、レンズの屈折は1つの法則に従って計算されました。 ただし、これは常にそうではありません。 レンズは、異なるプロパティを持つレンズのグループで構成されます。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/storage2/e99/ff5/5cf/e99ff55cf4e0afdbe15384875e0e9243.png" alt="レンズモデル">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      <font color="#aaa">レンズ内のレンズグループ（Pat Hanrahanによる写真）。</font> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     メーカーが提供する光学レンズの仕様は、数学モデルとして正しく実装されています。 このモデルには、レンズグループのシミュレーションが含まれ、アウトレット（レンダラーが1つのサンプルの光線を放出する範囲）のモデルも提供されます。 出口に入る光線は、通過するレンズグループの光学特性を考慮して計算されます。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     この方法では、被写界深度とレンズによって生じる歪みの両方を物理的に正しくシミュレートできます。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/storage2/ca1/031/1e4/ca10311e48d80d8835401ae25856ae69.jpg" alt="さまざままなレンズズモデル">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      <font color="#aaa">焦点距離の異なるレンズ：焦点距離とレンズモデルの変更により、遠近法の変更と歪みが表示される場合があります（たとえば、上の写真のように）-Pat Hanrahanの写真。</font> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     魚眼レンズを実装するシェーダーの例： <pre> <code class="cpp hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">fisheye</span></span></span><span class="hljs-class"> {</span></span> miColor outside_color; }; <span class="hljs-function"><span class="hljs-function">miBoolean </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">fisheye</span></span></span><span class="hljs-function"> </span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(miColor *result, miState *state, struct fisheye *params )</span></span></span><span class="hljs-function"> </span></span>{ miVector camera_direction; miScalar center_x = state-&gt;camera-&gt;x_resolution / <span class="hljs-number"><span class="hljs-number">2.0</span></span>; miScalar center_y = state-&gt;camera-&gt;y_resolution / <span class="hljs-number"><span class="hljs-number">2.0</span></span>; miScalar radius = center_x &lt; center_y ? center_x : center_y; miScalar distance_from_center = miaux_distance(center_x, center_y, state-&gt;raster_x, state-&gt;raster_y); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (distance_from_center &lt; radius) { mi_vector_to_camera(state, &amp;camera_direction, &amp;state-&gt;dir); camera_direction.z *= miaux_fit(distance_from_center, <span class="hljs-number"><span class="hljs-number">0</span></span>, radius, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>); mi_vector_normalize(&amp;camera_direction); mi_vector_from_camera(state, &amp;camera_direction, &amp;camera_direction); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> mi_trace_eye(result, state, &amp;state-&gt;org, &amp;camera_direction); } <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { *result = *mi_eval_color(&amp;params-&gt;outside_color); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> miTRUE; } }</code>
      
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
     </pre>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/storage2/96c/d22/be3/96cd22be34d65a7b258206127530521b.jpg" alt="フィッッシュアイ">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      <font color="#aaa">シェーダーを適用した結果（コードは<a href="http://www.writingshaders.com/lecture_slides/WMRS_part6_image_april_2008.pdf">手動のmental ray</a>から取得され、画像はそこから取得され<a href="http://www.writingshaders.com/lecture_slides/WMRS_part6_image_april_2008.pdf">ます</a> ）。</font> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h3> 蓄積バッファー </h3> 蓄積バッファは、被写界深度の効果を達成するためにも使用できます。 いくつかのフレームがレンダリングされた後、それらを平均すると、目的の画像が得られます。 この方法は、分散レイトレーシングに非常に似ていますが、それよりも高速です。 レンダリングはハードウェアを使用して行われます。 ただし、最初の方法では、サンプル数を適応的に制御し、より少ないサンプルを使用して許容できる品質の画像を取得できます。 この方法は、シーンをハードウェアで仲介できる場合にのみ適用できます。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h3> 波動伝播シミュレーション（波動伝播） </h3> 上記のすべての方法は、回折と干渉を無視して、幾何光学の法則を使用します。 特定の波長の光を放出するシーンに複数の点光源がある場合、空間内の光波の伝播を追跡できます。 画面は特定の距離にあり、サンプルの値を決定するために、ソースから放射されるすべての波からの寄与が考慮されます。 フーリエ変換を使用して、周波数領域で計算を行うことができます。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h3> 散布[Krivanek] </h3> レンダリングするとき、シーンはテクスチャを備えたジオメトリプリミティブのセットとしてではなく、ポイントのセットとして表示されます。 点は特定の法則に従って散らばりますが、ほとんどの場合はガウスです。 速度を上げるために、ポイントを散乱させる場合、ポイントスプレッド関数（PSF）を考慮した畳み込み演算が使用されます。 ガウスぼかしの場合、PSFパラメーターは標準偏差です。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     得られたポイントはツリーに保存され、ぼやけた領域からポイントを選択すると、特定の半径で検索が実行されます。 これにより、画像のデフォーカス領域でより少ないサンプルを計算できます。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     メソッドのかなり厳密な制限は、必要な形式でシーンを表現する能力であると仮定することは論理的です。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/storage2/8a7/c3a/d7a/8a7c3ad7a7373f27103f1973f4a0008f.jpg" alt="スプラッテイング">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      <font color="#aaa">散乱画像。</font>  <font color="#aaa">ぼやけた領域では、サンプリング密度が低くなります（Jaroslav Krivanekによる写真）。</font> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h3> 分析的可視性[カトムール] </h3>  3次元のシーンを使用すると、焦点が合っていないオブジェクトを分析的に判断できます。 そのようなオブジェクトでは、サンプルの数が少なくなり、結果としてぼやけて見えます。 この方法では、分散レイトレーシングとは対照的に、ノイズのない正確な画像を取得できます。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h2> 画像空間アプローチ </h2>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     理想的な後処理メソッドには、次のプロパティが必要です。 <ul><li> 点像分布関数（PSF）の選択 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     ぼかしのタイプはPSFに依存します。PSFは、1つのポイントから取得する散乱スポットを決定します。 この特性は光学システムごとに異なるため、適切な方法でPSFのタイプを選択できます。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/storage2/45c/386/3bc/45c3863bcb414c7a7f8785c12ab90c5c.jpg" alt="PSFの選択">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      <font color="#aaa">異なるPSFを使用すると、異なるぼかしパターンを取得できます。</font> </li><li> ピクセルぼかし制御 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     画像の各ポイントで、散乱スポットのサイズと性質は異なります。 通常、後処理方法では、ポイントの位置に応じてぼかしの性質を変更することはできません。 これは、多くの場合、メソッドが分離可能なフィルターまたはフーリエ変換のいずれかを使用しているため、そのような選択を実装するのが困難であるという事実も原因です。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/storage2/a90/3b4/3e0/a903b43e00b8068385f14af709ac7897.jpg" alt="PSF変換">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      <font color="#aaa">最初の画像では、PSFは同じです。</font>  <font color="#aaa">2つ目は変更され、一部のレンズの<s>Helios-44</s>機能をより正確にシミュレートします。</font> </li><li> 強度不足のアーティファクトの欠如（強度漏れアーティファクト） 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     背景のぼやけたオブジェクトは、焦点の合ったオブジェクトの境界を決して超えません。 ただし、原始線形フィルタではこの事実を考慮しない場合があります。 このエラーの結果として表示される強度不足のアーティファクトは、画像の写実性を低下させます。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/storage2/6d3/288/2e0/6d32882e0f96e31d8c7ae7f80c27e560.png">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      <font color="#aaa">画像では、緑色の図に焦点が合っているため、背景のオブジェクトをぼかすことはできません。</font> </li><li> 連続的な不連続アーチファクトによるアーチファクトの欠如 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     実際には、前景でオブジェクトをぼかすことは柔らかく、オブジェクトには目に見えるハードアウトラインはありません。 多くの場合、フィルターはオブジェクトをぼかして、ぼかしとシルエットの両方を同時に持つようにしますが、これは間違っています。 この動作は、深度マップを平滑化する機能によるものです。その結果、オブジェクトの境界で深度が段階的に変化します（そして、オブジェクトの端と外側の混合色のピクセルが判明します）。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/storage2/9a1/cc7/df0/9a1cc7df032819a7ce632477a429354f.png" alt="深度不連続アーティファクト">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      <font color="#aaa">異なるフィルターを適用した結果。</font>  <font color="#aaa">画像（美容マップ）は平滑化されていますが、深度マップ（深度マップ）は平滑化されていないため、このようなアーティファクトが発生する可能性があります。</font> </li><li> オブジェクトの部分交差の正しいシミュレーション（部分オクルージョン） 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     実際には、前面の焦点が合っていないオブジェクトには、背後にあるオブジェクトが見える滑らかにぼやけた境界線があります。 この効果は、部分的な交差と呼ばれます。これは、後部オブジェクトが前部によって部分的にのみブロックされるためです。 ピンホールカメラを通して見ると、オブジェクトのこれらの可視領域を背景に見ることができませんでした。 効果の幾何学的な説明については、図を参照してください。 なぜなら 後処理方法は、ピンホールカメラで受信した画像を処理するため、部分的な交差をシミュレートするのは難しいタスクです。不可視のポイントの色は、利用可能なデータから推定する必要があります。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/storage2/533/3b2/47d/5333b247d68d7304b8c6aee7590a51c0.png" alt="部分閉塞">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      <font color="#aaa">オブジェクトの部分的な交差（画像Barsky）。</font> </li><li> 高性能 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     画像空間に「直接」適用されるフィルターの性能（フィルターの最も単純な実装を意味します）は、ぼかし半径が大きくなると低下します。 大きな半径の場合、プロセスには数分かかることがあります。 理想的には、フィルターをリアルタイムで適用したいのですが、これは常に可能ではありません。 </li></ul>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h3> 線形フィルタリング[Potmesil and Chakravarty] </h3> 後処理段階でDoFを取得する最初の方法の1つ。 ポイントの深度（深度マップによって決定）に応じて、ぼかし関数（PSF）のパラメーターが変化します。  PSFの半径が大きいほど、フィルターのパフォーマンスは低下します。 フィルターは次の式で表現できます。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/storage2/143/e71/dd6/143e71dd685afda3a4e23c9f349ac5dc.png" alt="線形フィルター式">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      <font color="#aaa">ここで、Bはぼかした画像、psfはフィルターコア、xとyは出力画像の座標、Sは元の画像、iとjは入力画像の座標です。</font> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      PSFは、ある意味では、回折や干渉などの光学的影響を考慮に入れる場合があります。 この方法の欠点：強度の欠如、非連続的な深さ。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h3> レイ分配バッファ[シンヤ] </h3> この方法は、オブジェクトの可視性を考慮に入れることを提案しています。これにより、強度の不足を取り除くことができます。 ぼやけたイメージを作成する代わりに、最初に各ポイントに対して、そこから発せられる光線の分布のためのバッファーが作成されます。 そのようなバッファには、あるポイントからの光が到達する可能性のある座標が、深度とともに含まれています。 すべてのポイントのレイ分布バッファーを計算した後、平均色値が計算されます。 このメソッドはオブジェクトの可視性で十分に正しく動作しますが、線形フィルタリングと比較してより多くのメモリと計算が必要です。  RDBメソッドによって取得されたマップのセットはライトフィールドと呼ばれることに注意してください。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h3> 階層化されたDoF [Scofield] </h3> このメソッドは、オブジェクトの位置の特殊なケースを対象としています。オブジェクトは画面に平行でなければなりません。 オブジェクトはレイヤーに分割され、レイヤーは周波数ドメインで個別に洗い流されます（高速フーリエ変換を使用）。  FFTを使用すると、パフォーマンスに影響を与えずに大きな半径のPSFを使用できます。 この方法には強度不足がなく、非常に迅速に機能しますが、その範囲は非常に限られています。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h3> 交差点と離散化[Barsky] </h3> 前の方法によって課せられた制限は非常に厳しいです。 画像はレイヤーに分割されるため、画像サンプルの深さは、最も近いレイヤーの選択された深さに丸められます。 結果のイメージには、レイヤーの交差線に沿ったストライプまたはハード境界の形の離散化アーティファクトがあります。 この方法では、境界を見つける方法（またはObjectIdマップから）で取得したオブジェクトのIDを使用して、このようなアーティファクトの問題を解決します。  1つのオブジェクトが2つのレイヤーに属する場合、レイヤーはマージされます。 この方法の別の問題は、部分的な交差です。 背景のオブジェクトをぼかすために、可視サンプルによる近似が使用されます。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/storage2/0c2/b34/38c/0c2b3438cf52a2bec307a786824e18cb.jpg" alt="レイヤードDOF">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      <font color="#aaa">上部の画像に黒い縞が表示されています-ObjectId（Barsky picture）を使用せずにレイヤーごとにぼかしを適用した結果のアーティファクト。</font> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h3> 視覚的にリアルなレンダリング[Kolb] </h3> 人間の目は、いくつかのレンズで構成される分析モデルの形で説明することは困難です-レンズに対してこれを行う方法。 この方法では、波面収差計と呼ばれる特別なデバイスを使用して（これを翻訳することを敢えてしませんでした）、人間の目に対応するPSFのセットが決定されます。 次に、レイヤーごとのぼかしが、結果のPSFに従って使用されます。 この方法を使用すると、視覚疾患のある人に画像を表示できます。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/storage2/845/2c8/b59/8452c8b59fce24fada6f96014749743a.jpg" alt="ビジオン現実的な自由度">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      <font color="#aaa">円錐角膜に苦しんでいる人の目の特性を考慮に入れた画像（写真Barsky）。</font> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h3> 重要度の注文[恐怖] </h3> この方法は、レンダラーのアンチエイリアスメカニズムと同様に機能します。まず、低解像度の画像が形成され、その後、色変化がしきい値を超えるサンプルが次の反復で処理され、元の画像のサンプルがさらに取得されて最終画像のピクセルが取得されます。 したがって、この方法は、より短い時間でより良い品質を実現します。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h3> ハイブリッド知覚ハイブリッド法[Mulder and van Lier] </h3> 画像の人間の知覚の特徴は、画像の端に沿った細部よりも中心の細部が重要であるということです。 画像の中心はより遅くより正確な方法でぼかすことができますが、周辺は迅速なぼかし近似を使用します。 ぼかしを高速にするには、ガウスピラミッドを使用します。ぼかしのレベルはピクセル深度に応じて選択されます。 結果にはアーティファクトがあります。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h3> 繰り返し畳み込み[ロキタ] </h3> このメソッドは、対話型アプリケーションでの迅速な適用を目的としています。  3x3ピクセルコアで畳み込み演算を効果的に実装できるハードウェアデバイスで動作します。 畳み込みは数回実行され、それにより大量のぼかしが実現されます。 ぼかしの半径が大きくなると、パフォーマンスが低下します。  PSFには制限があります：ガウスでなければなりません。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h3>  GPUの被写界深度[Scheueremann and Tatarchuk] </h3> 被写界深度はGPUでも読み取ることができます。 方法の1つは、ScheueremannとTatarchukによって提案されました。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     光学の法則に従って、ピクセルの深さを与えて、散乱スポットの大きさを決定し、スポット内で結果としてピクセルの色を形成するサンプルを選択します。 メモリを最適化するために、CoCの半径が大きい画像の領域では、ピクセルは入力画像からではなく、数倍削減されます。 強度不足のアーティファクトの数を減らすために、ピクセルの深さも考慮されます。 このメソッドは、深さの連続性のアーティファクトを所有しています。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h3> 積分行列（総面積表）[ヘンズリー] </h3>  CoC内でサンプリングする代わりに、画像のピクセル領域の平均色は、統合マトリックス（SAT）を使用して見つけることができます。 この場合、計算速度は速く、ぼかし半径が大きくなっても低下しません;さらに、低解像度の画像を生成する必要はありません。 当初、この方法はテクスチャを平滑化することを目的としていましたが、後にGPUを含む被写界深度に適応しました。 このメソッドには、ほぼすべてのタイプのアーティファクトがあります。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h3> ピラミッド法[クラウスとストレンガート] </h3> シーンは、深さに応じてレイヤーに分割されます。 レイヤー境界に近いピクセルは、最も近いレイヤーではなく、いくつかのレイヤーに部分的に関連します。これにより、レイヤー境界でのサンプリングアーティファクトが除去されます。 次に、レイヤーに存在しないピクセル（前景のオブジェクトで覆われているピクセル）の値が外挿されます。 その後<a href="http://www.jvrb.org/past-issues/6.2009/1821/">、ピラミッド法によって</a>各レイヤーが洗い流され、ポイントウェイトがアーティファクトを除外するために使用されます。 結果のレイヤーは、レイヤーの透明度を考慮して混合されます。 この方法は、FFTを使用した階層化方法よりも高速ですが、使用するPSFに制限を課します。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/storage2/f46/c22/dd6/f46c22dd6edf99b9f169f607e33fc943.jpg" alt="ピラミッドぼかし">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      <font color="#aaa">ピラミッド法を使用して画像をぼかしました（Magnus Strengert picture）。</font> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h3> 分離可能なぼかし[周] </h3> 深度（ボックスぼかし、ガウスぼかし）を考慮しない従来のぼかし方法と同じ方法で、分離可能なPSFを使用して被写界深度を計算できます。 最初に、画像は水平方向にぼやけ、次に垂直方向にぼやけます-その結果、スポットの面積ではなく、鮮明さではなく、その直径に依存する速度が得られます。 このメソッドはGPUに実装でき、リアルタイムで適用できます。 分離可能な関数を使用するアイデアを図に示します。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/storage2/f01/d2f/740/f01d2f740f2ee930c8401dd78936f34e.png" alt="分離可能なぼかし">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      <font color="#aaa">分離可能なぼかしでは、パフォーマンスはPSFの面積ではなく、その直径に依存します。</font> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     別の研究では、深度を考慮した適切なぼかしは分離できないと強調していることに注意する価値があります。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h3> 熱拡散のシミュレーション[Barsky、Kosloff、Bertalmio、Kass] </h3> 熱放散は、ぼやけも観察できる物理的なプロセスです（ただし、光学系とは関係ありません）。 温度が熱伝導体に均一に分布していない場合、時間の経過とともにぼやけが観察されます。 このようなぼかしの効果を表す微分方程式を使用して、被写界深度をシミュレートできます。 十分に大きなぼかし半径の場合でも、この方法はリアルタイムでGPUに適用できます。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/storage2/fd7/8a7/88b/fd78a788b1581f1d3d443f3c1e845812.jpg" alt="位置マップ">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      <font color="#aaa">このメソッドで深度マップの代わりに使用される位置マップには、深度だけでなく、ポイントの3次元に関する情報が含まれています（Barsky picture）。</font> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h3> 一般化されたセマンティックな被写界深度 </h3> これまでのところ、自然界で起こる被写界深度をシミュレートする方法を説明してきました。 ただし、ぼかしは、観察に使用したものとは異なる場合があります。 コンピューターグラフィックスでは、物理的に実現可能なレンズモデルに限定されないため、ぼかし領域は任意に設定できます。たとえば、群衆から数人を区別することができます。 この方法は、物理的なもの以外の法則をぼかしマップとして使用して熱放散をシミュレートする方法のバリエーションとして実装できます。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/storage2/973/282/317/973282317e9f2026fd2b7eb8e2f76961.jpg" alt="一般化された自由度">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      <font color="#aaa">物理的に正しくないぼかし（KosloffとBarskyによる写真）</font> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h2> ライトフィールド </h2> ライトフィールドはもともと、シーンの複雑さに関係なく、異なるポイントからのシーンの画像を記述する方法として説明されていました。 ライトフィールドをコーディングする標準的な方法は、2平面パラメーター化です。  2つの平行な平面が選択されています。 各光線は、両方の平面上の点で記述されます。 結果は、4次元のデータ構造です。 取得したデータは、焦点面や被写界深度の変更など、操作できます。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     カメラでは、ライトフィールド（レンズの平面とマトリックスの間）が自然に統合されていると言えます。光線がレンズのどの点から来たかは区別しません。 ただし、これを考慮すると、説明したデータ構造を使用して、センサーの読み取り値を取得した後、被写界深度をインタラクティブに管理できます。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     さらに、4次元空間の高速フーリエ変換を使用して、画像のさまざまな部分に焦点を合わせることができます。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     コンピューターで生成された画像では、さまざまな角度からシーンをレンダリングすることでライトフィールドデータを簡単に取得できます。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     ライトフィールドを記録できるカメラ（物理）があります。 センサーの前には、さまざまな方向からの光を分離するマイクロレンズがあります。<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">したがって、従来のカメラとは異なり、光は1つのポイントで集計されず、方向に応じて分散されます。</font><font style="vertical-align: inherit;">センサーによると、すでに処理段階で、焦点の合ったオブジェクトとぼかしサイズを選択できます。</font></font>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/storage2/119/d3a/0af/119d3a0af2b3ae5141760d372d8c0949.jpg" alt="ライトフィールド">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     <font color="#aaa"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ライトフィールド：LytroセンサーからのRAW画像のごく一部。</font><font style="vertical-align: inherit;">マトリックスの前にマイクロリーフがあります。</font></font></font> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> スポッティング（まだらの）写真 </font></font></h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">上記の方法では、1つのピクセルをエンコードするために多くのマトリックスポイントが必要であるため、解像度が低くなります。</font><font style="vertical-align: inherit;">実際、このカメラの解像度は、11MPixマトリックスのほとんどの部分で約800ピクセルです。</font><font style="vertical-align: inherit;">この問題は、非常に高い解像度のセンサーを使用することで解決できます（ただし、これはより高価なセンサーと非常に大きなデータ構造につながります）。</font></font>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <font style="vertical-align: inherit;"><font style="vertical-align: inherit;">斑点写真は、マトリックスのサイズ制限をバイパスして、ライトフィールドを取得する代替方法を提供します。</font><font style="vertical-align: inherit;">多数のマイクロレンズの代わりに、特定の法則に従って光を変える半透明のマスクが使用されます。</font><font style="vertical-align: inherit;">逆フーリエ変換を使用すると、元のライトフィールドを取得できます。</font></font>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> デフォーカス倍率 </font></font></h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ライトフィールドなしで、「通常の」写真に被写界深度の効果を適用できると便利です（レンダリングとは異なり、デプスマップはありません）。</font><font style="vertical-align: inherit;">この方法には、ぼかしの定義とその増加が含まれます（この方法では、写真にぼかしが既に存在するが、十分ではないことを前提としています-たとえば、写真は石鹸の皿で撮影されたため、マトリックスのサイズのために大きなぼかし半径を達成することはできません）。</font><font style="vertical-align: inherit;">画像に既に存在するぼかしが大きいほど、より多くのぼかしが追加で適用されます。</font></font>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> オートフォーカス </font></font></h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">バーチャルリアリティアプリケーションやビデオゲーム、および写真で被写界深度を使用する場合、オートフォーカス、つまりピクセルが焦点を合わせる深度を決定するタスクが必要です。画像の中央で領域が選択され、この領域のサンプルが焦点深度の決定に関与します。深さの加重平均値と、描かれたオブジェクトの既知の重要性の両方を考慮します（たとえば、木製の箱や壁ではなく、キャラクターの1つに「外観」を集中させることができます）-これはオブジェクトのセマンティックウェイトと呼ばれます。また、視線の調節のプロセスを考慮する必要があります（焦点は時間の経過とともに徐々に変化します）。これには、たとえば、ローパスフィルターが使用されます。</font></font>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h2> おわりに </h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">現代のコンピュータグラフィックスで被写界深度の効果を達成するために使用される最も一般的な方法のほとんどを調べました。</font><font style="vertical-align: inherit;">それらの一部は3Dオブジェクトで動作し、一部は後処理メソッドです。</font><font style="vertical-align: inherit;">また、適切な方法で満たす必要がある基本的な特性についても説明しました。</font></font>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <font style="vertical-align: inherit;"><font style="vertical-align: inherit;">現在、フォトリアリスティックな被写界深度を効果的に達成する問題は未解決のままです。</font><font style="vertical-align: inherit;">さらに、写真から深度マップを再構築する問題（オブジェクトまでの距離を決定する）も未解決です。</font></font>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h2> 参照資料 </h2><div class="spoiler"> <b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">リンクを読む</font></font></b> <div class="spoiler_text"> <a href="http://www.cs.berkeley.edu/~barsky/vis.sci.pubs.html">  Brian A.Barsky</a> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     <a href="http://onlinelibrary.wiley.com/doi/10.1111/j.1467-8659.2007.00935.x/full">Accurate Depth of Field Simulation in Real Time (Tianshu Zhou, Jim X. Chen, Mark Pullen)</a> —     DoF 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     <a href="http://www.eecs.berkeley.edu/Pubs/TechRpts/2007/EECS-2007-19.pdf">An Algorithm for Rendering Generalized Depth of Field Effects Based on Simulated Heat Diffusion (Todd Jerome Kosloff, Brian A. Barsky)</a> —      
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     <a href="http://graphics.berkeley.edu/papers/Barsky-IOA-2003-07/Barsky-IOA-2003-07.pdf">Investigating Occlusion and DiscretizationProblems in Image Space Blurring T echniques (Brian A. Barsky, Michael J. Tobias, Daniel R. Horn, Derrick P. Chu)</a> —     
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     <a href="http://www.jvrb.org/past-issues/6.2009/1821/">Quasi-Convolution Pyramidal Blurring (Martin Kraus)</a> —   
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     <a href="http://groups.csail.mit.edu/graphics/classes/CompPhoto06/html/lecturenotes/22_DepthDefocus_6.pdf">Focus and Depth of Field (Frédo Durand, Bill Freeman)</a> —   ,     : cheat sheet.      . </div></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h2> 翻訳者から </h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ブライアンA.バースキー（バークレー大学）のこの作品およびその他の作品は</font></font><a href="http://www.cs.berkeley.edu/~barsky/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、彼のウェブサイト</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">で見つけることができます</font><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">アルゴリズムのいくつかの用語とよく知られている名前が見つかったどこでも、私はそれらを英語の括弧内に残し、名前を翻訳しませんでした。</font><font style="vertical-align: inherit;">どこかで間違って翻訳した場合-PMに書いて修正します（すべての用語を英語で勉強したので、翻訳と間違われる可能性があります）。</font><font style="vertical-align: inherit;">[角括弧]内のメソッドの名前は、それらに取り組んだ人の名前です。</font><font style="vertical-align: inherit;">明快さと興味のために、私は出版物を例といくつかの写真で補った。</font></font></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../J146128/index.html">Dolphin Browserは独自のエンジンを取得します</a></li>
<li><a href="../J14613/index.html">Gyration M2000 UltraSenseワイヤレスマウス</a></li>
<li><a href="../J146130/index.html">gitlabとgitoliteをパスワードとキーから保護する</a></li>
<li><a href="../J146133/index.html">iRobotはロボットにリモートコントロールを装備しました</a></li>
<li><a href="../J146135/index.html">グーズベリー-Raspberry Piの興味深い代替品</a></li>
<li><a href="../J146137/index.html">私の自転車Entity FrameWork、自動移行、保存データ付き</a></li>
<li><a href="../J146139/index.html">スマートケース：スマートカバーを更新する必要がありますか？</a></li>
<li><a href="../J14614/index.html">収益性の高いローンの無料選択サービスがオープンしました</a></li>
<li><a href="../J146140/index.html">退屈な積分</a></li>
<li><a href="../J146141/index.html">メディアクエリとメディアの「表示モード」-これはRECです</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter70218013 = new Ya.Metrika({
                  id:70218013,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/70218013" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'G-FEDBM7F51Q', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Clever Geek | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <div class="company-info js-company-info" itemscope="" itemtype="http://schema.org/Organization">
      <span itemprop="name">Western Town Media (WTM)</span>
      <div itemprop="address" itemscope="" itemtype="http://schema.org/PostalAddress">
        <span itemprop="streetAddress">1968 Stoney Lonesome Road</span>
        <br>
        <span itemprop="postalCode">PA 18640</span>
        <span itemprop="addressLocality">Pittston, USA</span>
      </div>
      <span itemprop="telephone">570-362-1316</span>
    </div>
    <script type="application/ld+json">
      {
        "@context": "http://schema.org",
        "@type": "Organization",
        "address": {
          "@type": "PostalAddress",
          "addressLocality": "Pittston, USA",
          "postalCode": "PA 18640",
          "streetAddress": "1968 Stoney Lonesome Road"
        },
        "name": "Western Town Media (WTM)",
        "telephone": "570-362-1316"
      }
    </script>
  </div>
</footer>
  
</body>

</html>