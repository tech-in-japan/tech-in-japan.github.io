<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-FEDBM7F51Q"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-FEDBM7F51Q');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🛀🏿 🧕🏼 🛩️ 拡張現実の最初の10年間 👙 👩🏿‍🤝‍👨🏽 💊</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="真に革新的なテクノロジーはそれぞれ、アイデア、デモ、成功したプロジェクト、大量生産という4つの開発段階を経ています。 これは、マルチタッチデバイスの例で明らかに見られます。 過去を振り返って、拡張現実技術の状況を見て、それが本当に大量の製品になる可能性があることを想像してみましょう。  
  
 
...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <link rel="sitemap" type="application/xml" href="/sitemap.xml"/>

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>

  <script>document.write('<script src="https://pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://tech-in-japan.github.io/index.html"></a>
    <div class="page-header-text">Clever Geek Handbook</div>
  </header>
  <section class="page js-page"><h1>拡張現実の最初の10年間</h1><div class="post__text post__text-html js-mediator-article" id="post-content-body" data-io-article-url="https://habr.com/ru/company/parallels/blog/327804/"><img src="https://habrastorage.org/files/6d9/d55/e33/6d9d55e330ec4963aa8ef161738e1536.jpg">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     真に革新的なテクノロジーはそれぞれ、アイデア、デモ、成功したプロジェクト、大量生産という4つの開発段階を経ています。 これは、マルチタッチデバイスの例で明らかに見られます。 過去を振り返って、拡張現実技術の状況を見て、それが本当に大量の製品になる可能性があることを想像してみましょう。 <a name="habracut"></a>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      2006年2月、Jeff Han（TEDトーク）は、実験的な「マルチタッチ」インターフェースのデモを示しました（以下のビデオ）。 今日、プレゼンテーションからの多くのことは当たり前のように見え、すべてのAndroidスマートフォンは50ドルでそれを行うことができます。 そして、聴衆は、ほとんどの場合、洗練された技術者たちを驚かせ、称賛しました。 今日は当たり前のことは驚くべきことでした。  1年後、最初のiPhoneが登場し、マルチタッチの「リセット」のアイデアが生まれました。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <iframe width="560" height="315" src="https://www.youtube.com/embed/ac0E6deG4AU" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     過去10年間のイベントを見ると、マルチタッチの起動には4つの段階があったことがわかります。 最初は彼は研究所からの興味深いアイデアでした。 その後、最初の公開デモが登場しました。 第3段階は、iPhoneに実装された最初の非常に便利なマルチタッチです。 そして最後に、数年後、iPhoneおよびAndroidスマートフォンの開発により、マルチタッチデバイスの大量販売が開始されました。 この遅延は下のグラフに反映されています-2007年の数年が経過した後、iPhoneが安くなったにもかかわらず、スマートフォンが本当に大量生産される前に。 同様の開発段階は、多くの革新的な技術の特徴です。 まれに、何かがすぐに完成した形になったとき。 同時に、技術の行き止まりのブランチが開発され<a href="https://en.wikipedia.org/wiki/I-mode">まし</a>た。西の<a href="https://en.wikipedia.org/wiki/Symbian">Symbian</a>と日本の<a href="https://en.wikipedia.org/wiki/Symbian">iMode</a>です。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/files/740/2f2/6d5/7402f26d55e74d98bba6a68a626b95d3.png">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     今日、拡張現実は第2段階と第3段階の間のどこかにあると思います。 私たちはすでに素晴らしいデモと最初のプロトタイプを見てきました。 まだ大量の商用製品を受け取っていませんが、すでにこれに近づいています。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/files/274/b50/ef2/274b50ef2beb49298dbbda9c96f2d6fe.jpg">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      MicrosoftはHololensを出荷しています。 このデバイスは宇宙空間での位置を追跡し、独自のコンピューティングプロセッサを備えています。 ただし、かなり面倒で、視野が非常に狭く（Microsoftが配信するビデオよりもはるかに少ない）、3000ドルかかります。 おそらく、デバイスの2番目のバージョンは<a href="https://www.thurrott.com/hardware/90780/microsoft-accelerates-hololens-v3-development-sidesteps-v2">2019年に</a>リリースされる<a href="https://www.thurrott.com/hardware/90780/microsoft-accelerates-hololens-v3-development-sidesteps-v2">予定</a>です。  Appleの空室や買収に関する情報、CEOのコメントを考えると、Appleも同様のことに取り組んでいるという事実に非常に似ています（Apple Watchに関しては、これは小型化、エネルギー消費の改善、無線通信などにも当てはまると思いますおよびAirPod）。  Googleは、FacebookまたはAmazonのいずれかをリリースする可能性があります。 興味深いプロジェクトは、多くの小規模企業や新興企業によって見られています。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/files/e4e/b85/867/e4eb858675e141418df8a1b6e229c1c1.jpg">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     一方、Magic Leap（a16zが投資した）は、独自のウェアラブル技術に取り組んでいます。 プロトタイプの機能を示す一連のビデオがリリースされました。 しかし、ガジェットについてのビデオを見るのと、それを使用するのはまったく別です。 存在しないオブジェクトが目の前に現れるとき、ARビデオとそのようなデバイスを身に着けている日常との間には大きな違いがあります。 試した-悪くない。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <iframe width="560" height="315" src="https://www.youtube.com/embed/kw0-JRa9n94" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     つまり、今日ジェフカーンの段階にいると、拡張現実の分野でiPhone 1のアナログが登場することをすぐに期待できるということです。 そして、10年かそこら後に、私たちは本当に巨大な製品を手に入れることができます。 何十億人にとって拡張現実とは何でしょうか？ 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/files/32d/d68/ea5/32dd68ea59d348289affe714dfbc31c6.png">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      ARへの最初のステップはGoogle Glassでした。 画面は目の前の空間の画像を「中断」しますが、現実の世界とは相互作用しません。 実際、Google Glassは概念的にはスマートな時計に非常に近く、下と左ではなく、右と上を見なければなりませんでした。 メガネはデータ出力用の画面を提供しましたが、環境についてはまったく知りませんでした。 おそらく、より高度な技術により、ユーザーの周囲の仮想球面スクリーンに情報を表示できるようになり、ウィンドウ、3Dオブジェクトなどを表示できるようになります。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      「現実の拡張現実」または「ハイブリッド現実」（混合現実）の出現により、デバイスは周囲のオブジェクトについて警告できるようになり、代わりに仮想オブジェクトを配置できるようになります。したがって、目の前に見えるものが本物かどうかはわかりません。  Google Glassとは異なり、将来のARメガネは周囲の空間の3次元地図を作成し、頭の位置を常に監視できるようになります。 これにより、壁に「仮想テレビ」を設置することができ、部屋にいる間、そこに「ぶら下がる」ことができます。 または、壁全体をディスプレイに変えることもできます。 または、Minecraftのコーヒーテーブル（または<a href="https://en.wikipedia.org/wiki/Populous_%2528video_game%2529">Populous</a> ）に置き、手で自分の世界を構築し、粘土の彫刻のように山と川を作成できます。 さらに言えば、同じ眼鏡をかけている人なら誰でも同じものを見ることができます。 会議室の壁やテーブルを、チーム全体または家族向けのディスプレイに変えることができます。 または、その小さなロボットを手に取ってソファの後ろに隠し、子供に探してもらうこともできます。 もちろん、これにはすべて、特に外部カメラの追加に関して、仮想現実との共通点があります。 ハイブリッド現実は、全世界をスクリーンに変えます。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     それ以前は、 <a href="https://ru.wikipedia.org/wiki/SLAM_(%25D0%25BC%25D0%25B5%25D1%2582%25D0%25BE%25D0%25B4)">SLAM</a>についてのみでした。つまり、3次元の部屋マップの作成についてでしたが、認識についてではありませんでした。 さらに先へ進むことができます。 ミーティングであなたに会い、頭の上に頭上にプロファイルプロファイルカードがあるとしましょう。 または、あなたが主要顧客であることを示すCRMシステムからのメモ。 または、Truecallerデータベースからのメモ。これに応じて、保険をかけて別れを告げます。 または、ブラックミラーシリーズのように、平らな黒い画像をその場所に配置することで、特定の人を単に「ブロック」できます。 つまり、メガネはオブジェクトをスキャンするだけでなく、認識します。 これは現実を補完するものになります。 実際のオブジェクトに画像を押し付けるだけでなく、意味のある方法で画像を実世界の一部に変えます。 一方で、あなたは豊かにすることができます-またはごみ、それは見ているようなものです。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <iframe width="560" height="315" src="https://www.youtube.com/embed/.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://player.vimeo.com/video/166807261" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     一方、周りの世界で非常に目立たないヒントや変更を作成できます。 たとえば、旅行中は、各碑文を自分の言語に翻訳するだけでなく、特定のスタイルを選択します。 今日、「千年」を「蛇」に置き換える<a href="http://www.slate.com/blogs/future_tense/2015/05/26/this_chrome_extension_replaces_the_word_millennials_with_snake_people.html">プラグイン</a>をブラウザに<a href="http://www.slate.com/blogs/future_tense/2015/05/26/this_chrome_extension_replaces_the_word_millennials_with_snake_people.html">追加</a>できるとしたら、将来のハイブリッドリアリティテクノロジーは何ができるでしょうか？ 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     メガネが十分にコンパクトであれば、一日中着用しますか？ そうでない場合、それらを使用すると多くの用途が失われます。 たとえば、スマートフォンまたは時計を組み合わせて、「常にオン」のデバイスとして機能し、メガネを装着してコンテンツを正しく「表示」できます。 これは、Google Glassの所有者が抱えていた社会的問題の一部を解決するのに役立ちます。携帯電話を入手したり、時計を見たり、普通の眼鏡をかけたりすることは、他の人にとって明確なシグナルです。壁を見つめて何かを読んでいます。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     これはすべて論理的な疑問につながります-拡張現実と仮想現実の合併はありますか？ それは間違いなく可能です。 両方のテクノロジーを使用すると、相互接続された作業を実行でき、相互接続されたエンジニアリングタスクを解決する必要があることを意味します。 それらの1つは、VRデバイスであるガジェットを使用してユーザーを別の世界に転送する方法です。 理論的には、ガラスディスプレイのみを覗く必要があります。つまり、ガラスの端を閉じる必要があります。 しかし、ARの場合、これは必要ありません。 同時に、ARの難しさは、周囲の世界を表示することですが、同時に「不要な」ものを遮断することです（別の質問は、明るい日光にどう対処するかです）。  ARメガネは透明です。つまり、他のユーザーはユーザーの目を見ることができます。 おそらく、10〜20年後には、ARとVRを組み合わせるためのほとんどのタスクは解決されますが、今日では両方のテクノロジーが別々に開発領域を見ています。  1990年代後半、モバイルインターネットデバイスに個別の無線モジュールとディスプレイ、さらにヘッドフォンとキーボードがあるのか​​、それとも画面とキーボードのクラムシェルなのかを議論しました。 業界は適切なフォームファクターを探していたため、キーボードも表示するディスプレイを備えたデバイスを開発するまで、2007年（およびそれ以上）待つ必要がありました。 おそらく、VRとARを組み合わせた理想的なフォームファクターはまだ見つかっていません。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/files/96c/578/5dd/96c5785ddf1449a28639d1cc0bfd9b15.png">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     別の質問：仮想オブジェクトをどのように管理し、やり取りしますか。 これにはVRに十分な物理コントローラーがありますか？ ハンドトラッキングは適切ですか（指の動作シミュレーションなし）？ スマートフォンのマルチタッチは、物理的な相互作用を意味します。つまり、関心のあるオブジェクトに触れます。 しかし、ARオブジェクトの「タッチ」をモデリングできますか？ これは、日常のインターフェースにとって本当に良い相互作用モデルですか？  Magic Leapを使用すると、空間の奥行き感を作り出すことができるため、仮想オブジェクトに触れることができると信じています。 しかし、モノリシックであるべきものを手が通るインターフェースを使用したいのですか？ 音声制御を使用する必要があり、どのような制限が課せられますか（音声認識が完全であっても、電話またはコンピューターの完全な音声制御を想像してください）。 または、目の動きを追跡するソリューションですか？ たとえば、オブジェクトを見て、2回点滅して選択しますか？ このような問題は、適切なフォームファクターの検索とともに、パーソナルコンピューターとスマートフォンの開発で解決されました。 答えは明らかではなく、さらに多くの質問があります。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     周囲の世界にARオブジェクトとデータを埋め込むタスクを熟考すればするほど、AIと物理インターフェイスの組み合わせでこれを解決する必要があるように見えます。 たとえば、あなたに近づいて、私は何を見るべきですか-VKontakteまたはFacebookからのカード？ 新しい着信メッセージはいつ表示されますか-すぐにまたは後で表示されますか？ レストランの前に立って、「おい、フォースクエア、これは良い施設ですか？」と言うべきでしょうか、それともオペレーティングシステムがこれを自動的に行うべきですか？ そして、OS、自分が追加したサービス、またはクラウド内の単一のGoogle Brainといった誰がこの動作を管理しますか？  Google、Apple、Microsoft、Magic Leapはこれについて異なる視点を持っているかもしれませんが、（AIを使用して）多くのことを自動化する必要があると思います。 エリック・レイモンドの言葉を思い出すと、コンピューターはそれ自体で計算できるものについて決して尋ねてはならないということは、コンピューターがあなたが見るものすべてを見たら、あなたが見ているものを正確に理解しなければならないと言うことができます。 そして、10年間のAI開発の後、おそらく、現在直面している多くの問題を解決することができるでしょう。 デスクトップコンピューターインターフェイスのウィンドウ-キーボード-マウスモデルからタッチコントロールに移行し、スマートフォンのオブジェクトと直接やり取りすると、一連の質問がすべて解決されました。 抽象化のレベルが変更されました。 スマートフォンは、写真の保存場所、タクシーの注文時の場所、手紙の送信に使用するアプリケーション、パスワード（スマートフォンに指紋スキャナーが搭載されている場合）を尋ねません。 これ以上の質問（および選択肢）はありません。  ARは、小さな窓の中で空中に現れる前のアプリケーション以上のものになるため、同じ方向に進む可能性があります。  Facebookデスクトップサイトのように、Snapchatがまったく機能しないのと同様に、無形のAI駆動ARインターフェースは、私たちの心を再び変えることができます。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/files/4b0/e1a/f4d/4b0e1af4d7ee431aaf0275feb531c7c4.png">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      ARメガネは、あなた（そしてあなた自身）の周りの世界を理解しようとすればするほど、コンテキスト、アプリケーションメソッド、アプリケーションモデルに応じて、自分が見ているものに関する情報を観察し、さまざまなクラウドデバイスに送信します。 これは男の顔です。あなたは彼に話しかけていますか？  Salesforce、LinkedIn、TrueCaller、Facebook、Tinderに送信（または圧縮された抽象化-はい、ネットワーク帯域幅が大きく影響します）。 これは靴ですか？  Pinterest、Ozone、Net a Porter。 または、一般的に、Googleにすべてを送信します。 これらおよび他の多くの状況は、プライバシーとセキュリティの問題を引き起こします。 いつか私たちの街を埋める無人の乗り物のようなものです。彼らは周囲の周囲の空間の写真を絶えず撮っており、それはただの観察の楽園です。 そして、誰もがARメガネをかけ始めるとどうなりますか？これから逃げることはまったく可能ですか？ そして、もしあなたの眼鏡がハックしたら？ スマートホームがハッキングされると「ポルターガイスト」になり、メガネをハッキングすると幻覚が発生します。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     最後に、別の重要な質問：ARメガネを着用する人は何人ですか？ 彼らは携帯電話用の追加のアクセサリーになりますか（例えば、スマートウォッチのように）？ それとも、ブラジルやインドネシアのアウトバックでも、現在のAndroidスマートフォンのように、中国製ARメガネのモデルを50ドルで購入できますか？  （そして、モバイルインターネットはどうなりますか？）予測するには時期尚早です。  1990年代後半から2000年代初頭に、誰もが同じタイプのモバイルデバイスを持っているのか、それとも今日スマートフォンと呼ばれるものを持っているのか、そしてほとんどがカメラやカラーのない原始的なデバイスまで、従来のボタン付き携帯電話を持っているのかと思いましたスクリーン？ 振り返ってみると、これらは「誰もがパソコンを持っているのか、誰かがタイプライター（ワープロ）を使うのか」などの論争であったことを理解しています。 スケーリングと汎用コンピューティングのロジックにより、最初にPC、次にスマートフォンが単一のユニバーサルデバイスになりました。 現在、地球上には約50億人のモバイルスマートフォンの所有者がおり、そのうちの25〜30億人がスマートフォンを所有しています。 質問はこれです：大多数はスマートフォンを使用し、一部（1億？5億？10億？）はアクセサリーとしてARグラスに切り替えますか、それとも新しいユニバーサル製品が登場しますか？ この質問に対する答えは、分析の産物ではなく、空想の飛行です。 しかし、その後、1995年に、彼らは誰もが普通の電話を持っているだろうと言った。 </div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../J327786/index.html">GameDevをゼロから：言葉を使わずにプレイヤーと通信する方法</a></li>
<li><a href="../J327788/index.html">node.js用の既成のネイティブモジュール</a></li>
<li><a href="../J327792/index.html">「最強が生き残る」単細胞生物の進化のシミュレーターの開発</a></li>
<li><a href="../J327796/index.html">Outsource-People Conference 2017、クラクフ（初日）</a></li>
<li><a href="../J3278/index.html">古いニュースフィード形式で私だけですか？</a></li>
<li><a href="../J327806/index.html">ドライバー、COMポート、7年間のスペアパーツなしで修理可能：店舗に鉄の信頼性を提供する方法</a></li>
<li><a href="../J327810/index.html">ルビーシングルではありません</a></li>
<li><a href="../J327820/index.html">GSMが存在しない地域におけるセルラー通信の過去と未来</a></li>
<li><a href="../J327822/index.html">ゲーム開発に関する4つの素晴らしいこと</a></li>
<li><a href="../J327836/index.html">パート1.ブロックチェーン上の分散アプリケーションのデータをどこに保存しますか？</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter70218013 = new Ya.Metrika({
                  id:70218013,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/70218013" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'G-FEDBM7F51Q', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Clever Geek | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <div class="company-info js-company-info" itemscope="" itemtype="http://schema.org/Organization">
      <span itemprop="name">Western Town Media (WTM)</span>
      <div itemprop="address" itemscope="" itemtype="http://schema.org/PostalAddress">
        <span itemprop="streetAddress">1968 Stoney Lonesome Road</span>
        <br>
        <span itemprop="postalCode">PA 18640</span>
        <span itemprop="addressLocality">Pittston, USA</span>
      </div>
      <span itemprop="telephone">570-362-1316</span>
    </div>
    <script type="application/ld+json">
      {
        "@context": "http://schema.org",
        "@type": "Organization",
        "address": {
          "@type": "PostalAddress",
          "addressLocality": "Pittston, USA",
          "postalCode": "PA 18640",
          "streetAddress": "1968 Stoney Lonesome Road"
        },
        "name": "Western Town Media (WTM)",
        "telephone": "570-362-1316"
      }
    </script>
  </div>
</footer>
  
</body>

</html>