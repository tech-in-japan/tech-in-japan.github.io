<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-FEDBM7F51Q"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-FEDBM7F51Q');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🌿 🎃 👨🏾‍🏭 ハードウェアアクセラレータプログラミングの未来 👋🏾 🌤️ 🙅🏽</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="最新のスーパーコンピューターの多くは、ハードウェアアクセラレータに基づいています。 2013年11月のTOP500による2つの最速システムが含まれます。 アクセラレータは通常のPCでも配布されており、ポータブルデバイスにも表示されます。これは、アクセラレータプログラミングへの関心の高まりにさらに貢献...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <link rel="sitemap" type="application/xml" href="/sitemap.xml"/>

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>

  <script>document.write('<script src="https://pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://tech-in-japan.github.io/index.html"></a>
    <div class="page-header-text">Clever Geek Handbook</div>
  </header>
  <section class="page js-page"><h1>ハードウェアアクセラレータプログラミングの未来</h1><div class="post__text post__text-html js-mediator-article" id="post-content-body">最新のスーパーコンピューターの多くは、ハードウェアアクセラレータに基づいています。  2013年11月のTOP500による2つの最速システムが含まれます。 アクセラレータは通常のPCでも配布されており、ポータブルデバイスにも表示されます。これは、アクセラレータプログラミングへの関心の高まりにさらに貢献しています。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     加速器のこのような広範な使用は、高性能、エネルギー効率、低コストの結果です。 たとえば、Xeon E5-2687Wと2012年3月にリリースされたGTX 680を比較すると、GTX 680が4倍安く、単精度演算のパフォーマンスが8倍、メモリ帯域幅が4倍であることがわかります。ドル換算で30倍以上のパフォーマンス、ワットあたり6倍のパフォーマンス。 これらの比較結果に基づいて、加速器はどこでも常に使用する必要があります。 なぜこれが起こらないのですか？ 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <a name="habracut"></a>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     主に2つの困難があります。 第一に、アクセラレータは特定のクラスのプログラム、特に十分な並行性、データの再利用、制御フローの連続性、メモリアクセス構造を持つプログラムのみを効率的に実行できます。 第二に、非常に大きな並列性、オープンなメモリ階層（ハードウェアキャッシュなし）、実行手順の厳格さ、メモリアクセス操作のマージなどのアーキテクチャの違いにより、通常のCPUよりもアクセラレータ用の効率的なプログラムを作成することは困難です。 したがって、これらの側面をさまざまな程度に隠し、アクセラレータプログラミングを容易にするために、いくつかのプログラミング言語と拡張機能が提案されました。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     現在最も有名なタイプのアクセラレータであるGPUを使用して非グラフィカルアプリケーションを加速する最初の試みは面倒であり、制限された制御フローをサポートし、整数演算をサポートしないシェーダーコードの形式で計算を提示する必要がありました。 次第に、これらの制限は削除され、グラフィックチップでの計算の普及に貢献し、グラフィック以外の領域の専門家がそれらをプログラムできるようになりました。 この方向で最も重要なステップは、CUDAプログラミング言語のリリースで行われました。  C / C ++を拡張し、追加の修飾子とキーワード、関数のライブラリ、カーネルと呼ばれるコードの一部を起動するメカニズム、GPUを追加します。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      CUDAが早期に採用され、独自の製品であり、高品質のCUDAコードを記述することが困難であるという事実と相まって、OpenCL、C ++ AMP、OpenACCなどのアクセラレータプログラミングへの他のアプローチが生まれました。  OpenCLはCUDAの非独占的な対応物であり、多くの大企業のサポートを受けています。  NVidiaチップだけに限らず、AMD GPU、マルチコアCPU、MIC（Intel Xeon Phi）、DSP、FPGAもサポートしているため、ポータブルです。 ただし、CUDAと同様に、非常に低いレベルです。 プログラマーがデータの移動を直接制御する必要があります。また、メモリー階層内の変数の保存場所を直接決定し、コードに手動で並列処理を実装する必要があります。  C ++ Accelerated Massive Parallelism（C ++ AMP）は中間レベルで機能します。 すでにC ++自体で並列アルゴリズムを記述でき、プログラマからすべての低レベルコードを隠します。  「for each」ステートメントは、並列コードをカプセル化します。  C ++ AMPはWindowsに関連付けられており、CPUをまだサポートしておらず、起動時のオーバーヘッドが大きいため、その助けを借りて短期コードを高速化するのは事実上不適切です。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      OpenACCは、すでにアクセラレータープログラミングに対する非常に高度なアプローチであり、プログラマーがコードにディレクティブを提供できるため、コンパイラーにコードのどの部分を加速する必要があるか、たとえばGPUに出荷することによってコンパイラーに通知できます。 この考え方は、OpenMPを使用してCPUプログラムを並列化する方法に似ています。 実際、2つのアプローチを組み合わせる努力がなされています。  OpenACCは熟成段階にあり、現在少数のコンパイラーでのみサポートされています。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     ハードウェアアクセラレータのプログラミング領域が将来どのように発展するかを理解するには、過去に他のハードウェアアクセラレータを使用して同様のプロセスがどのように進行したかを調べる価値があります。 たとえば、初期の高度なPCには追加のプロセッサがありました。これは、浮動小数点計算を実行するコプロセッサです。 その後、中央処理装置（CPU）を備えたチップに統合され、現在ではその一部となっています。 異なるレジスタと算術論理デバイス（ALU）のみがあります。 その後のSIMDプロセッサ拡張（MMX、SSE、AltiVec、AVX）は個別のチップとしてリリースされませんでしたが、現在ではプロセッサコアに完全に統合されています。 浮動小数点演算と同様に、SIMD命令は個別のALUで計算され、独自のレジスタを使用します。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     驚くべきことに、これらの2種類の命令は、プログラマーの観点とは大きく異なります。 材料の種類とその操作は長い間標準化されており（IEEE 754）、今日どこでも使用されています。 これらは、通常の算術演算と組み込みの実データ型（高精度の実数の場合は32ビット、倍精度の場合は64ビット）を通じて、高レベルのプログラミング言語で使用できます。 それどころか、SIMD命令には標準がなく、その存在自体はプログラマにほとんど隠されています。 これらの命令を使用して計算をベクトル化することは、コンパイラに委任されます。 これらの命令を明示的に使用したい開発者は、特別な非クロスプラットフォームマクロを使用してコンパイラに連絡する必要があります。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      GPUおよびMICアクセラレータのパフォーマンスはSIMDの性質によるものであるため、これらの開発は以前のSIMDアクセラレータを介して行われると考えています。  SIMDとそれを成功させたCUDAの主要な機能とのもう1つの類似点は、CUDAがGPUのSIMDエンティティの特性を隠し、プログラマーがベクトルを操作するワープ（ベクトル）ではなく、スカラーデータを操作するストリームの観点から考えることを可能にすることです。 したがって、間違いなく、アクセラレーターもプロセッサーを搭載したチップに転送されますが、プログラマーがハードウェアGPUデータ型に直接アクセスできないように、プログラムコードは通常のCPUコードに十分に埋め込まれないと考えています。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     一部のアクセラレータは、AMD APU（Xbox Oneで使用）、統合されたHDグラフィックスを備えたIntelプロセッサ、NVIDIAのTegra SoCなど、従来のプロセッサとチップ上で既に結合されています。 ただし、アクセラレーターは、数学コプロセッサーおよびSIMD拡張で行われたのと同じ程度に従来のプロセッサーコアと組み合わせること、つまり、中央プロセッサーの一部としてレジスターセットおよび個別のALUにカットすることは難しいため、おそらく別個のコアのままになります。 。 最終的に、アクセラレーターは、切断されたキャッシュ、完全に異なるパイプライン実装、GDDR5メモリ、桁違いに多いレジスターやマルチスレッドなど、CPUとは異なるアーキテクチャーにより、非常に高速、並列、エネルギー効率に優れています。 その結果、アクセラレータでコードを実行する複雑さは依然として残っています。 通常、単一のチップ上に作成されたプロセッサコアでさえも、メモリ階層の下位レベルのみが共通しているため、CPUとアクセラレータ間のデータ交換の速度はおそらく向上しますが、依然としてボトルネックのままです。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     デバイス間のデータ交換のプロセスを明示的に制御する必要性は、エラーの重大な原因であり、プログラマに大きな負担がかかります。 小さなアルゴリズムでは、計算そのものよりも多くのコードを記述してデータの交換を編成する必要があることがよくあります。 この負担をなくすことは、C ++ AMPやOpenACCなどの高レベルプログラミングアプローチの主な利点の1つです。 低レベルの実装でさえ、この問題を解決することを目的としています。 たとえば、よくデバッグされ統合されたメモリアクセスは、CUDA、OpenCL、およびNVIDIA GPUハードウェアソリューションの最新バージョンで行われた主な改善点の1つです。 それでも、優れたパフォーマンスを実現するには、OpenACCなどの非常に高レベルのソリューションであっても、通常はプログラマーの助けが必要です。 特に、必要な場所でのメモリの割り当てとデータの転送は、多くの場合手動で行う必要があります。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     残念ながら、そのようなアプローチによって提供されるすべての単純化は、部分的な解決策にすぎないことが判明する場合があります。 将来のプロセッサが今日の（小型の）スーパーコンピューターに近いことを考えると、共有メモリで処理できるよりも多くのコアを搭載する可能性があります。 代わりに、各結晶には核のクラスターがあり、各クラスターには独自のメモリがあり、おそらくこれらの核の上に3次元空間で配置されると考えています。 クラスターは、MPIなどのプロトコルを使用して同じチップ上で実行されるネットワークによって相互に接続されます。 インテルは、ネットワーク機能が将来のXeonチップに追加されることを発表したばかりであり、これはその方向への一歩であるため、これは真実からそれほど遠くありません。 したがって、将来的には、レイテンシとスループットに最適化されたコアを組み合わせることにより、チップがますます不均質になる可能性があります。 ネットワークアダプター、圧縮およびエンコードセンター、FPGAなど 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     これは、そのようなデバイスをどのようにプログラムするかについて非常に重要な質問を提起します。 この質問に対する答えは、マルチコアCPU、SIMD拡張機能、および既存のハードウェアアクセラレータの今日の解決方法に驚くほど似ていると信じています。 これは、ライブラリ、自動化ツール、日曜大工と呼ばれる3つのレベルで発生します。 ライブラリ-誰かがすでにアクセラレータ用に最適化したライブラリからの関数への単純な呼び出しに基づいた最も単純なアプローチ。 多くの最新の数学ライブラリはこのクラスに属します。 ほとんどのプログラム計算がこれらのライブラリ関数で実行される場合、このアプローチの適用は完全に正当化されます。 これにより、複数の専門家が1つの優れたライブラリを作成して、このライブラリが使用される多くのアプリケーションを高速化できます。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      C ++ AMPおよびOpenACCは、異なるアプローチ-自動化ツールを使用します。 このアプローチでは、ハードワークがコンパイラに転送されます。 その成功は、既存のソフトウェアツールの品質と複雑さに依存し、前述のように、多くの場合、プログラマーの介入が必要です。 それにもかかわらず、ほとんどのプログラマーは、ライブラリーから事前定義された関数を使用することに限定されないこのアプローチを使用して、すぐに良い結果を達成できます。 これは、複数の専門家グループがSQLの「内部」を実装する方法に似ており、通常の開発者は将来的に既製の最適化されたコードを使用できます。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     最後に、日曜大工アプローチがCUDAおよびOpenCLで使用されます。 プログラマーは、ほぼすべてのアクセラレーターリソースへのアクセスを完全に制御できます。 実装が適切であれば、結果のコードは、前の2つのコードのいずれよりも優れています。 しかし、これはこのアプローチを研究するための相当な努力によって達成され、多くの追加コードを作成し、可能性のあるエラーの余地を増やします。 開発環境およびデバッグ環境に対するあらゆる種類の改善により、これらのすべての問題を軽減できますが、ある程度までしかできません。 したがって、このアプローチは主に専門家に役立ちます。 前の2つのアプローチで述べた方法を開発している人。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     ライブラリの使いやすさにより、プログラマは可能な限りライブラリを使用できます。 ただし、これは、対応するライブラリ関数が存在する場合にのみ可能です。 人気のある地域では、そのようなライブラリが通常存在します。 たとえば、行列の操作（BLAS）。 しかし、関連分野や計算が構造化されていない場所では、アクセラレータライブラリを実装することは困難です。 適切なライブラリがない場合、もちろん十分に開発されていない限り、プログラマは自動化ツールを選択します。 ライブラリの形式では利用できず、パフォーマンスをそれほど要求せず、コンパイラによってサポートされる計算は、ほとんどの場合、自動化ツールを使用して実装されます。 それ以外の場合は、日曜大工メソッドが使用されます。  OpenCLはCUDAで提示された成功したソリューションを結合し、プロプライエタリではなく、さまざまなハードウェアソリューションをサポートしているため、MPIが分散メモリシステムのプログラミングの事実上の標準になったように、この分野で支配的になると考えています。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     上記のハードウェア機能と進化プロセスを考慮すると、将来のプロセッサチップには独自のメモリを持つ多くのクラスタが含まれると言えます。 各クラスターは多くのコアで構成されますが、すべてのコアが機能的に同一というわけではありません。 各マルチスレッドコアは多数のコンピューティングユニット（つまり、機能ユニットまたはALU）で構成され、各コンピューティングユニットはSIMDコマンドを実行します。 将来のチップにこのすべてが一度に含まれない場合でも、それらはすべて1つの重要な類似性、つまり並列レベルの階層を持ちます。 このようなシステム用の効率的で移植性の高いプログラムを作成するために、大量並列処理手法と呼ばれるものを提案します。 これは、プログラマーがMPIプログラムを異なる数のコンピューティングノードに適応させる方法、またはOpenMPコードが異なる数のコアまたはスレッドに暗黙的に適応する方法の一般化です。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     広範な並行性の基本的な考え方とこの名前の理由は、あらゆるレベルで、パラメーター化可能な広大な並行性機能を提供することです。 パラメータ化により、任意のレベルでプログラムの並列度が低下し、このレベルのハードウェア並列度と一致します。 たとえば、共有メモリを備えたシステムでは、最高レベルの並列処理は不要であり、1つの「クラスター」にインストールする必要があります。 同様に、計算ユニットがSIMD命令を実行できないカーネルでは、SIMDの幅を指定するパラメーターを1に設定する必要があります。 この手法を使用すると、マルチコアCPU、GPU、MIC、およびその他のデバイスの機能を実装できるだけでなく、将来のハードウェアアーキテクチャも実装できます。 この方法でプログラムを作成することは間違いなく困難ですが、広範な並行性により、単一のコードベースを使用して幅広いクラスのデバイスから高いパフォーマンスを引き出すことができます。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     このアプローチは、n体の直接モデリングの問題で<a href="http://cs.txstate.edu/~mb92/papers/sac14.pdf">テスト</a>しました。  OpenCLを使用した広範な並列処理アルゴリズムの唯一の実装を作成し、NVIDIA GeForce Titan GPU、AMD Radeon 7970 GPU、Intel Xeon E5-2690 CPU、Intel Xeon Phi 5110P MICの4つの完全に異なるハードウェアアーキテクチャで測定しました。 すべての浮動小数点演算の54％がFMA演算（FMA-累積と乗算の演算）ではないことを考慮すると、広範な並列処理により、NVIDIA Titanの理論上のピークの75％、Radeonの95％、CPUの80.5％のパフォーマンスを達成できました。 MICの場合は80％。 これは単なる別の例ですが、その結果は非常に有望です。 実際、既存および将来のハードウェアアクセラレータシステム用のポータブルで高性能なプログラムを作成するための唯一のアプローチは、ある程度の同時実行性であると考えています。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      <i>[ <a href="http://ht.ly/sGPb0">ソース</a> ]</i> <i>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    </i>  <i>2014年1月9日</i> <i>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    </i>  <i>カミル・ロッキーとマーティン・バーチャー</i> </div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../J209592/index.html">変更するが検証する：インターフェース設計におけるWeb分析の役割</a></li>
<li><a href="../J209594/index.html">ハードウェアの起動を簡単にする</a></li>
<li><a href="../J20960/index.html">RU-CENTERは個人データを隠すことができます</a></li>
<li><a href="../J209600/index.html">未知からの驚き：Chrome拡張機能への信頼</a></li>
<li><a href="../J209604/index.html">ウクライナの法的分野内にDOU.uaが存在することはできません</a></li>
<li><a href="../J20961/index.html">ここに</a></li>
<li><a href="../J209610/index.html">最適化の概要。 シミュレーテッドアニーリング</a></li>
<li><a href="../J209612/index.html">Laravel 4上のクライアントとサーバー間の暗号化された通信</a></li>
<li><a href="../J209614/index.html">ユニバーサリウムコース開始</a></li>
<li><a href="../J209616/index.html">ロールプレイングゲームの技術。 パート3.周囲の技術とマスタリング</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter70218013 = new Ya.Metrika({
                  id:70218013,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/70218013" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'G-FEDBM7F51Q', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Clever Geek | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <div class="company-info js-company-info" itemscope="" itemtype="http://schema.org/Organization">
      <span itemprop="name">Western Town Media (WTM)</span>
      <div itemprop="address" itemscope="" itemtype="http://schema.org/PostalAddress">
        <span itemprop="streetAddress">1968 Stoney Lonesome Road</span>
        <br>
        <span itemprop="postalCode">PA 18640</span>
        <span itemprop="addressLocality">Pittston, USA</span>
      </div>
      <span itemprop="telephone">570-362-1316</span>
    </div>
    <script type="application/ld+json">
      {
        "@context": "http://schema.org",
        "@type": "Organization",
        "address": {
          "@type": "PostalAddress",
          "addressLocality": "Pittston, USA",
          "postalCode": "PA 18640",
          "streetAddress": "1968 Stoney Lonesome Road"
        },
        "name": "Western Town Media (WTM)",
        "telephone": "570-362-1316"
      }
    </script>
  </div>
</footer>
  
</body>

</html>