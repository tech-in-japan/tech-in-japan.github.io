<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-FEDBM7F51Q"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-FEDBM7F51Q');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>⛔️ 😋 👕 畳み込みニューラルネットワークとリカレントニューラルネットワークを使用して、文書のテキスト文字列を文字に分割 👰🏾 💯 🐾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="文字列を文字に分割することは、光学式文字認識（OCR）のプロセス、特に文書画像の光学的認識における最も重要なステップの1つです。 ラインセグメンテーションは、一連の文字を含む画像を個々の文字を含むフラグメントに分解することです。 
  
 
  
 セグメンテーションの重要性は、最新の光学式テキスト...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <link rel="sitemap" type="application/xml" href="/sitemap.xml"/>

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>

  <script>document.write('<script src="https://pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://tech-in-japan.github.io/index.html"></a>
    <div class="page-header-text">Clever Geek Handbook</div>
  </header>
  <section class="page js-page"><h1>畳み込みニューラルネットワークとリカレントニューラルネットワークを使用して、文書のテキスト文字列を文字に分割</h1><div class="post__text post__text-html js-mediator-article" id="post-content-body" data-io-article-url="https://habr.com/ru/company/smartengines/blog/328000/"> 文字列を文字に分割することは、光学式文字認識（OCR）のプロセス、特に文書画像の光学的認識における最も重要なステップの1つです。 ラインセグメンテーションは、一連の文字を含む画像を個々の文字を含むフラグメントに分解することです。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     セグメンテーションの重要性は、最新の光学式テキスト認識システムは、単語やテキストの断片ではなく、個々の文字の分類器（ニューラルネットワークを含む）に基づいているためです。 そのようなシステムでは、通常、キャラクター間のセクションを誤って切断するエラーが、最終的な認識におけるエラーの大部分の原因です。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     文字の境界の検索は、文書の印刷およびデジタル化（スキャン）のアーティファクトにより複雑になり、文字の「散乱」および「接着」につながります。 据え置きまたはモバイルの小型ビデオカメラを使用する場合、デジタル化アーティファクトの範囲が大幅に拡大されます。デフォーカスとぼかし、投影歪み、ドキュメントの変形と曲げが可能です。 自然なシーンでカメラを撮影する場合、画像はしばしば、明るさ（影、反射）の迷い違いを引き起こし、低光量の結果としての色の歪みとデジタルノイズを引き起こします。 次の図は、ロシア連邦のパスポートのフィールドをセグメント化する際の複雑なケースの例を示しています。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/files/f35/6b6/46c/f356b646c0ba460eb600ec5bb3fec842.jpg" height="70" width="350"><img src="https://habrastorage.org/files/b88/5a6/59d/b885a659dd5c4108878619e985f67769.jpg" height="70" width="350">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/files/a39/971/46a/a3997146a5c64213b4abd26d0eaf2c3b.jpg" height="70" width="350"><img src="https://habrastorage.org/files/c03/f5f/6bc/c03f5f6bc33b4f40821e3ed48cf28056.jpg" height="70" width="350">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/files/5a4/906/ea3/5a4906ea3edd4969bef564ca9a01738c.jpg" height="70" width="350"><img src="https://habrastorage.org/files/25d/414/ea5/25d414ea58a14e3b8b8437c03aa58df6.jpg" height="70" width="350">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     この記事では、畳み込みニューラルネットワークとリカレントニューラルネットワークのトレーニングに基づいて、 <a href="http://smartengines.ru/">Smart Engine</a>で開発したドキュメントのテキスト文字列の文字を分割する方法について説明します。 仕事で考慮される主要な文書<a href="https://habrahabr.ru/company/smartengines/blog/252703/">は、ロシア連邦のパスポートです</a> 。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <a name="habracut"></a>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h2> 機械学習法を使用したエンドツーエンドのセグメンテーション </h2>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     機械学習法は、現代のセグメンテーションアルゴリズムで広く使用されています。 ただし、それらの使用は通常、訓練された文字認識モデルの主要セクションの生成や、このモデルの出力推定値の動的プログラミングなど、追加のアルゴリズムと組み合わされます。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     興味深いのは、機械学習手法を使用して、追加の予備処理および後続処理（英語のエンドツーエンド）を実質的に追加せずに文字列の画像を分析するセグメンテーションアルゴリズムの開発です。 このようなアプローチは、特定のケース（フォント、フィールドの種類、ドキュメントの種類）を手動で微調整する必要はないが、十分なサイズの代表的なラベル付きトレーニングサンプルが必要であるという事実によって区別されます。 これにより、新しいタイプのドキュメントフィールド用のセグメンテーションアルゴリズムの作成を簡素化および高速化し、撮影中に発生するさまざまな歪みに対する精度と耐性を高めることができます。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h2> セグメンテーション手法の品質の評価 </h2>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     アルゴリズムの開発と同様に、セグメンテーション方法の開発では、作業の品質を評価する方法を修正する必要があります。 この方法で、開発した方法を他のアルゴリズムと比較できることが非常に望ましいです。 ロシア連邦のパスポートのフィールドのセグメンテーションの方法を評価するために、このペーパーで使用される品質指標について説明します。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     文字へのテキストセグメンテーションの目的は、その後の認識であり、セグメンテーションアルゴリズムの品質の評価として最終認識の品質を使用することの人気を決定します。 認識アルゴリズムの品質の評価は、個々の文字または単語の認識の精度と、レーベンシュタインの平均距離の両方になります。 この作品のロシア連邦のパスポートの認識システムの品質指標は、単一のフィールドでの単一のエラーの高コストのために、シンボルに正確な各ドキュメントフィールド（名前、姓、出生地など）の完全な認識の正確さに基づいていました人を識別するフィールドのシンボルは重要です。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     ただし、認識の品質を介してセグメンテーションの品質を評価する場合、特定の認識モデルへの推定値の依存性が生じます。 これは、さまざまなセグメンテーションアルゴリズムと認識アルゴリズムの互換性が失われるため、統合システムを開発する際の問題です。 したがって、開発中に、精度、完全性、F1メジャーなど、セグメンテーションアルゴリズムによって設定された文字間の直接の境界の分析のみに基づいて、追加の品質メトリックが使用されました。 これは、フィールド内のキャラクターだけでなく、この作品で準備されたが常に利用できるわけではない人々によって準備されたキャラクター間のカットの「理想的な」マーキングがある場合に可能になります。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h2> トレーニングサンプルの準備と人為的な拡張 </h2>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     トレーニングサンプルには、ロシア連邦のパスポートの選択されたフィールドの画像が含まれており、テキストのベースラインに沿ってカットされ、キャラクター間の理想的なカットのマークされた位置が含まれています。 マークアップは完全に手動または半自動で実行できます。既存のセグメンテーションアルゴリズムはカットを付加し、その後、人がチェックし、必要に応じて調整します。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     ロシア連邦のパスポートのサンプルを準備し、それをマークアップすることは、膨大な手作業のためだけでなく、高価な作業です。 身分証明書には個人情報が含まれており、その売り上げは法律で規制されているため、ロシア連邦のパスポートの多数の画像を含むデータベースに公然とアクセスすることはできません。 ギョーシェ、ホログラムなど、ロシアのパスポートのバックグラウンドセキュリティ要素のオープン仕様がないため、完全に人工的なサンプルを作成することも難しいことに注意してください。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     したがって、撮影条件やフィールドガイダンスエラーに強い高精度の近似器をトレーニングするのに十分な量のサンプルをコンパイルすることは問題です。 安定性を高めるために、データ変換を使用し<a href="https://habrahabr.ru/company/smartengines/blog/264677/">た</a>トレーニングサンプルの<a href="https://habrahabr.ru/company/smartengines/blog/264677/">人為的拡張（拡張）を</a>使用します。 各サンプルの合成は、実フィールド画像の変換をシミュレートするランダムな変換セットを適用することにより実行されます。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     ロシア連邦のパスポートのフィールドのトレーニングサンプルを拡張するために、以下が適用されました：ガウスノイズの歪み、モバイルデバイスからの撮影条件でのドキュメントの境界の不完全な位置をシミュレートする射影歪み、焦点をぼかすことをシミュレートするガウスぼかし、および文字の高さと幅のストレッチ（これらの文字設定は大きく異なる場合があります）異なる地域からのパスポート）、垂直および水平シフト（実際のフィールドガイダンスシステムのエラーがモデル化されています）。 サンプルを拡張するための追加の方法も使用されました。文字と鏡面反射の混合は生体内では見られませんが、実験ではそのような拡張を適用すると精度が向上することが示されています。 次に、説明されている変換の図を示します。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <table><tbody><tr><th> 変換 </th><th> イラスト </th></tr><tr><td> 元の画像 </td><td><img src="https://habrastorage.org/files/09e/c51/3bb/09ec513bbe75453b9c3c148d9de33f2e.png"></td></tr><tr><td> ガウスノイズ </td><td><img src="https://habrastorage.org/files/ad8/75d/679/ad875d6790db40419fcd59f63fd7a152.png"></td></tr><tr><td> 射影歪み </td><td><img src="https://habrastorage.org/files/f63/30c/317/f6330c3171e14e64be4101a5560f7188.png"></td></tr><tr><td> ガウスぼかし </td><td><img src="https://habrastorage.org/files/064/81e/912/06481e912cfb43dba5794bc9d0ef2d5a.png"></td></tr><tr><td> シフト </td><td><img src="https://habrastorage.org/files/1b4/a72/1bc/1b4a721bc9e643fa8f2236dddb9006fe.png"></td></tr><tr><td> シャッフル文字 </td><td><img src="https://habrastorage.org/files/6b0/715/8af/6b07158afe1f40a98d9ea523dac5825d.png"></td></tr><tr><td> 反射 </td><td><img src="https://habrastorage.org/files/c34/cce/832/c34cce8325794184b3e6d612bd489ff7.png"></td></tr><tr><td> 捻rain </td><td><img src="https://habrastorage.org/files/a81/126/d62/a81126d627be4fdc8023bb6daa1a3c33.png"></td></tr><tr><td> 変換の組み合わせ </td><td><img src="https://habrastorage.org/files/3e1/94a/8b0/3e194a8b0f904e4ca01019e9fdc2f03c.png"></td></tr></tbody></table>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h2> レイアウト形式とネットワーク出力ベクトル </h2>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     使用する汎用近似器のタイプに関係なく、そのトレーニングと操作のために、モデルパラメーターのトレーニング段階のトレーニングセットで最小化される損失（エラー）関数を決定する必要があります。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     標準偏差（RMS）は、連続性と微分可能性の要件を満たす古典的な損失関数です。 セグメンテーションアルゴリズムの最終的な答えはセクション位置のリストです。したがって、理論的には、対応する出力セクション間の標準偏差（RMS）と、それらの間の平均距離としての「理想」を適合させることができます。 残念ながら、単純な実装では、特にニューラルネットワークを使用している場合、このアプローチでは問題が発生します。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     文字間のカット数および文字自体の数は固定されておらず、セグメンテーションアルゴリズムは、必要なカット数を事前に知りません。 次に、マークアップとセグメンテーションアルゴリズムの出力でのカットの数が一致する場合、距離に対する誤差関数が適切です。 ただし、カットの数が異なると、特に損失関数の合理的な要件がある場合に、欠落したカットまたは過剰なカットの損失を計算する問題が発生します。 さらに、ニューラルネットワークの出力数は同じアーキテクチャ内で固定されており、出力の動的な数をサポートするには、モデルの不当な複雑さと混乱が必要です。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     したがって、任意の許容カット数の設定をサポートするようなマーキング形式とネットワーク出力が必要ですが、対応する損失関数は勾配ニューラルネットワークトレーニングでの使用に適したままです。 次のモデルを使用することを提案します。セクションの座標のリストの代わりに、画像ピクセルの各列におけるセクションの位置の実際の確率的推定値を考慮します。 セクションのレイアウトは次のようになります。ユニットがあるセクションの位置を除き、すべての位置にゼロが表示されます。 この場合の標準偏差も損失関数として適していますが、確率推定ベクトル間ですでに計算されています。 アルゴリズムの出力でのカットの最終位置は、出力確率推定値を変換することによって取得されます。これについては後で詳しく説明します。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     特にセグメンテーションアルゴリズムが文字の境界に直接（2つの文字の間に2つの切れ目があるように）切れ目ではなく、中央の領域（文字間に1つの切れ目がある）に切れ目を配置する場合、マークアップからの切れ目に関する小さな変動は通常、認識品質に大きく影響しません。 この場合、上記で提案された損失関数は、その距離に関係なく、理想的なカットに対応しない位置での出力確率を等しく細かくします。 したがって、ネットワーク出力のわずかな変動で細かさを軽減するために、テストサンプルからのこの画像のシンボルの平均幅に比例する半径のマーキングのガウスぼかしを使用することを提案します。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h2> 畳み込みニューラルネットワークを使用した畳み込みセグメンテーション </h2>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     画像解析タスクで最も人気のあるニューラルネットワークアーキテクチャの1つは、トレーニングされたセグメンテーション手法を作成するための最初の実質的な実験で選択されたディープコンボリューショナルネットワークアーキテクチャです。 古典的な畳み込みネットワークモデルは、特徴マップの次元を減らすために最大プーリングと交互に、トレーニングされたカーネルで畳み込み操作を適用することにより特徴マップを構成するいくつかの畳み込み層で構成されます。 最後の層（出力層で終わる）には、完全に接続されたアーキテクチャがあります。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     作業で使用されるニューラルネットワークの場合、入力データ（機能ベクトル）は、ロシア連邦のパスポートフィールドのハーフトーンラスターイメージで、固定幅と高さ（200x20ピクセルなど）に縮小されています。 画像列のセクションの存在の確率的推定値をそれぞれ返す出力レイヤーのサイズも、200ピクセルに固定されています。 次の図は、作業で使用される畳み込みニューラルネットワークを示しています。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/files/01a/0c2/0ac/01a0c20acc764a33a791fad48b79f6ed.png">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     ニューラルネットワークの隠れた部分は、畳み込み層で構成され、その後に2つの完全に接続された層が続きます。 各畳み込み層の後にはサブサンプリング層が続きます。 活性化関数として、双曲線正接が使用されました。 トレーニング中に、隠れ層の活性化関数のランダムな選択的ゼロ化（ドロップアウト）の手法が使用されました。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h2> リカレントニューラルLSTMネットワークを使用した追加のセグメンテーション </h2>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     説明されたアーキテクチャの訓練されたセグメンテーションネットワークの精度を高めるために、追加の双方向リカレントネットワークの入力に適用することにより、畳み込みネットワーク出力の後続処理の方法が適用されました。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     再帰的ニューラルネットワークは、シーケンスを操作するために特別に設計されています。シーケンスの次の要素に加えて、独自の隠された状態を受け入れます。 私たちは、長い短期記憶のアーキテクチャ（LSTM、Long Short-Term Memory）のリカレントニューラルネットワークを使用しました。これは、印刷および手書きのテキスト、音声などの認識など、シーケンス分析の多数のアプリケーションで実証されています。  LSTMアーキテクチャネットワークは、シーケンス構造を「記憶」できます。 行分割の場合、構造は、たとえば、行の文字の平均幅と文字間の距離として理解できます。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     使用される双方向リカレントLSTMネットワークは、固定サイズ（たとえば10）のスライディングウィンドウを畳み込みネットワークの確率的推定値の出力ベクトルに適用することで構成される入力シーケンスを受け取ります。 したがって、リカレントネットワークの入力ベクトルのi位置には、最後の10個の畳み込み出力が含まれます。 ネットワークの両側の向きは、2つの一方向ネットワークを作成することです。1つは左から右にシーケンスを処理し、もう1つは右から左にシーケンスを処理します。 次に、元のシーケンスの同じ位置に対応する両方のネットワークの出力ベクトルが連結され、完全に接続されたレイヤーの入力に送信され、最後のレイヤーが続き、同様の最終確率推定が返されます。 繰り返しトレーニングが行われる畳み込みネットワークの出力は事前に計算されているため、繰り返しのトレーニング中に畳み込みネットワークは変化せず、トレーニングが大幅に高速化されることに注意することが重要です。 以下の図には、畳み込み出力で使用されるリカレントネットワークアーキテクチャの図が含まれています。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <div style="text-align:center;"><img src="https://habrastorage.org/files/5d5/7c3/64a/5d57c364ad4943b4b586dcd4979d798a.png"></div>
      
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     畳み込み出力でリカレントネットワークを追加すると、全体的な最終認識品質が大幅に向上しました。これは、記事の最後の表に示されています。  LSTMネットワークのアクティベーション関数も双曲線正接でした。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h2> 確率推定値から最終セクションへの変換 </h2>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     アルゴリズムの出力でカットの最終位置を取得するには、確率推定値の変換を実行する必要があります。 ネットワークの出力推定値が提案されたセクションの周囲に多数集中しているため、単純なしきい値フィルタリングはこの場合には適していません。 ニューラルネットワークは、セクションの位置の周りのガウスぼかしの対象となるマーキングを近似しているため、確率をセクションに変換するかなり安定した簡単な方法はフィルタリングでき、カットオフに続く推定値の局所的な最大値のみを低しきい値で残します。 ノイズ操作を排除するために、追加のガウスぼかしが使用されますが、これは強い最大値の位置を変更しません。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     極大値をフィルタリングする方法は簡単で、良い結果を示しましたが、確率変換の段階で「エンジニアリング」アプローチを完全に取り除くことができるかどうかを確認することにしました。 実験の目的で、少数の訓練された重みを持つ完全に接続されたアーキテクチャの別のネットワークが訓練され、最終ネットワークの最終確率出力を受信し、出力で同じ確率推定を返します。 違いは、ガウスぼかしにさらされずに、セクションの元のマークで学習することです。 最後のネットワークの出力での確率的推定は、セクションの最終位置を取得するための追加処理なしで、すでに単純なしきい値フィルタリングの対象となります。 次の図は、説明した学習器セグメンテーションアルゴリズムの動作と中間結果の出力の例を示しています。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/files/781/32c/009/78132c00984c43768c3639599d24f168.jpg" height="120" width="350"><img src="https://habrastorage.org/files/488/cd8/f76/488cd8f7634f47499d089b4c8ca963f2.jpg" height="120" width="350">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/files/77e/397/afe/77e397afe7a14a298d5255592d21749a.jpg" height="120" width="350"><img src="https://habrastorage.org/files/9bf/926/1ce/9bf9261ced9242ee97e431a4c6e74797.jpg" height="120" width="350">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/files/e14/e21/d74/e14e21d74d644fc48c8dd86016f52089.jpg" height="120" width="350"><img src="https://habrastorage.org/files/714/ea8/a73/714ea8a735a445e69b9eec9c88f2889e.jpg" height="120" width="350">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     赤い背景は、畳み込みネットワークの出力での確率的推定値を示し、黄色の背景はそれに続くリカレントネットワークを示します。 緑色は、固定しきい値でフィルター処理されたリカレントネットワークの確率的推定値を示し、最後に、青色は残りのセクション（フィルター処理された推定値）を示します。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h2> 実験と結果 </h2>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     実験におけるロシア連邦のパスポートの主なフィールドは、姓、名、および愛顧のフィールドでした。 最初のトレーニングサンプルのサイズは、データ合成による拡張後の6000イメージで、150,000イメージでした。 認識なしの補助メトリックによるセグメンテーションを評価するためのテストサンプルのサイズは、630画像です。 フィールド認識のテストサンプルには、ロシア連邦のパスポートの1300枚の画像が含まれており、ドキュメントの各フィールドの画像が1枚ありました。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     セグメンテーション結果のフィールドを認識するとき、ロシア連邦の同じパスポート認識システムが変更なしで使用されました。 フィールド認識用に設計されたニューラルネットワークは、従来の「エンジニアリング」セグメンテーションメソッドを使用してクリンプされたシンボルでトレーニングされ、トレーニングされたセグメンテーションアルゴリズムによって公開されたセクションは、追加の処理および圧縮システムなしで認識システムに送信されたことに注意することが重要です。 次の表には、フィールドによる最終認識の精度の実験結果（完全に正しく認識されたフィールドの割合）が含まれています。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <table><tbody><tr><th> セグメンテーションアルゴリズム </th><th> 姓、％ </th><th> 名前、％ </th><th> ミドルネーム、％ </th></tr><tr><td> 畳み込みネットワーク </td><td>  68.53 </td><td>  76.00 </td><td>  78.30 </td></tr><tr><td> 畳み込みネットワーク出力でのリカレントネットワーク </td><td>  86.23 </td><td>  90.69 </td><td>  91.38 </td></tr></tbody></table>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     この表は、セグメンテーションサブシステムの畳み込みネットワークの出力にリカレントネットワークを追加すると、フィールド認識の精度が大幅に向上することを示しています。 処理には、モバイルデバイスからの撮影時に生体内でパスポートの境界を見つけることが含まれます。これは、不完全な認識精度を説明します。最も好ましくないサンプルは、撮影中に発生する歪みなどの観点から選択されました。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     セグメンテーション手法の学習の実験では、PythonのLasagneパッケージのニューラルネットワークの実装を使用しました。 訓練されたモデルは、ニューラルネットワークライブラリの内部C ++形式にさらに変換されました。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h2> おわりに </h2>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     この記事では、印刷されたテキストフィールドのセグメンテーションの方法を検討し、ロシア連邦市民のパスポート認識システムのセグメンテーションモジュールの例について実験的分析を行いました。 この方法では、作業のほぼすべての段階で機械学習アプローチ（人工ニューラルネットワーク）を使用します。これにより、新しいタイプのフィールドとドキュメントのセットアッププロセスが完全に自動化され、トレーニングサンプルの可用性に応じて、方法の見込みが決まります。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     機械学習アプローチに基づくセグメンテーション手法のさらなる研究として、他のタイプのフィールドおよびドキュメントで実験を実施し、エラーを分析および分類して、トレーニングサンプルを拡大する新しい方法を形成するとともに、モバイルデバイスでのメソッドのパフォーマンスをプロファイリングおよび最適化することが計画されています訓練されたパラメータの数を減らします。 また、リカレントニューラルネットワークを使用して、セグメンテーションなしで単語全体またはフィールド全体を統合的に認識する方法の研究も興味深いものです。 </div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../J327986/index.html">WebRTCを介してWebページからビデオストリームをFacebookとYouTubeに同時にストリーミングします</a></li>
<li><a href="../J327994/index.html">静的アナライザーを使用したValgrind Dynamic Analyzerコードの確認</a></li>
<li><a href="../J327996/index.html">FPGA上のエミュレータBK-0010</a></li>
<li><a href="../J327998/index.html">Outsource-People Conference 2017、クラクフ（2日目）</a></li>
<li><a href="../J3280/index.html">カルマ変更に関するコメントの追加と表示</a></li>
<li><a href="../J328002/index.html">SimplePage：ラピッドプロトタイピング用のシンプルで宣言的なフレームワーク</a></li>
<li><a href="../J328004/index.html">パート3.ブロックチェーン上の分散アプリケーションのデータをどこに保存しますか？</a></li>
<li><a href="../J328006/index.html">「Gitlabでの出来事は非常に優れた、明らかな物語です」-PostgreSQL管理に関するAlexey Lesovsky</a></li>
<li><a href="../J328010/index.html">CMakeを使用してstm32duinoでビルドします（そしてリンカーをレーキします）</a></li>
<li><a href="../J328012/index.html">フロントエンドアーキテクチャの中心としてのRedux</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter70218013 = new Ya.Metrika({
                  id:70218013,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/70218013" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'G-FEDBM7F51Q', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Clever Geek | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <div class="company-info js-company-info" itemscope="" itemtype="http://schema.org/Organization">
      <span itemprop="name">Western Town Media (WTM)</span>
      <div itemprop="address" itemscope="" itemtype="http://schema.org/PostalAddress">
        <span itemprop="streetAddress">1968 Stoney Lonesome Road</span>
        <br>
        <span itemprop="postalCode">PA 18640</span>
        <span itemprop="addressLocality">Pittston, USA</span>
      </div>
      <span itemprop="telephone">570-362-1316</span>
    </div>
    <script type="application/ld+json">
      {
        "@context": "http://schema.org",
        "@type": "Organization",
        "address": {
          "@type": "PostalAddress",
          "addressLocality": "Pittston, USA",
          "postalCode": "PA 18640",
          "streetAddress": "1968 Stoney Lonesome Road"
        },
        "name": "Western Town Media (WTM)",
        "telephone": "570-362-1316"
      }
    </script>
  </div>
</footer>
  
</body>

</html>