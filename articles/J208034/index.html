<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-FEDBM7F51Q"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-FEDBM7F51Q');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🦌 📒 🤾🏾 機械学習 正月休みをお得に過ごしたい人のためのYandexのコース 🚹 👩🏻‍🔬 ⚠️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="正月休みは、リラックスするだけでなく、独学にも適しています。 日常のタスクから逃れ、数年間、一年中（そし​​ておそらく1つではない）役立つ新しい何かを学ぶことに専念できます。 そのため、今週末は、データ分析学部の最初の学期に一連の講義コースを公開することにしました。 
  
 
  
 今日は最も重...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <link rel="sitemap" type="application/xml" href="/sitemap.xml"/>

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>

  <script>document.write('<script src="https://pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://tech-in-japan.github.io/index.html"></a>
    <div class="page-header-text">Clever Geek Handbook</div>
  </header>
  <section class="page js-page"><h1>機械学習 正月休みをお得に過ごしたい人のためのYandexのコース</h1><div class="post__text post__text-html js-mediator-article" id="post-content-body"> 正月休みは、リラックスするだけでなく、独学にも適しています。 日常のタスクから逃れ、数年間、一年中（そし​​ておそらく1つではない）役立つ新しい何かを学ぶことに専念できます。 そのため、今週末は、データ分析学部の最初の学期に一連の講義コースを公開することにしました。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     今日は最も重要なことです。 それなしで現代のデータ分析を想像することは不可能です。 コースの一部として、先例による学習の主な目的が考慮されます：分類、クラスタリング、回帰、次元の低下。 過去10〜15年にわたって作成された、古典的および新規の両方のソリューションの方法を研究しています。 重点は、検討中のメソッドの数学的基礎、相互接続、利点および制限の深い理解にあります。 別の定理が証明付きで与えられます。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <iframe src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://video.yandex.ru/iframe/ya-events/m-69601-150442cd519-a40e2fa0384c4fcc/&amp;xid=17259,15700022,15700186,15700190,15700256,15700259,15700262,15700265,15700271,15700280,15700283&amp;usg=ALkJrhgFU6bb_iwhdeMNCmRoHCmnHOamvQ" width="450" height="253" frameborder="0" scrolling="no" allowfullscreen="1"></iframe>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     講義コースKonstantin Vyacheslavovich Vorontsov、ロシア科学アカデミーコンピューティングセンター主任研究員。  CJSC Forexis科学副局長。 部門「インテリジェントシステム」FUPM MIPTの副部長。  「予測の数学的手法」VMiK MSU部門の准教授。  Yandexのエキスパート。 物理科学および数理科学の博士。 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <a name="habracut"></a>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4>  <a href="">講義1.適用される問題の基本概念と例</a> </h4>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <ul><li> 前例による学習目標の設定。 オブジェクトと標識。 スケールのタイプ：バイナリ、名目、順序、定量。 </li><li> タスクの種類：分類、回帰、予測、クラスタリング。 </li><li> 基本概念：アルゴリズムのモデル、トレーニング方法、損失関数および品質関数、経験的リスクを最小化する原理、能力の一般化、制御の移動。 </li><li> 適用されたタスクの例。 </li></ul>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4>  <a href="">講義2.ベイジアン分類アルゴリズム、ノンパラメトリック手法</a> </h4>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <ul><li> 分類問題の確率的ステートメント。 重要な概念：事前確率、事後確率、クラス尤度関数。 </li><li> 中リスクの機能。  IおよびIIの種類のエラー。 </li><li> 最適ベイズ分類器。 </li><li> 分布密度の推定：3つの主なアプローチ。 </li><li> 単純ベイズ分類器。 </li><li>  Parzen-Rosenblattによる分布密度のノンパラメトリック推定。 カーネル機能の選択。 ウィンドウ幅の選択、可変ウィンドウ幅。  Parzenovskyウィンドウメソッド。 </li><li> ノンパラメトリックナイーブベイズ分類器。 </li><li> 堅牢な密度推定。 サンプルの検閲（放出オブジェクトのスクリーニング）。 </li></ul>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4>  <a href="">講義3.パラメトリック手法、通常の判別分析</a> </h4>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <ul><li> 多次元正規分布：幾何学的解釈、サンプルパラメーター推定：数学的期待ベクトルと共分散行列。 </li><li> 二次判別式。 分割面のタイプ。 置換アルゴリズム、その欠点、およびそれらを除去する方法。 </li><li> フィッシャー線形判別。 </li><li> 多重共線性と再訓練の問題。 共分散行列の正則化。 </li><li> 次元削減方法。 </li><li> 分布ミックスモデル。 </li><li>  EMアルゴリズム：基本的な考え方、隠れた変数の概念、Eステップ、Mステップ。  Mステップ式の構成的導出（収束の正当化なし）。 </li></ul>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4>  <a href="">講義4. EMアルゴリズムと動径基底関数のネットワーク</a> </h4>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <ul><li> 停止基準、初期近似の選択、コンポーネント数の選択。 </li><li> 確率的EMアルゴリズム。 </li><li> 多次元正規分布の混合。 放射基底関数ネットワーク（RBF）と、それを構成するEMアルゴリズムのアプリケーション。 </li><li> 最近傍法（kNN）とその一般化。 </li><li> 移動制御の基準に従った数kの選択。 </li></ul>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4>  <a href="">講義5.メトリック分類アルゴリズム</a> </h4>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <ul><li> 一般化されたメトリック分類子、インデントの概念。 </li><li> 潜在的な機能の方法、勾配アルゴリズム。 </li><li> 参照オブジェクトの選択。 擬似コード：STOLPアルゴリズム。 </li><li> 競合アフィニティ機能、FRiS-STOLPアルゴリズム。 </li><li> 生体ニューロン、マッカロックピッツモデル。 </li><li> 線形分類器、インデントの概念、しきい値損失関数の連続近似。 </li></ul>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4>  <a href="">講義6.線形分類アルゴリズム</a> </h4>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <ul><li> 二次損失関数、最小二乗法、フィッシャー線形判別式との接続。 </li><li> 確率的勾配法と特別な場合：適応線形要素ADALINE、Rosenblattパーセプトロン、Habbルール。 </li><li> 確率的勾配法の欠点とその除去方法。 収束の加速、ローカルミニマムの「ノックアウト」。 再訓練の問題、体重減少（体重減少）。 </li><li> クラスの尤度関数の指数仮説。 </li><li> ベイズ最適分類器の線形定理。 </li><li> シグモイド活性化関数を使用した事後クラス確率の推定。 </li><li> ロジスティック回帰。 尤度最大原理と対数損失関数。 </li><li> 確率的勾配法、Habbルールとの類推。 </li></ul>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4>  <a href="">講義7.サポートベクターの方法（SVM）</a> </h4>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <ul><li> 最適な分割超平面。 クラス間のギャップの概念（マージン）。 線形分離可能性と線形分離可能性の欠如の場合。 </li><li> 正規化された経験的リスクの最小化との関係。 区分線形損失関数。 </li><li> 二次計画問題と二重問題。 サポートベクターの概念。 </li><li> 定数Cを選択するための推奨事項 </li><li> カーネル関数、整流空間、マーサーの定理。 </li><li> 核の建設的構築の方法。 コアの例。 </li><li>  SVMとガウスコアおよびRBFネットワークの比較。 </li></ul>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4>  <a href="">講義8.線形分類法：一般化とレビュー</a> </h4>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <ul><li> さまざまな連続損失関数とさまざまな正則化の理論的実証。 </li><li> ベイジアンアプローチ。 データとモデルの最大結合尤度の原理。 </li><li> 実際に使用されるいくつかの種類のレギュラー。 二次（L2）正則化。  L1-およびL0-レギュラーと、文字の選択との関係。 </li><li> 関連するベクトルの方法。 </li><li> 複雑さのアプローチ。  Rademacherの複雑さとそのプロパティの一部。 線形分類器のエラー確率の上限。 </li></ul>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4>  <a href="">講義9.回帰回復法</a> </h4>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <ul><li> 回帰回復問題、最小二乗法。 </li><li>  1次元ノンパラメトリック回帰（平滑化）：Nadara-Watson推定、カーネルの選択、平滑化ウィンドウ幅。 </li><li> 多次元線形回帰。 特異分解。 </li><li> 正則化：リッジ回帰と投げ縄Tibshirani。 </li><li> 主成分法と相関関係のないカルネン・レーエフ変換。 </li><li> ロバスト回帰：単純なLOWESS放出スクリーニングアルゴリズム。 </li></ul>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4>  <a href="">講義10.時系列予測</a> </h4>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <ul><li> 加法および乗法の時系列モデル。 トレンド、季節性、カレンダー効果。 </li><li> 適応モデル：指数平滑法、Holt-WintersおよびTheil-Wageモデル。 </li><li> スライディングパイロットとTrigg-Lichモデル。 </li><li> 予測モデルの適応的な選択と構成。 </li><li> 適用されるタスクの例：トラフィック予測、訪問数、販売量。 </li></ul>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4>  <a href="">講義11.ニューラルネットワーク</a> </h4>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <ul><li> 多層ニューラルネットワークの構造。 アクティベーション機能。 </li><li> 完全性の問題。 排他的ORのタスク。 ブール関数の空間における2層ネットワークの完全性。 </li><li> エラー逆伝播アルゴリズム。 初期近似の形成。 ネットワーク麻痺の問題。 </li><li> ネットワーク構造最適化方法。 隠れ層の層数とニューロン数の選択。 ネットワークの緩やかな合併症。 最適なネットワークの間引き（最適な脳損傷）。 </li></ul>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4>  <a href="">講義12.クラスタリングアルゴリズム</a> </h4>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <ul><li> クラスター化問題ステートメント。 クラスター構造のタイプ。 </li><li> グラフクラスタリング手法：接続されたコンポーネントを識別するアルゴリズム、FORELアルゴリズム、クラスタリング品質機能。 </li><li> 階層クラスタリング（分類）：凝集階層クラスタリング、樹状図および単調性のプロパティ、圧縮、拡張、および還元性のプロパティ。 </li><li> 統計的クラスタリング手法：EMアルゴリズム、k-means法。 </li></ul>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4>  <a href="">講義13.部分学習法</a> </h4>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <ul><li> 単純な発見的方法：SSLタスクの機能、自己訓練方法、分類アルゴリズムの構成。 </li><li> クラスタリング手法の変更：最適化アプローチ、制限付きクラスタリング。 </li><li> 分類方法の変更：変換SVM、ロジスティック回帰、期待正則化。 </li></ul>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4> 講義14-15。 分類子の構成。 ブースティング（ <a href="">パート1</a> 、 <a href="">パート2</a> ） </h4>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <ul><li> 分類子の構成：学習構成の問題、古典的なAdaBoostアルゴリズム、勾配ブースティング。 </li><li> バギングおよび委員会の方法：バギングおよびランダム部分空間法、単純でバランスの取れた投票、年功序列投票。 </li><li> アルゴリズムの混合物：能力の分野の考え方、混合物を学習し、混合物を順次構築する反復的な方法 </li></ul>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4>  <a href="">講義16.一般化能力の評価</a> </h4>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <ul><li> 教育方法を選択するためのタスクと基準：モデルまたは教育方法を選択するためのタスク、移動制御の経験的推定、分析的推定および正則化基準。 </li><li> 一般化能力の理論：再訓練の確率とVC理論、Occamの剃刀、再訓練の組み合わせ理論。 </li><li> 特性選択方法：徹底的な検索と貪欲なアルゴリズム、深さおよび幅の検索、確率的検索。 </li></ul>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4>  <a href="">講義17.機能を選択する方法。</a>  <a href="">機能の選択</a> </h4>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <ul><li> 機能を選択するタスクの複雑さ。 完全な検索。 </li><li> 追加および削除の方法、段階的回帰。 </li><li> 深さ、枝と境界線の方法で検索します。 </li><li> 切り捨てられた幅優先の検索、MSUA複数行反復アルゴリズム。 </li><li> 遺伝的アルゴリズム、MGUAとの類似性。 </li><li> ランダム検索および適応付きランダム検索（SPA）。 </li></ul>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4>  <a href="">講義18.論理分類アルゴリズム</a> </h4>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <ul><li> 規則性と情報コンテンツの概念：定義と指定、解釈可能性、情報コンテンツ。 </li><li> 有益なパターンを検索する方法：貪欲なアルゴリズム、標識の選択に基づくアルゴリズム、データの二値化。 </li><li> パターンの構成：決定的なリスト、決定的な木、投票パターン、決定的な森林。 </li></ul>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4>  <a href="">講義19.論理分類アルゴリズム。</a>  <a href="">決定的な木</a> </h4>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <ul><li> 決定的なリスト。 欲張りリスト合成アルゴリズム。 </li><li> 決定的なツリー。 擬似コード：貪欲なID3アルゴリズム。 アルゴリズムの欠点とそれらを除去する方法。 再訓練の問題。 </li><li> 決定木削減：事前削減と事後削減。 </li><li> 決定木を決定リストに変換します。 </li><li>  LISTBBアルゴリズム。 </li><li> 交互決定木。 </li><li> 不注意な決定木。 </li><li> 決定的な森と決定的な木を後押しします。  TreeNetアルゴリズム。 </li></ul>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4>  <a href="">講義20。論理分類アルゴリズム。</a>  <a href="">加重投票</a> </h4>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <ul><li> 結合パターンの合成方法。 擬似コード：CORAアルゴリズム、TEMPアルゴリズム。 </li><li> パターンの多様性と有用性を提供するヒューリスティック。 パレート最適パターンの構築。 インデント分布の整列。 </li><li> パターンに適用されるAdaBoostブースティングアルゴリズム。 ブースティングの情報基準。 </li><li> 適用されるタスクの例：クレジットスコアリング、カスタマーケアの予測。 </li></ul>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4>  <a href="">講義21.連想ルールの検索</a> </h4>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <ul><li> 結合パターンの合成方法。 擬似コード：CORAアルゴリズム、TEMPアルゴリズム。 </li><li> パターンの多様性と有用性を提供するヒューリスティック。 パレート最適パターンの構築。 インデント分布の整列。 </li><li> パターンに適用されるAdaBoostブースティングアルゴリズム。 ブースティングの情報基準。 </li><li> 適用されるタスクの例：クレジットスコアリング、カスタマーケアの予測。 </li></ul>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4>  <a href="">講義22.共同イテレーション</a> </h4>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <ul><li> 問題とアプリケーションの声明。 </li><li> データストレージに基づく相関モデルでは、欠損値を回復するタスクが近接関数です。 </li><li> 潜在モデル：二重クラスター化とマトリックス分解、確率的潜在モデル、Yandexデータからの実験。 </li></ul>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4> 講義23-24。 テーマ別モデリング（ <a href="">パート1</a> 、 <a href="">パート2</a> ） </h4>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <ul><li> テーマモデリングタスク：確率的テーマモデル、ユニグラムモデル。 </li><li> テーマモデルPLSAおよびLDA：確率的潜在セマンティックモデル、潜在ディリクレ配置、テーマモデルの品質の経験的評価。 </li><li> ロバストな確率論的テーマモデル：バックグラウンドおよびノイズ成分を含むモデル、ロバストモデルのEMアルゴリズム、ロバストモデルのスパース性。 </li></ul>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4>  <a href="">講義25.強化トレーニング</a> </h4>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <ul><li> 多腕バンディット：問題、貪欲および半欲張りの戦略、適応戦略の簡単な説明。 </li><li> 動的プログラミング：問題の完全な記述、ベルマン方程式。 </li><li> 時差の方法。 </li></ul>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      <b>更新：</b> <a href="http://yadi.sk/d/V9p7E6uAFjHcD">機械学習コースのすべての講義は、Yandex.Diskの開いているフォルダーの形式で行われます</a> 。 </div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../J208020/index.html">1058人の候補者が火星への飛行に選ば</a></li>
<li><a href="../J208022/index.html">シーメンスのロゴ！ -10年後</a></li>
<li><a href="../J208026/index.html">STM32およびUSB-HID-簡単です</a></li>
<li><a href="../J208030/index.html">今年の発見-もう一つの便利な睡眠機能</a></li>
<li><a href="../J208032/index.html">2つの文化の衝突：「できる」と「できない」</a></li>
<li><a href="../J208038/index.html">NASAが形状変化ロボットホイールをテスト</a></li>
<li><a href="../J208040/index.html">プログラマーがファッションサイトにたどり着いた方法</a></li>
<li><a href="../J208042/index.html">3Dプリンター。 2013年の成果の概要</a></li>
<li><a href="../J208044/index.html">コンピュータゲーム「Noosphere」-最初のレベルのスクリプトの提案</a></li>
<li><a href="../J208048/index.html">ロケット技術の目に見えない困難</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter70218013 = new Ya.Metrika({
                  id:70218013,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/70218013" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'G-FEDBM7F51Q', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Clever Geek | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <div class="company-info js-company-info" itemscope="" itemtype="http://schema.org/Organization">
      <span itemprop="name">Western Town Media (WTM)</span>
      <div itemprop="address" itemscope="" itemtype="http://schema.org/PostalAddress">
        <span itemprop="streetAddress">1968 Stoney Lonesome Road</span>
        <br>
        <span itemprop="postalCode">PA 18640</span>
        <span itemprop="addressLocality">Pittston, USA</span>
      </div>
      <span itemprop="telephone">570-362-1316</span>
    </div>
    <script type="application/ld+json">
      {
        "@context": "http://schema.org",
        "@type": "Organization",
        "address": {
          "@type": "PostalAddress",
          "addressLocality": "Pittston, USA",
          "postalCode": "PA 18640",
          "streetAddress": "1968 Stoney Lonesome Road"
        },
        "name": "Western Town Media (WTM)",
        "telephone": "570-362-1316"
      }
    </script>
  </div>
</footer>
  
</body>

</html>